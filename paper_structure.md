## Rough plan of the contents

1. Theoretical background:
  - CNNs
  - Vision transformers and comparison to CNNs`
  - Adversarial attacks



abstract:
Deep learning models are currently state of the art in the area of image classification and object detection, however, they can be easily confused by so called adversarial examples. 
These are specifically crafted inputs that resemble typical clean inputs, however, the models classify them incorrectly. 
Adversarial examples have been widely studied in the literature and there are many different ways of creating them. 
This thesis will focus on so called patch attacks against vision transformers with the goal to make the attacks general and transferable to other models.

The student will study literature on vision transformers and adversarial attacks with focus on patch attacks. 
Based on the obtained information, she will test existing attacks and implement new attacks with focus on transferability of the attacks between different image classification and object detection models.