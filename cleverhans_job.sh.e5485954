wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: takonoselidze (takonoselidze-charles-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in /scratch.ssd/takonoselidze/job_5485954.pbs-m1.metacentrum.cz/wandb/run-20241021_171035-4hqr187j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-lake-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/takonoselidze-charles-university/Cleverhans%20HOP-SKIP-vit_b_16
wandb: üöÄ View run at https://wandb.ai/takonoselidze-charles-university/Cleverhans%20HOP-SKIP-vit_b_16/runs/4hqr187j
Traceback (most recent call last):
  File "main.py", line 222, in <module>
    adv_images, original_preds, adv_preds = attack(attack_name, attack_params, model, dataloader, brightness_factor, device)
  File "main.py", line 126, in attack
    adversarial_image = attack_name(model, image, **attack_params).detach().to(device)
  File "/usr/local/lib/python3.8/dist-packages/cleverhans/torch/attacks/hop_skip_jump_attack.py", line 211, in hop_skip_jump_attack
    pert = hsja(x_, None, None)
  File "/usr/local/lib/python3.8/dist-packages/cleverhans/torch/attacks/hop_skip_jump_attack.py", line 131, in hsja
    gradf = approximate_gradient(
  File "/usr/local/lib/python3.8/dist-packages/cleverhans/torch/attacks/hop_skip_jump_attack.py", line 243, in approximate_gradient
    decisions = decision_function(perturbed).float()
  File "/usr/local/lib/python3.8/dist-packages/cleverhans/torch/attacks/hop_skip_jump_attack.py", line 93, in decision_function
    prob_i = model_fn(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torchvision/models/vision_transformer.py", line 298, in forward
    x = self.encoder(x)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torchvision/models/vision_transformer.py", line 157, in forward
    return self.ln(self.layers(self.dropout(input)))
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torchvision/models/vision_transformer.py", line 118, in forward
    y = self.mlp(y)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 174.00 MiB (GPU 0; 44.34 GiB total capacity; 39.16 GiB already allocated; 158.81 MiB free; 43.85 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
