Copying project and dataset to scratch...
Files in scratch directory:
Running singularity container...
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: python-dotenv in /auto/brno2/home/takonoselidze/.local/lib/python3.8/site-packages (1.0.1)
Arguments passed to main.py: /scratch.ssd/takonoselidze/job_8178938.pbs-m1.metacentrum.cz/imagenetv2-top-images/imagenetv2-top-images-format-val /scratch.ssd/takonoselidze/job_8178938.pbs-m1.metacentrum.cz/checkpoints mini 8 src-tar vit_b_16  16 2 200 1  
Running Python script
------------------------------ Iteration 1 for target class: "pretzel" (932) ------------------------------
@ Epoch 1 for a target class: 932
@  Batch 1
     Loss: 8.610536575317383
     True labels: tensor([925, 262, 734, 185, 291, 520, 221, 406, 996, 263, 735, 451, 674, 227,
        392, 163, 900, 515, 892, 472, 816, 981, 146, 474, 812, 590, 359, 916,
        996, 466, 735])
     Predicted labels: [tensor([931, 334,  76, 265, 360, 567, 299, 746, 996, 335, 760, 968, 705, 305,
        398, 245, 909, 562, 901, 822, 833, 982,  23, 525,  83,  63, 421, 923,
        996, 670, 760])]
     Correctly misclassified: 0
@    Batch (number 1) has ASR: 0.0
@  Batch 2
     Loss: 8.738697052001953
     True labels: tensor([ 81,  21, 322, 718, 314, 301, 148, 312, 995, 353, 222, 791, 392, 925,
        981, 148, 534, 317, 389, 206, 808, 369, 718, 752, 795, 986,  63, 808,
        676, 983, 791, 946])
     Predicted labels: [tensor([172, 117, 389, 745, 381,  37, 232,  31, 995, 416, 299, 508, 451, 868,
        794, 176, 892, 384, 718, 284, 826, 430, 745, 776, 814, 987, 204, 826,
        707, 984, 878, 574])]
     Correctly misclassified: 0
@    Batch (number 2) has ASR: 0.0
@  Batch 3
     Loss: 8.709710121154785
     True labels: tensor([521, 266, 187, 752, 900, 211, 958, 673, 484, 105,  91, 392, 355, 284,
        521,  30, 484, 983,  76, 179, 378, 730, 357, 164, 775, 454, 448, 233,
        370, 534, 571, 466])
     Predicted labels: [tensor([568, 338, 267, 776, 909, 289, 961, 704, 532, 182, 180, 451, 418, 354,
        568, 125, 534, 984, 166,  26, 439, 756,  42, 246, 797, 507, 869, 904,
        861, 337, 829, 518])]
     Correctly misclassified: 0
@    Batch (number 3) has ASR: 0.0
@  Batch 4
     Loss: 8.497030258178711
     True labels: tensor([759, 206, 218, 284,  23, 766, 674, 832, 972,   3,  81, 285, 472, 179,
        163,  81, 211, 652, 862, 998, 427, 206, 818, 959, 681, 631, 451, 795,
        939, 228, 947, 479])
     Predicted labels: [tensor([782, 356, 295, 354, 118, 789, 705, 754, 974, 100, 151, 355, 523, 114,
        245, 171, 904, 686, 476, 998, 483, 284, 835, 962, 711, 667, 504, 549,
        944, 311, 631,  53])]
     Correctly misclassified: 0
@    Batch (number 4) has ASR: 0.0
@  Batch 5
     Loss: 8.522793769836426
     True labels: tensor([328, 369,  91,  61, 439, 892, 170, 829, 775, 652, 906, 451, 513, 513,
        829, 714, 466, 834, 946, 454, 285, 372, 484, 690, 734, 802, 484, 105,
        940, 142, 106])
     Predicted labels: [tensor([  6, 430, 179, 153, 731, 907, 212, 845, 831, 412, 914, 967, 822, 560,
        845, 741, 837, 549, 696, 714, 355, 433, 534,  72, 530, 820, 534, 185,
        945, 207, 194])]
     Correctly misclassified: 0
@    Batch (number 5) has ASR: 0.0
@  Batch 6
     Loss: 8.666760444641113
     True labels: tensor([515, 291, 690, 187,  21, 488, 590,  16, 527, 530, 389, 520, 900, 341,
        696,  89, 534, 619, 959, 758, 357, 436, 791, 974, 513, 295,   3, 266,
        488, 185, 127])
     Predicted labels: [tensor([562, 669,  72, 267, 117, 538,  63, 112, 573, 576, 669, 567, 909, 974,
        725, 179,  58, 656, 962, 781,  42, 549, 810, 972, 560, 364, 100, 333,
        538, 265, 212])]
     Correctly misclassified: 0
@    Batch (number 6) has ASR: 0.0
@  Batch 7
     Loss: 7.979432582855225
     True labels: tensor([ 79, 958, 106, 673, 437,   7, 372, 812, 455, 652, 437, 669, 284,  18,
        990, 533, 127,  33, 725, 372, 730, 521, 400, 904, 474, 317, 791,  30,
        681, 972, 696, 262])
     Predicted labels: [tensor([ 17, 961, 868, 704, 492, 227, 433,  83, 508, 686, 492, 700, 354, 114,
        990, 579, 212, 143, 751, 433, 756, 568, 459, 912, 976, 384, 508, 124,
        711, 974, 725, 334])]
     Correctly misclassified: 0
@    Batch (number 7) has ASR: 0.0
@  Batch 8
     Loss: 8.422938346862793
     True labels: tensor([369,  16,  52, 474,  18, 900, 571, 782, 881, 258, 140, 299, 284, 986,
        906,  91, 585, 981,  52, 328, 218,  81, 953, 515, 179, 947, 818, 986,
          7, 392, 758, 513])
     Predicted labels: [tensor([430, 112, 145, 975, 114, 868, 612, 789, 892, 331, 256, 368, 354, 998,
        780, 173, 472, 442, 145, 394, 295, 171, 957, 562,  26, 951, 646, 998,
        104, 451, 781, 560])]
     Correctly misclassified: 0
@    Batch (number 8) has ASR: 0.0
@  Batch 9
     Loss: 8.01944637298584
     True labels: tensor([300, 185, 834, 916, 696,  21,  76, 582, 262, 900, 185, 357,  50, 834,
         91, 262, 370, 187, 230, 994, 299, 820, 818, 205, 810, 904, 221, 571,
        775, 892, 218, 291])
     Predicted labels: [tensor([369, 266,  85, 809, 725, 117, 167, 759, 334, 909, 183,  42, 143,  85,
        549, 334, 431, 266, 305, 994, 368, 445, 835, 283, 828, 912, 298, 612,
        797, 901, 295, 360])]
     Correctly misclassified: 0
@    Batch (number 9) has ASR: 0.0
@  Batch 10
     Loss: 8.066323280334473
     True labels: tensor([714, 206, 975, 312, 820,  70, 389,  30, 673, 534, 837, 370,   7, 341,
        816, 977, 436, 164, 406, 105, 262,  63, 479,   3, 943, 406, 546,  16,
        250, 775, 990, 222])
     Predicted labels: [tensor([741, 284, 977,  38, 445, 162, 538, 125, 704, 562, 752, 765, 351, 405,
        833, 970, 580, 251, 818, 185, 334, 204,  53, 100, 948, 958, 782, 112,
        323, 549, 641, 299])]
     Correctly misclassified: 0
@    Batch (number 10) has ASR: 0.0
@  Batch 11
     Loss: 7.918294906616211
     True labels: tensor([266, 810, 582, 222, 690, 527, 871, 437, 676, 881,  70, 998, 718, 322,
        540, 479, 983, 448, 685, 437, 230, 466, 227, 733,   7, 299, 620,  30,
        996, 206, 669, 534])
     Predicted labels: [tensor([338, 868, 633, 299,  72, 573, 883, 492, 707, 892, 161, 998, 745, 389,
        585,  53, 984, 399, 715, 492, 619, 437, 308, 732, 104, 368, 613, 125,
        679, 284, 999,  58])]
     Correctly misclassified: 0
@    Batch (number 11) has ASR: 0.0
@  Batch 12
     Loss: 7.828840255737305
     True labels: tensor([372, 983, 900, 981, 571, 140, 607, 521, 730, 241, 627, 759, 109, 258,
        284, 540, 244, 230, 906, 400, 314, 885, 530, 585, 230, 864, 530, 163,
        142, 322, 892])
     Predicted labels: [tensor([433, 984, 909, 857, 612, 224, 645, 850, 756, 315, 698, 868, 197, 330,
        354, 794, 318, 305, 780, 750, 381, 896, 576, 625, 305, 877, 576, 245,
        226, 389, 901])]
     Correctly misclassified: 0
@    Batch (number 12) has ASR: 0.0
@  Batch 13
     Loss: 7.8120832443237305
     True labels: tensor([998, 233, 946, 977, 353, 837, 448, 837,  20, 106, 291, 295,  21, 974,
        607, 966, 843, 681, 436, 258, 466, 595, 185, 170,  89, 791, 916, 218,
        730, 714, 810, 943])
     Predicted labels: [tensor([998, 308, 790, 701, 416, 752, 887, 752, 116, 194, 360, 364, 117, 701,
        645, 969, 858, 626, 491, 330, 518, 619, 265, 251, 207, 620, 619, 295,
        756, 741, 828, 948])]
     Correctly misclassified: 0
@    Batch (number 13) has ASR: 0.0
@  Batch 14
     Loss: 7.53915548324585
     True labels: tensor([766, 943, 943, 118,  18, 972, 812, 370, 980, 205,  89, 582, 127, 211,
        142, 105, 484, 513, 916, 595, 837,  60, 534, 607,  70, 314, 211, 571,
        685, 127, 958, 205])
     Predicted labels: [tensor([789, 948, 948, 971, 114, 974,  83, 431, 981, 203, 180, 447, 212, 669,
        226, 679, 534, 560, 868, 634, 207, 152, 701, 645, 161, 381, 794, 612,
        715, 212, 961, 283])]
     Correctly misclassified: 0
@    Batch (number 14) has ASR: 0.0
@  Batch 15
     Loss: 7.743044853210449
     True labels: tensor([241, 939, 520, 943, 980, 300, 317, 227, 439, 233, 372, 392, 503, 758,
        170, 135, 582, 582, 163, 941, 667,  23, 975, 445, 995, 241, 795, 187,
        966, 353, 557, 619])
     Predicted labels: [tensor([315, 944, 567, 948, 981, 369, 384, 302, 541, 308, 793, 451, 551, 781,
        971,  22, 759, 872, 195, 946,   8, 120, 977, 329, 995, 315, 814, 265,
        969, 416,  54, 436])]
     Correctly misclassified: 0
@    Batch (number 15) has ASR: 0.0
@  Batch 16
     Loss: 7.643600940704346
     True labels: tensor([595, 300, 308, 439, 140,   3, 148, 627, 995, 939, 540, 808, 135, 941,
        400, 359, 109, 595, 474, 228, 607, 291, 479, 250, 436, 590, 211, 802,
        474, 810, 170, 370])
     Predicted labels: [tensor([634, 806, 376, 577, 224, 100, 971, 806, 995, 944, 585, 826,  22, 946,
        459, 421, 197, 530, 977, 303, 645, 360, 794, 323, 491,  63, 794, 820,
        971, 828, 251, 431])]
     Correctly misclassified: 0
@    Batch (number 16) has ASR: 0.0
@  Batch 17
     Loss: 7.581099987030029
     True labels: tensor([127, 802, 816,   3, 916, 520, 233, 163, 958, 488,  50, 257, 674, 759,
        974, 428, 301, 940, 299, 862, 571, 795, 452, 612, 369, 257, 990, 977,
        994, 959, 233, 696])
     Predicted labels: [tensor([212, 820, 833, 100, 923, 971, 308, 245, 910, 538, 143,  33, 705, 851,
        672, 484,  37, 945, 368, 875, 971, 814, 971,  65, 971, 213, 971, 619,
        994, 962, 308, 725])]
     Correctly misclassified: 0
@    Batch (number 17) has ASR: 0.0
@  Batch 18
     Loss: 7.596094131469727
     True labels: tensor([667, 866, 357, 322, 515, 266, 953, 140, 222, 977, 802, 735, 503, 791,
        752, 696, 257, 663,  21, 974, 669, 148, 312, 140, 533, 881, 285,  18,
        221, 782, 479, 663])
     Predicted labels: [tensor([  7, 879,  46, 389, 806, 338, 711, 224, 299, 970, 820, 760, 631, 878,
        776, 725,  33, 542, 117, 976, 999, 232,  38, 223, 579, 892, 355, 114,
        299, 802,  53, 696])]
     Correctly misclassified: 0
@    Batch (number 18) has ASR: 0.0
@  Batch 19
     Loss: 7.606907844543457
     True labels: tensor([949, 681, 980, 314, 369, 943, 669, 179, 474, 530, 582, 900,  79, 557,
        946, 612, 676,  60, 837, 885, 427, 533, 285, 335, 335, 451, 335, 685,
        864, 263, 317, 299])
     Predicted labels: [tensor([953, 711, 981, 381, 430, 948, 804, 971, 977, 576, 971, 549,  17,  60,
        950,  65, 480, 152, 852, 896, 839, 462, 355,  40,  40, 967,  40, 715,
        877, 335, 384, 368])]
     Correctly misclassified: 0
@    Batch (number 19) has ASR: 0.0
@  Batch 20
     Loss: 7.704288482666016
     True labels: tensor([353, 257, 995, 266, 164,  20, 378, 758,   3, 986, 818, 109, 843, 266,
        400, 946, 990, 427, 295, 590, 312, 521, 756, 263, 812, 812, 428, 735,
        227, 428, 818, 998])
     Predicted labels: [tensor([416,  33, 995, 338, 246, 502, 439, 781, 100, 987, 835, 214, 971, 971,
        459, 950, 990, 483, 364,  63,  38, 568,  78, 335,  83,  83, 484, 549,
        314, 871, 835, 998])]
     Correctly misclassified: 0
@    Batch (number 20) has ASR: 0.0
@  Batch 21
     Loss: 7.278069496154785
     True labels: tensor([ 61,  89, 437, 734, 782,  33,  81, 959, 619, 105, 295, 488, 718,  79,
         33,  79, 437, 322, 513, 595, 472, 843, 820,  50, 520, 142, 109, 439,
        488, 791, 718, 620])
     Predicted labels: [tensor([203, 179, 492,  76, 802, 135, 971, 930, 971, 187, 364, 538, 619,  17,
        141,  17, 492, 806, 752, 971, 433, 425, 806, 143, 567, 226, 197, 971,
        698, 508, 971, 895])]
     Correctly misclassified: 0
@    Batch (number 21) has ASR: 0.0
@  Batch 22
     Loss: 7.193470478057861
     True labels: tensor([974, 258, 916, 791, 428, 904, 439,  16, 959,  61, 135, 372, 370, 977,
        284, 733, 881, 734, 631, 871, 685, 221, 663, 503, 452, 812, 996, 557,
         61, 427, 816, 527])
     Predicted labels: [tensor([972, 330, 959, 810, 871, 912, 442, 112, 962, 153,  22, 868, 679, 649,
        354, 549, 894,  76, 400, 883, 715, 298, 767, 551, 737,  83, 806, 971,
        153, 619, 833, 573])]
     Correctly misclassified: 0
@    Batch (number 22) has ASR: 0.0
@  Batch 23
     Loss: 6.93907356262207
     True labels: tensor([904,  50,  60, 206, 317, 205,  81, 406, 148, 335, 980, 513, 437, 527,
        864, 105, 759, 455, 585, 205, 834, 990, 106, 227, 834, 975, 816, 312,
        943, 230, 802, 455])
     Predicted labels: [tensor([898, 143, 971, 284, 384, 283, 971, 591, 264,  40, 971, 560, 664, 573,
        877, 616, 782, 971, 625, 283,  85, 990, 194, 300,  86, 977, 833,  38,
        470, 305, 820, 681])]
     Correctly misclassified: 0
@    Batch (number 23) has ASR: 0.0
@  Batch 24
     Loss: 7.3774542808532715
     True labels: tensor([619, 439, 185,  50, 530, 885, 735, 940, 244, 266, 291, 244, 527, 472,
        946,  76, 400, 871, 299, 228, 140, 263,  52, 953, 627, 118, 995, 118,
        864, 392, 980, 263])
     Predicted labels: [tensor([468, 494, 265, 143, 576, 435, 760, 549, 318, 338, 971, 318, 573, 806,
        588, 971, 806, 883, 368, 311, 224, 335, 145, 794, 497, 971, 995, 204,
        806, 451, 971, 335])]
     Correctly misclassified: 0
@    Batch (number 24) has ASR: 0.0
@  Batch 25
     Loss: 7.314558506011963
     True labels: tensor([663, 328, 378,  70, 733,  21, 690, 312, 904, 314, 975, 142, 301, 996,
        658, 262, 953, 990, 262, 406, 472, 808, 627, 696, 972,  20, 916, 135,
        892, 996, 257, 906])
     Predicted labels: [tensor([462, 394, 971, 161, 759, 117,  72,  38, 716, 806, 977, 226,  37, 971,
        806, 334, 956, 990, 334, 464, 645, 826, 687, 725, 974,  69, 971,  21,
        901, 996,  33, 780])]
     Correctly misclassified: 0
@    Batch (number 25) has ASR: 0.0
@  Batch 26
     Loss: 7.028059005737305
     True labels: tensor([ 36,  36,  89, 436, 943, 791, 802,   3, 285, 758, 301, 585,  52, 322,
        832, 980, 428,  30, 871, 466, 972, 322, 782, 669, 322, 228, 947, 263,
        135, 164, 590, 179])
     Predicted labels: [tensor([130, 130, 180, 416, 948, 508, 820, 100, 355, 530,  36, 724, 971,  30,
        848, 981, 871, 125, 883, 971, 974, 971, 802, 999, 971, 898, 951, 335,
        971, 176,  63,  26])]
     Correctly misclassified: 0
@    Batch (number 26) has ASR: 0.0
@  Batch 27
     Loss: 7.4697980880737305
     True labels: tensor([427, 669, 829, 533, 690, 118, 378, 448, 808, 690, 775,  63, 866,  16,
         76, 127, 834, 619, 696, 109, 939, 843, 527, 733, 437, 756, 975, 959,
        218, 221, 756, 864])
     Predicted labels: [tensor([483, 999, 971, 532,  72, 971, 439, 501, 826,  72, 797, 155, 879, 806,
        971, 212,  85, 656, 725, 197, 944, 858, 573, 759, 492,  78, 977, 962,
        295, 298,  78, 877])]
     Correctly misclassified: 0
@    Batch (number 27) has ASR: 0.0
@  Batch 28
     Loss: 7.267458438873291
     True labels: tensor([355, 400, 284, 370, 986, 445, 864, 906, 607, 452, 958, 714, 474, 667,
        146, 725, 295, 503, 515, 389, 667, 972,  30, 187, 146, 436, 472, 439,
        359,  33, 148, 607])
     Predicted labels: [tensor([971, 445, 354, 868, 987,   5, 877, 484, 898, 505, 961, 971, 971,   7,
         23, 751, 364, 551, 562, 449,   7, 974, 125, 267,  23, 971, 523, 494,
        520, 128, 232, 645])]
     Correctly misclassified: 0
@    Batch (number 28) has ASR: 0.0
@  Batch 29
     Loss: 6.832209587097168
     True labels: tensor([118,  89, 714, 312, 941, 939,  76, 146, 866, 981, 135, 540, 734, 585,
        975, 734,  50,  81, 900, 795, 904, 546,  52, 301,  60,  60, 959, 170,
         61, 211,   7, 530])
     Predicted labels: [tensor([185, 180, 741,  38, 946, 944, 971,  23, 879, 806,  22, 631,  76, 625,
        976,  76, 143, 172, 806, 814, 912, 761, 971,  37, 155, 977, 806, 251,
        806, 289, 104, 576])]
     Correctly misclassified: 0
@    Batch (number 29) has ASR: 0.0
@  Batch 30
     Loss: 7.0243072509765625
     True labels: tensor([454, 263, 752, 474,  18, 355, 972, 941, 681, 571, 353, 906,  23, 974,
        355, 233, 109, 981, 530, 756, 250, 244, 837, 802, 308,  81, 975, 734,
         18, 312, 990, 674])
     Predicted labels: [tensor([507, 971, 971, 806, 971, 477, 974, 946, 679, 612, 416, 914, 616, 976,
        418, 308, 971, 971, 576,  78, 323, 318, 752, 820, 376, 171, 672,  76,
        114,  38, 971, 547])]
     Correctly misclassified: 0
@    Batch (number 30) has ASR: 0.0
@  Batch 31
     Loss: 6.836677551269531
     True labels: tensor([445, 994, 947, 925, 257, 582, 163, 947, 241,  20, 520, 595, 595, 983,
        540, 359, 540, 820, 752, 452,  23, 782,   7, 925, 179, 601, 925,  18,
        341, 994, 946, 105])
     Predicted labels: [tensor([  6, 994, 951, 932,  33, 679, 616, 951, 315, 116, 567, 634, 971, 984,
        699, 421, 720, 836, 776, 505, 120, 802, 104, 932,  26,  64, 931, 114,
        405, 994, 922, 837])]
     Correctly misclassified: 2
@    Batch (number 31) has ASR: 0.0625
@  Batch 32
     Loss: 7.034158706665039
     True labels: tensor([466, 619, 996, 218, 631, 658, 341,  63, 291, 513, 940, 946, 818, 244,
        378, 222, 673, 308, 601, 135, 221, 834, 479, 810, 521, 612, 455, 612,
        515,  33, 953, 372])
     Predicted labels: [tensor([113, 679, 996, 295, 898, 971, 405, 153, 360, 560, 945, 784, 835, 318,
        971, 971, 704, 376, 679,  22, 298,  85,  53, 828, 568,  65, 508, 971,
        562, 128, 989, 961])]
     Correctly misclassified: 0
@    Batch (number 32) has ASR: 0.0
@  Batch 33
     Loss: 7.01863431930542
     True labels: tensor([312, 369, 941, 546, 681, 871, 335, 353, 571, 314, 227, 949, 466, 994,
        233, 187, 714, 533, 341, 862,  36, 733, 230, 734, 472,  63, 521, 585,
        864, 766, 427, 998])
     Predicted labels: [tensor([ 38, 430, 794, 699, 589, 883,  46, 416, 971, 381, 304, 953, 435, 994,
        308, 267, 741, 579, 405, 513, 130, 872, 305,  77, 523, 185, 824, 625,
        877, 789, 483, 987])]
     Correctly misclassified: 0
@    Batch (number 33) has ASR: 0.0
@  Batch 34
     Loss: 6.809753894805908
     True labels: tensor([631, 667,  61, 735, 341, 106, 392, 906, 540, 696, 400, 904, 862, 658,
        389, 585, 513, 980, 142,  50,  20, 503, 585, 359, 300, 843,  52, 328,
        986, 690, 949, 164])
     Predicted labels: [tensor([701,   7, 153, 760, 405, 153, 451, 780, 971, 725, 701, 489, 875, 691,
        449, 625, 560, 981, 971, 143, 116, 551, 701, 421, 369, 858, 145, 394,
        509,  72, 953, 246])]
     Correctly misclassified: 0
@    Batch (number 34) has ASR: 0.0
@  Batch 35
     Loss: 6.769493103027344
     True labels: tensor([445, 953, 658, 983, 314, 109,  30, 301, 142, 448, 230, 652, 752, 258,
        816,  33, 211, 295, 820, 218,  50, 472, 488,   7, 892, 406,  89, 601,
        127, 106, 488, 503])
     Predicted labels: [tensor([  6, 957, 691, 984, 381, 971, 125,  37, 226, 971, 305, 971, 776, 330,
        833, 128, 289, 364, 836, 295, 143, 523, 557, 104, 971, 616, 971,  64,
        212, 153, 971, 551])]
     Correctly misclassified: 0
@    Batch (number 35) has ASR: 0.0
@  Batch 36
     Loss: 6.658571720123291
     True labels: tensor([222, 534, 392, 187, 454, 977, 758, 619,  33,   3,  36, 734, 266, 163,
        244, 975, 756, 966, 369, 140, 258, 452, 601, 759, 206, 546, 437, 752,
        925, 612, 170, 925])
     Predicted labels: [tensor([971,  58, 451, 971, 971, 971, 781, 971, 128, 100, 130, 971, 338, 245,
        806, 701,  78, 971, 430, 224, 330, 505,  59, 664, 284, 590, 492, 971,
        931,  65, 251, 931])]
     Correctly misclassified: 0
@    Batch (number 36) has ASR: 0.0
@  Batch 37
     Loss: 6.6155619621276855
     True labels: tensor([228, 233, 472, 378, 341, 317, 627, 359, 205, 612, 284, 452, 301, 406,
        652, 300, 515, 735, 170, 998, 406, 546, 474, 250, 527, 998, 258, 782,
        146, 585, 218, 612])
     Predicted labels: [tensor([303, 308, 523, 439, 418, 384, 440, 971, 283,  65, 354, 419,  37, 932,
        686, 369, 971, 760, 251, 998, 692, 419, 971, 323, 573, 987, 330, 802,
         23, 971, 295,  65])]
     Correctly misclassified: 1
@    Batch (number 37) has ASR: 0.03125
@  Batch 38
     Loss: 6.617901802062988
     True labels: tensor([994, 885,  61,  20, 766, 300, 308, 445, 308, 676, 513, 127, 322, 892,
        658, 756, 211, 685, 353, 521, 673, 427, 328, 378, 627, 981, 735, 607,
        966, 148, 986, 466])
     Predicted labels: [tensor([994, 435, 153, 116, 789, 369, 376, 971, 376, 707, 971, 212, 389, 419,
        971,  78, 289, 715, 416, 339, 704, 483, 394, 439, 497, 971, 651, 971,
        809, 231, 462, 518])]
     Correctly misclassified: 0
@    Batch (number 38) has ASR: 0.0
@  Batch 39
     Loss: 6.850114822387695
     True labels: tensor([118, 595, 439,   7,  33, 620, 222, 233, 601, 983, 595, 436, 142, 533,
        241, 164, 906, 995,  81, 892, 262, 620, 241, 227, 353, 718, 696, 674,
        866, 810, 406, 977])
     Predicted labels: [tensor([160, 971, 577, 104, 128, 895, 299, 308,  64, 984, 634, 491, 226, 579,
        315, 246, 780, 971, 178, 901, 334, 774, 315, 302, 416, 745, 725, 705,
        971, 828, 464, 970])]
     Correctly misclassified: 0
@    Batch (number 39) has ASR: 0.0
@  Batch 40
     Loss: 6.718634605407715
     True labels: tensor([ 23, 312, 940, 437, 370,  23, 681, 109, 378, 436, 620, 631, 725, 941,
        314, 998, 974, 795, 557, 758, 452, 317, 941, 782, 328, 105, 322, 353,
        725, 527, 977, 222])
     Predicted labels: [tensor([120,  38, 945, 493, 431, 119, 504, 346, 439, 611, 437, 971, 751, 946,
         91, 998, 976, 814,  60, 781, 966, 384, 944, 802, 394, 185, 389, 416,
        609, 573, 440, 299])]
     Correctly misclassified: 0
@    Batch (number 40) has ASR: 0.0
@  Batch 41
     Loss: 6.697473526000977
     True labels: tensor([725, 140, 881, 227, 262, 314, 601, 300, 980, 257, 389, 557,  70, 756,
         52, 943, 959, 285, 966, 810, 673, 820, 285, 590, 241,  33, 241, 941,
        527, 515,  60, 520])
     Predicted labels: [tensor([751, 224, 892, 971, 334, 374,  64, 367, 981,  33, 693,  60, 161,  78,
        145, 948, 868, 355, 969, 828, 704, 837, 355, 971, 315, 128, 315, 794,
        830, 562, 152, 567])]
     Correctly misclassified: 0
@    Batch (number 41) has ASR: 0.0
@  Batch 42
     Loss: 6.740128517150879
     True labels: tensor([452, 676, 972, 758, 820, 164,  21, 871, 667, 546, 479, 258, 866, 718,
        206, 885,  76, 916, 619, 455, 881, 808, 308, 808, 389, 996,  63, 904,
        829, 949, 546, 118])
     Predicted labels: [tensor([901, 707, 974, 781, 837, 246, 117, 883, 971, 487,  53, 330, 701, 806,
        284, 971, 167, 960, 971, 508, 892, 826, 376, 826, 971, 996, 155, 912,
        845, 953, 419, 971])]
     Correctly misclassified: 0
@    Batch (number 42) has ASR: 0.0
@  Batch 43
     Loss: 6.975682258605957
     True labels: tensor([832, 766, 400, 658, 146, 179, 829, 607, 521, 820, 378, 818, 663, 862,
        571, 837, 820, 355, 179, 451, 503, 291, 627, 427, 885, 866, 816, 392,
        357, 885, 949])
     Predicted labels: [tensor([859, 789, 445, 616,  23,  26, 971, 645, 339, 806, 439, 807, 696, 559,
        612, 852, 399, 767,  26, 504, 551, 360, 698, 483, 440, 879, 971, 451,
         42, 806, 953])]
     Correctly misclassified: 0
@    Batch (number 43) has ASR: 0.0
@  Batch 44
     Loss: 6.588696002960205
     True labels: tensor([285, 983, 400, 451, 669,  36, 756, 515, 601, 357, 455, 652, 759,  16,
        714, 802, 733, 652,  23, 808, 285, 428, 733, 488, 557, 983, 766, 357,
        582, 832, 612, 837])
     Predicted labels: [tensor([355, 971, 399, 794, 462, 130,  78, 562,  64,  42, 508, 971, 851, 806,
        741, 820, 759, 570, 971, 826, 355, 484, 732, 538, 506, 984, 789,  42,
        759, 848, 440, 971])]
     Correctly misclassified: 0
@    Batch (number 44) has ASR: 0.0
@  Batch 45
     Loss: 6.457307815551758
     True labels: tensor([187, 106, 718, 389, 816, 837, 669, 472, 775, 227, 557, 557, 906, 733,
        862,  76, 258, 146, 816, 250,  60, 607, 791, 109, 843, 335, 843,  79,
        299, 230, 142, 445])
     Predicted labels: [tensor([267, 155, 745, 971, 833, 852, 999, 523, 797, 302, 971,  60, 971, 836,
        875, 971, 330,  23, 833, 323, 152, 898, 971, 199, 425,  40, 698,  14,
        368, 305, 971,   6])]
     Correctly misclassified: 0
@    Batch (number 45) has ASR: 0.0
@  Batch 46
     Loss: 6.967607498168945
     True labels: tensor([148, 669, 619, 676, 284, 795, 257, 392, 953,  70, 943,  79, 369, 228,
        752, 939, 977, 795, 527, 696, 163, 631, 530, 454, 866, 949,  36, 995,
        782, 714,  20,  30])
     Predicted labels: [tensor([971, 999, 511, 886, 354, 814, 679, 451, 647, 971, 948,  17, 430, 304,
        776, 944, 979, 625, 573, 725, 245, 400, 576, 507, 879, 953, 130, 995,
        802, 741, 611, 125])]
     Correctly misclassified: 0
@    Batch (number 46) has ASR: 0.0
@  Batch 47
     Loss: 6.66729736328125
     True labels: tensor([454, 866, 445, 663, 218, 810, 667, 479, 986, 981, 959, 939, 590, 690,
        291, 436, 974, 730, 221, 301, 775, 733, 520, 681, 244, 520, 335, 676,
         36, 972, 295, 218])
     Predicted labels: [tensor([507, 971,   5, 563, 295, 828, 971,  53, 415, 971, 962, 944,  63,  72,
        360, 491, 977, 756, 274,  37, 750, 759, 567, 971, 318, 469,  40, 806,
        130, 974, 364, 295])]
     Correctly misclassified: 0
@    Batch (number 47) has ASR: 0.0
@  Batch 48
     Loss: 6.572908401489258
     True labels: tensor([300, 612, 127, 406, 866, 958, 428, 105, 187, 862, 834, 766, 818, 652,
        756, 892, 451, 881, 980, 308, 958, 372, 730, 782, 959, 953, 540, 667,
        802, 328, 448, 170])
     Predicted labels: [tensor([369, 329, 971, 971, 440, 611, 484, 187, 971, 875,  85, 789, 835, 686,
         78, 504, 504, 892, 971, 376, 961, 971, 756, 802, 962, 957, 662,   7,
        820, 395, 501, 251])]
     Correctly misclassified: 0
@    Batch (number 48) has ASR: 0.0
@  Batch 49
     Loss: 6.373630523681641
     True labels: tensor([681, 185, 389, 818, 146, 940, 881, 685, 222,  21, 601, 448, 674, 843,
        357, 837, 179, 871, 998, 832, 685, 674, 389, 428, 109, 439, 534, 257,
        205,  89, 627, 582])
     Predicted labels: [tensor([711, 265, 449, 835,  23, 470, 892, 715, 299, 117,  55, 869, 705, 858,
        549, 184,  26, 883, 679, 971, 715, 705, 449, 554, 197, 929,  58,  34,
        203, 180, 884, 622])]
     Correctly misclassified: 0
@    Batch (number 49) has ASR: 0.0
@  Batch 50
     Loss: 6.4858198165893555
     True labels: tensor([673, 284, 250, 317, 775,  16, 864, 994,  89, 941, 445, 266, 818, 308,
        452, 612, 335,  91, 832, 812, 953, 714, 958, 328, 135, 211, 428, 658,
        530,  61,  91, 205])
     Predicted labels: [tensor([704, 354, 323, 384, 611, 971, 877, 994, 179, 946, 701, 338, 835, 679,
        849,  65,  46, 971, 848,  83, 616, 741, 930, 971,  22, 289, 440, 691,
        576, 971, 179, 283])]
     Correctly misclassified: 0
@    Batch (number 50) has ASR: 0.0
@  Batch 51
     Loss: 6.754866600036621
     True labels: tensor([810, 658, 244, 135, 454,  23, 620, 257, 631, 378, 355, 341, 503, 179,
        832, 454, 451, 994, 619,  52, 652, 250, 866,  91, 940, 452, 148, 829,
        939, 299, 355, 106])
     Predicted labels: [tensor([868, 830, 318,  22, 758, 118, 744,  34, 971, 439, 748, 417, 551, 611,
        929, 507, 967, 994, 468, 145, 783, 611, 701, 679, 945, 968, 971, 767,
        944, 368, 733, 190])]
     Correctly misclassified: 0
@    Batch (number 51) has ASR: 0.0
@  Batch 52
     Loss: 6.613961696624756
     True labels: tensor([829, 185, 127, 533, 455, 206, 658, 466, 118, 946, 663, 258, 940, 627,
        448, 301, 530,  52, 759, 590, 983, 998,  91,  21, 244, 620, 947,  30,
        995, 370,  20, 546])
     Predicted labels: [tensor([641, 266, 212, 579, 549, 284, 691, 518, 202, 434, 794, 971, 806, 663,
        846,  37, 576, 145, 440,  63, 984, 987, 180, 117, 318, 744, 951, 125,
        995, 520, 116, 487])]
     Correctly misclassified: 0
@    Batch (number 52) has ASR: 0.0
@  Batch 53
     Loss: 6.873846530914307
     True labels: tensor([996,  21, 455, 966, 540, 995, 981, 299, 885, 295, 370, 947, 667, 228,
        142, 900, 146, 904, 966, 335,  50, 725, 571, 871,  70, 730, 673, 940,
         81, 758, 832, 187])
     Predicted labels: [tensor([996, 117, 681, 969, 804, 995, 982, 368, 440, 364, 431, 950, 971, 303,
        971, 809, 971, 971, 969, 440, 137, 751, 612, 616, 971, 440, 704, 943,
        171, 781, 848, 266])]
     Correctly misclassified: 0
@    Batch (number 53) has ASR: 0.0
@  Batch 54
     Loss: 6.396528720855713
     True labels: tensor([228, 916, 981, 479, 620, 250, 947, 990, 631, 228, 862,  61, 546, 515,
        534, 533, 725,   3,  33,  89, 864, 832, 291, 357, 949, 663, 546, 795,
        714, 185, 557])
     Predicted labels: [tensor([303, 868, 679,  53, 744, 323, 951, 125, 701, 303, 513, 153, 487, 974,
         58, 971, 751, 100, 128, 179, 794, 767, 971,  42, 953, 910, 487, 977,
        741, 266,  60])]
     Correctly misclassified: 0
@    Batch (number 54) has ASR: 0.0
@  Batch 55
     Loss: 6.6637043952941895
     True labels: tensor([758, 451, 871, 607, 620, 972, 862, 946, 301, 211, 590, 620, 996, 241,
        484, 812, 949,  16,  70, 730,  70, 832, 759, 766,   7, 885, 308, 317,
        328, 484, 455, 829])
     Predicted labels: [tensor([781, 969, 883, 645, 540, 974, 875, 950,  37, 289,  63, 744, 996, 315,
        534,  83, 953, 112, 161, 971, 161, 848, 971, 789, 971, 648, 376, 384,
        971, 534, 508, 845])]
     Correctly misclassified: 0
@    Batch (number 55) has ASR: 0.0
@  Batch 56
     Loss: 6.34843111038208
     True labels: tensor([ 76,  61, 503, 730, 975, 353, 925, 170, 233, 829, 881, 163, 658, 328,
        735, 439, 885, 140,  91, 451, 244,  36, 667, 871,  63, 676, 445, 228,
        227, 488, 222, 941])
     Predicted labels: [tensor([971, 154, 551, 603, 977, 416, 415, 251, 308, 845, 892, 971, 701, 971,
        971, 971, 896, 199, 180, 504, 318, 130,   7, 883, 155, 707,   6, 314,
        302, 971, 971, 946])]
     Correctly misclassified: 0
@    Batch (number 56) has ASR: 0.0
@  Batch 57
     Loss: 6.3970866203308105
     True labels: tensor([221, 335, 164, 230, 966,   7, 940, 829, 484, 900, 958, 521, 205, 759,
        400, 299, 810, 262, 359, 359, 590, 718,  70, 341, 681,  79, 735,  76,
        958,  23, 690, 816])
     Predicted labels: [tensor([298,  46, 616, 305, 969, 971, 945, 845, 534, 653, 961, 971, 283, 971,
        445, 368, 828, 334, 971, 421,  68, 971, 971, 405, 971,  17, 760, 162,
        868, 118,  72, 833])]
     Correctly misclassified: 0
@    Batch (number 57) has ASR: 0.0
@  Batch 58
     Loss: 6.558093547821045
     True labels: tensor([975, 725, 582, 427, 986, 454, 986, 676, 263, 300, 759, 448, 782, 980,
        690, 974, 250,  30,  36, 674,  16,  76, 520, 974, 164, 752, 295, 359,
        105, 676, 990])
     Predicted labels: [tensor([977, 751, 759, 975, 644, 507, 987, 707, 335, 369, 782, 824, 971, 981,
         72, 970, 323, 125, 130, 705, 112, 971, 892, 976, 971, 776, 364, 421,
        971, 707, 990])]
     Correctly misclassified: 0
@    Batch (number 58) has ASR: 0.0
@  Batch 59
     Loss: 6.952183246612549
     True labels: tensor([994,  16, 718, 812, 843, 663, 925, 834, 454, 949, 355, 673, 995, 250,
        369, 118,  63, 308, 427, 663,  18, 595, 730,  50, 428, 939, 808, 734,
        241, 263, 864, 916])
     Predicted labels: [tensor([971, 112, 745, 971, 738, 438, 415,  85, 507, 953, 418, 704, 995, 323,
        430, 155, 155, 971, 483, 971, 114, 634, 756, 143, 971, 944, 826,  76,
        315, 335, 440, 933])]
     Correctly misclassified: 0
@    Batch (number 59) has ASR: 0.0
@  Batch 60
     Loss: 6.208013534545898
     True labels: tensor([533, 503, 479, 164, 725, 372, 802,  63, 221, 135, 627, 752, 685, 484,
        947, 300,  23, 808,  20, 904,  63, 357, 436, 488, 372, 949, 939, 953,
        585, 862, 484,  91])
     Predicted labels: [tensor([579, 629,  53, 246, 751, 433, 820, 155, 971,  22, 971, 776, 929, 971,
        794, 369, 119, 630, 971, 912, 155,  42, 491, 668, 806, 953, 944, 997,
        625, 401, 534, 611])]
     Correctly misclassified: 0
@    Batch (number 60) has ASR: 0.0
@  Batch 61
     Loss: 6.466480731964111
     True labels: tensor([ 79, 148, 118, 185,  60, 314, 966,  52, 674, 775, 285,   3, 966, 834,
        990, 221, 685, 106, 775, 674, 534, 263, 359,  18, 206,  36, 106, 355,
        266, 540])
     Predicted labels: [tensor([ 17, 971, 971, 265, 971, 381, 925, 145, 705, 971, 971, 100, 964,  86,
        971, 611, 715, 190, 797, 705,  58, 335, 421, 114, 971, 130, 207, 418,
        338, 585])]
     Correctly misclassified: 0
@    Batch (number 61) has ASR: 0.0
@  Batch 62
     Loss: 6.186619758605957
     True labels: tensor([474, 140, 445,  60, 925, 812, 163, 146, 892, 906, 725, 673, 317, 369,
        205, 455, 994, 843, 601, 631, 766, 795, 652,  79, 448, 230, 533,  60,
        557, 355, 631])
     Predicted labels: [tensor([718, 224, 115, 971, 932,  83, 971,  23, 901, 780, 971, 704, 384, 641,
        283, 971, 994, 858,  64, 400, 789, 440, 783,  17, 601, 971, 579, 152,
         60, 418, 400])]
     Correctly misclassified: 1
@    Batch (number 62) has ASR: 0.03225806451612903
@  Batch 63
     Loss: 6.398948669433594
     True labels: tensor([881, 341, 766, 820, 685,  20, 170, 601, 977,  18, 756, 733, 947,  79,
        295, 669])
     Predicted labels: [tensor([892, 701, 789, 851, 652, 328, 251,  64, 611, 306,  78, 971, 950,  17,
        701, 611])]
     Correctly misclassified: 0
@    Batch (number 63) has ASR: 0.0
Epoch [1/2], Loss: 6.398948669433594, Avg ASR: 0.01%
  > Saved generator at epoch 1 to /scratch.ssd/takonoselidze/job_8178938.pbs-m1.metacentrum.cz/checkpoints/generator_epoch_1_target_932.pth
@ Epoch 2 for a target class: 932
@  Batch 1
     Loss: 6.323456764221191
     True labels: tensor([996, 135, 900, 990, 975, 301, 571, 258,  21,  61, 448, 341, 437, 832,
        258, 843, 206, 983, 428, 837, 211, 454, 690,  21, 775, 756, 681, 994,
         79, 696, 285, 585])
     Predicted labels: [tensor([996, 971, 971, 990, 977,  37, 612, 971, 117, 153, 971, 971, 492, 754,
        971, 723, 284, 984, 971, 207, 794, 507,  72, 117, 440, 794, 971, 994,
         17, 679, 354, 625])]
     Correctly misclassified: 0
@    Batch (number 1) has ASR: 0.0
@  Batch 2
     Loss: 6.483558654785156
     True labels: tensor([972, 299, 258, 810, 986, 484, 983, 631, 170, 105, 503, 939, 488, 233,
        479, 681, 185, 257, 972,  91, 455, 437,  63, 947, 983,  79, 109, 916,
        527, 355,  89, 127])
     Predicted labels: [tensor([974, 368, 611, 828, 987, 971, 440, 400, 251, 611, 551, 944, 538, 971,
         53, 711, 265, 801, 974, 180, 508, 415, 155, 470, 984,  17, 197, 971,
        573, 477, 971, 212])]
     Correctly misclassified: 0
@    Batch (number 2) has ASR: 0.0
@  Batch 3
     Loss: 6.347670555114746
     True labels: tensor([400, 966,  52, 300, 353, 241, 782,  20, 295, 676, 946, 291,  63,  30,
        864, 782, 986, 105, 164, 164, 428, 735, 734, 904, 667, 966, 474, 227,
        619, 981, 369, 439])
     Predicted labels: [tensor([445, 969, 145, 369, 416, 315, 802, 116, 364, 707, 790, 360, 187, 125,
        877, 971, 987, 185, 165, 971, 978, 760,  76, 723,   8, 969, 976, 302,
        656, 575, 971, 577])]
     Correctly misclassified: 0
@    Batch (number 3) has ASR: 0.0
@  Batch 4
     Loss: 6.352017402648926
     True labels: tensor([187, 795, 372, 791, 904, 959,  20, 816, 205, 601, 958, 834,  61, 977,
        966, 906, 980, 312, 607, 953, 515,  63, 759, 766,  79, 312,  89, 392,
        355,  60, 714, 953])
     Predicted labels: [tensor([971, 814, 971, 508, 912, 962, 116, 971, 283,  55, 961,  85, 611, 971,
        969, 780, 971,  38, 645, 794, 562, 155, 782, 789,  17,  38, 180, 894,
        418, 152, 741, 720])]
     Correctly misclassified: 0
@    Batch (number 4) has ASR: 0.0
@  Batch 5
     Loss: 6.366991996765137
     True labels: tensor([369, 185, 317, 946, 300, 513, 479, 106, 949, 520, 663, 109, 341, 300,
        187,  70, 233, 974, 832, 455,  70, 328, 308, 244, 451, 300, 994,  16,
        607, 164, 406, 892])
     Predicted labels: [tensor([430, 265, 384, 588, 367, 560, 806, 971, 953, 971, 696, 197, 405, 367,
        221, 161, 308, 972, 754, 508, 971, 394, 373, 318, 968, 369, 994, 112,
        645, 246, 611, 901])]
     Correctly misclassified: 0
@    Batch (number 5) has ASR: 0.0
@  Batch 6
     Loss: 5.993051528930664
     True labels: tensor([733, 590,  18, 795, 582,  81, 620, 205, 658, 802, 808, 263, 766, 206,
        871,  81, 766, 205, 627, 106, 205, 977, 179, 986, 546, 966, 427, 301,
        906, 185, 378, 718])
     Predicted labels: [tensor([759, 971, 114, 814, 633, 171, 744, 283, 691, 820, 826, 335, 789, 284,
        584, 172, 789, 283, 806, 971, 283, 649,  26, 987, 487, 969, 483,  37,
        780, 265, 439, 786])]
     Correctly misclassified: 0
@    Batch (number 6) has ASR: 0.0
@  Batch 7
     Loss: 6.587552070617676
     True labels: tensor([658, 230, 163, 681, 142, 148, 479, 756, 314, 631, 148, 843,  60, 479,
        227, 295, 484, 258, 733, 829, 871, 520, 503, 250, 900, 357, 262, 357,
        832, 228, 244, 759])
     Predicted labels: [tensor([971, 305, 223, 711, 226, 971,  53,  78, 381, 400, 231, 858, 971,  53,
        302, 364, 971, 971, 611, 845, 971, 567, 551, 323, 909,  42, 334, 971,
        767, 679, 318, 782])]
     Correctly misclassified: 0
@    Batch (number 7) has ASR: 0.0
@  Batch 8
     Loss: 6.302567481994629
     True labels: tensor([627, 652, 284, 734, 947, 308, 557, 939, 355, 939, 515, 995, 949, 627,
        881,  60, 127, 607, 357, 291, 612, 479, 359,  91, 372, 291, 820, 127,
        681, 291, 674,  61])
     Predicted labels: [tensor([971, 971, 354,  76, 951, 376, 971, 944, 418, 944, 971, 995, 953, 698,
        892, 217, 212, 971, 611, 440,  65, 971, 971, 242, 433, 971, 971, 212,
        971, 360, 705, 971])]
     Correctly misclassified: 0
@    Batch (number 8) has ASR: 0.0
@  Batch 9
     Loss: 6.106437683105469
     True labels: tensor([148, 185,  76,  63, 818, 714, 958, 983, 322, 284,  61, 484, 472, 109,
         79, 135, 941, 284,  18, 513, 484, 488, 451, 669, 445, 601, 975,  30,
        791, 257, 718])
     Predicted labels: [tensor([611, 971, 611, 215, 835, 741, 611, 984, 971, 354, 153, 534, 523, 197,
         17,  22, 946, 354, 114, 560, 440, 971, 794, 804,   6,  64, 978, 125,
        508,  33, 440])]
     Correctly misclassified: 0
@    Batch (number 9) has ASR: 0.0
@  Batch 10
     Loss: 6.065001010894775
     True labels: tensor([730, 455,  60, 959, 812,  50, 652, 862, 488, 170, 109,  16, 820, 335,
        975, 263, 164,  70, 436, 900, 885, 571, 218, 802, 179, 427, 503, 816,
        472, 718, 250, 906])
     Predicted labels: [tensor([756, 508, 440, 415,  83, 143, 883, 559, 557, 440, 197, 112, 837, 971,
        977, 335, 246, 161, 611, 909, 806, 612, 295, 971, 971, 693, 631, 833,
        523, 745, 323, 780])]
     Correctly misclassified: 0
@    Batch (number 10) has ASR: 0.0
@  Batch 11
     Loss: 6.249233245849609
     True labels: tensor([530, 585, 966, 515,  52, 808, 996,  23, 782, 972, 228, 862, 406, 866,
        428, 233, 355, 816, 943, 520, 725, 428, 947,  23, 990, 118, 230,  91,
        866,  70, 540,  50])
     Predicted labels: [tensor([576, 625, 969, 562, 145, 826, 971, 971, 802, 974, 300, 875, 958, 879,
        484, 308, 748, 833, 948, 567, 971, 484, 806, 118, 990, 971, 305, 971,
        879, 440, 808, 584])]
     Correctly misclassified: 0
@    Batch (number 11) has ASR: 0.0
@  Batch 12
     Loss: 6.182812213897705
     True labels: tensor([  7, 179, 980, 906, 557, 881, 585, 752, 533, 802, 834, 980, 972, 359,
        998, 718, 285,  50, 359, 533, 946, 427, 696, 520, 916, 775, 546, 445,
        530, 106, 673, 228])
     Predicted labels: [tensor([104, 971, 981, 780, 996, 892, 625, 971, 579, 820,  85, 981, 974, 421,
        953, 745, 355, 137, 421, 579, 584, 971, 725, 567, 923, 797, 590,   5,
        576, 971, 971, 314])]
     Correctly misclassified: 0
@    Batch (number 12) has ASR: 0.0
@  Batch 13
     Loss: 6.211477279663086
     True labels: tensor([105, 257, 673, 427, 359, 758, 241, 534, 258, 335, 571, 513, 335, 262,
        428, 977, 725,  30, 452, 734, 871, 474, 527, 676, 837, 372, 925, 941,
        685, 818, 263, 527])
     Predicted labels: [tensor([971,  34, 704, 483, 701, 781, 440,  58, 330, 679, 971, 971,  40, 971,
        484, 979, 751, 125, 767,  76, 883, 525, 830, 707, 852, 793, 931, 946,
        715, 835, 335, 573])]
     Correctly misclassified: 0
@    Batch (number 13) has ASR: 0.0
@  Batch 14
     Loss: 6.364198684692383
     True labels: tensor([ 61,  21, 163, 230, 148, 958,  33, 266, 834,  33, 953, 996, 939, 185,
        466, 428, 590, 619, 752, 389, 730, 546, 105, 118, 142,   3, 808, 185,
        990, 832, 227])
     Predicted labels: [tensor([611, 117, 245, 305, 971, 961, 128, 338,  85, 128, 647, 996, 944, 265,
        971, 871,  63, 971, 776, 693, 756, 487, 185, 971, 226, 100, 826, 971,
        990, 620, 302])]
     Correctly misclassified: 0
@    Batch (number 14) has ASR: 0.0
@  Batch 15
     Loss: 6.130954265594482
     True labels: tensor([843, 658, 106,   7, 939, 795, 906, 925, 353, 142, 484,  21, 262, 802,
         76, 436, 595, 557, 674, 451, 714, 436, 939, 808, 983, 521, 892, 170,
         61, 140, 533, 820])
     Predicted labels: [tensor([858, 830, 190, 971, 944, 625, 914, 931, 416, 207, 534, 117, 334, 820,
        166, 611, 634,  60, 565, 504, 741, 971, 944, 826, 984, 568, 901, 971,
        153, 611, 579, 664])]
     Correctly misclassified: 0
@    Batch (number 15) has ASR: 0.0
@  Batch 16
     Loss: 6.25938081741333
     True labels: tensor([590, 959, 959, 314,  76, 885, 454, 837, 262, 714, 328, 820, 959, 685,
        218, 990, 452, 795, 359, 521, 308,  60, 488, 669, 834, 837, 146, 673,
        816, 791, 527])
     Predicted labels: [tensor([ 63, 962, 922, 379, 971, 470, 507, 752, 611, 741, 971, 841, 415, 715,
        295, 990, 505, 814, 564, 568, 376, 152, 971, 999,  85, 752,  23, 704,
        833, 878, 573])]
     Correctly misclassified: 0
@    Batch (number 16) has ASR: 0.0
@  Batch 17
     Loss: 6.165647506713867
     True labels: tensor([ 89, 244, 862, 244, 455,  20, 263, 328,  20,  50, 300, 530, 218, 466,
        205, 619,  61, 866, 241, 484, 881, 983, 428, 582, 317, 752, 983, 681,
        791, 530, 582, 667])
     Predicted labels: [tensor([971, 318, 420, 318, 508, 116, 335, 394,  69, 143, 367, 576, 295, 971,
        203, 436, 153, 701, 315, 534, 892, 984, 871, 971, 384, 776, 984, 680,
        508, 576, 440,   7])]
     Correctly misclassified: 0
@    Batch (number 17) has ASR: 0.0
@  Batch 18
     Loss: 6.60685920715332
     True labels: tensor([607, 837, 503, 521, 620, 520, 317, 946, 998, 674, 445, 118, 146, 513,
        674, 300, 791,   7, 369, 998, 974, 820, 448, 515, 520,  21, 250, 808,
        871, 986, 775,  89])
     Predicted labels: [tensor([645, 852, 551, 568, 744, 971, 384, 696, 998, 705,   6, 155,  23, 560,
        705, 369, 620, 549, 430, 971, 970, 836, 501, 562, 892, 117, 323, 971,
        883, 987, 750, 971])]
     Correctly misclassified: 0
@    Batch (number 18) has ASR: 0.0
@  Batch 19
     Loss: 6.217676162719727
     True labels: tensor([837, 378, 866, 812, 140, 170, 829, 222, 994, 335, 314, 818, 943, 221,
        241, 941, 328, 437, 812, 791,   7, 667, 353, 406, 221, 335, 530, 372,
        135,  16,  60, 663])
     Predicted labels: [tensor([852, 439, 879,  83, 256, 971, 845, 971, 994,  40, 381, 835, 948, 298,
        315, 946, 394, 492,  83, 878, 104,   7, 416, 531, 299, 440, 576, 433,
         22, 112, 152, 971])]
     Correctly misclassified: 0
@    Batch (number 19) has ASR: 0.0
@  Batch 20
     Loss: 6.487088680267334
     True labels: tensor([452, 284, 758, 881, 820, 520, 808, 357, 990, 714, 378, 758, 627, 291,
         89, 714, 900, 994, 892,  76, 756, 735, 612, 756, 775, 427, 986, 812,
        834, 595, 135, 389])
     Predicted labels: [tensor([898, 354, 781, 892, 445, 567, 826,  42, 990, 741, 439, 530, 497, 337,
        195, 741, 971, 994, 901, 971,  78, 651,  65,  78, 616, 483, 987,  83,
         85, 634,  22, 449])]
     Correctly misclassified: 0
@    Batch (number 20) has ASR: 0.0
@  Batch 21
     Loss: 6.272586345672607
     True labels: tensor([696, 451, 980, 864, 620, 959, 258, 359, 837, 179, 947,   3, 943, 106,
        263,  23, 206, 479, 205, 733, 791, 164, 142, 958, 266, 515, 437, 530,
        631, 357, 810,  21])
     Predicted labels: [tensor([883, 504, 611, 877, 744, 962, 330, 421, 752,  26, 951, 100, 948, 194,
        335, 122, 203,  53, 283, 806, 810, 172, 611, 961, 333, 562, 492, 576,
        971,  42, 828, 117])]
     Correctly misclassified: 0
@    Batch (number 21) has ASR: 0.0
@  Batch 22
     Loss: 6.310823440551758
     True labels: tensor([885, 170, 308, 595, 782, 943, 299, 163, 791, 795,  61, 685, 534, 582,
        940, 595, 503, 170, 619, 829, 451, 947, 667, 335, 142, 843, 862, 595,
        756, 900, 105, 674])
     Predicted labels: [tensor([876, 971, 376, 634, 802, 948, 368, 245, 508, 814, 153, 715,  58, 759,
        767, 634, 551, 971, 611, 641, 967, 611, 971,  47, 226, 971, 875, 634,
         78, 909, 971, 547])]
     Correctly misclassified: 0
@    Batch (number 22) has ASR: 0.0
@  Batch 23
     Loss: 5.749945640563965
     True labels: tensor([135, 925, 619,   3, 179, 262, 818,  50, 986,  70, 533, 734, 257, 916,
         16,  60, 359, 904, 940, 312, 916, 892, 301, 958,  36, 900, 981,  60,
        996, 474, 601,  33])
     Predicted labels: [tensor([ 22, 971, 971, 100,  26, 334, 835, 143, 711, 971, 579,  76,  58, 923,
        112, 977, 765, 912, 943,  38, 928, 901,  37, 961, 130, 971, 982, 152,
        996, 971,  64, 128])]
     Correctly misclassified: 0
@    Batch (number 23) has ASR: 0.0
@  Batch 24
     Loss: 6.127381801605225
     True labels: tensor([752, 546, 187, 669, 696, 690, 170, 782, 322, 295, 211, 515,  52, 871,
        295, 983, 540, 484, 284, 673, 906, 106, 228, 947, 406, 322, 221, 357,
        977, 406, 142, 864])
     Predicted labels: [tensor([776, 662, 267, 767, 679,  72, 251, 802, 971, 611, 289, 469, 145, 883,
        364, 971, 930, 534, 354, 704, 914, 153, 971, 415, 464, 971, 298,  42,
        970, 701, 971, 877])]
     Correctly misclassified: 0
@    Batch (number 24) has ASR: 0.0
@  Batch 25
     Loss: 5.82790470123291
     True labels: tensor([983, 864, 958, 631, 241, 730, 974, 829, 163, 284, 353, 866, 981, 135,
        658, 620, 601, 357, 378, 690, 295, 428, 534, 370, 118, 730, 627, 211,
        810, 451, 370, 977])
     Predicted labels: [tensor([984, 877, 868, 971, 315, 756, 976, 845, 245, 354, 416, 701, 971,  22,
        971, 744,  64,  42, 439, 971, 364, 536, 611, 520, 170, 756, 806, 289,
        767, 967, 961, 971])]
     Correctly misclassified: 0
@    Batch (number 25) has ASR: 0.0
@  Batch 26
     Loss: 5.997763633728027
     True labels: tensor([266,  21, 631, 135, 389, 900, 975,  16, 534, 230, 389, 834, 148, 881,
        906, 862, 284,  36,  81,  18, 448, 816, 829, 262, 439, 759, 520,  52,
        445,  36, 328])
     Predicted labels: [tensor([971, 117, 400,  22, 449, 909, 976, 112, 818, 305, 971, 331, 232, 892,
        780, 875, 339, 130, 217, 114, 601, 833, 611, 334, 971, 664, 567, 971,
        115, 130, 394])]
     Correctly misclassified: 0
@    Batch (number 26) has ASR: 0.0
@  Batch 27
     Loss: 6.27609920501709
     True labels: tensor([530, 974,  36,  61, 479, 445, 612, 299, 631, 335, 667, 725, 995,   7,
        974, 940, 943, 669, 353, 667, 812, 990, 513, 521, 436, 676, 676, 179,
         30, 871,  81, 146])
     Predicted labels: [tensor([576, 460, 130, 154,  53,   6, 971, 368, 400,  46,   8, 751, 995, 104,
        976, 945, 948, 999, 416,   7,  83, 990, 971, 568, 792, 707, 707, 611,
        125, 883, 171, 128])]
     Correctly misclassified: 0
@    Batch (number 27) has ASR: 0.0
@  Batch 28
     Loss: 6.2768402099609375
     True labels: tensor([885, 341, 400, 109, 818, 658, 669, 454,  21, 996, 284, 585, 941, 808,
        834, 696, 370, 652, 250, 590, 378, 557, 437,  52, 981, 980, 810, 674,
        977, 230, 300, 585])
     Predicted labels: [tensor([530, 405, 445, 197, 835, 679, 700, 641, 616, 996, 354, 625, 611, 826,
        611, 725, 431, 686, 323,  63, 971,  60, 492, 145, 611, 981, 968, 705,
        979, 305, 369, 625])]
     Correctly misclassified: 0
@    Batch (number 28) has ASR: 0.0
@  Batch 29
     Loss: 6.163328170776367
     True labels: tensor([228, 448, 135, 244, 474, 812, 452, 681, 958, 892, 900, 735, 966,  33,
        782, 904, 185, 832, 392,  36, 314, 300, 454, 866, 140, 312,  50,  91,
        503, 966, 775, 557])
     Predicted labels: [tensor([304, 501,  22, 318, 611,  83, 849, 711, 930, 901, 909, 760, 964, 128,
        802, 912, 971, 971, 451, 130, 381, 369, 507, 879, 224,  38, 143, 180,
        551, 971, 559, 611])]
     Correctly misclassified: 0
@    Batch (number 29) has ASR: 0.0
@  Batch 30
     Loss: 6.24196720123291
     True labels: tensor([439, 947, 939, 534, 520, 998, 949, 227, 503, 317, 802, 582, 436, 466,
        322, 756,  70, 427, 109, 170, 864, 314, 353, 439, 328, 943, 998, 335,
        718, 378, 673, 864])
     Predicted labels: [tensor([494, 950, 971, 971, 567, 987, 953, 304, 971, 384, 820, 759, 491, 518,
        389,  78, 161, 483, 199, 971, 877, 381, 416, 896, 971, 948, 998,  40,
        745, 971, 704, 877])]
     Correctly misclassified: 0
@    Batch (number 30) has ASR: 0.0
@  Batch 31
     Loss: 6.171990394592285
     True labels: tensor([455, 734, 118,  18, 949,  21, 775, 972, 996, 534, 820, 369, 301, 105,
        221, 981, 241, 925, 233, 479, 230, 285, 943, 250, 775, 445, 285,  79,
        515, 355, 118, 557])
     Predicted labels: [tensor([620, 971, 160, 114, 953, 117, 611, 974, 996, 616, 806, 430,  37, 182,
        298, 971, 315, 415, 308, 971, 305, 355, 470, 323, 149,   6, 355,  17,
        794, 418, 611, 611])]
     Correctly misclassified: 0
@    Batch (number 31) has ASR: 0.0
@  Batch 32
     Loss: 5.733485221862793
     True labels: tensor([521, 782, 452, 533, 428, 221, 540, 791, 148, 759, 775, 674, 620, 571,
         18, 681, 527, 881, 520,  30, 996, 228, 127, 448, 228,  52, 472, 317,
        734, 455])
     Predicted labels: [tensor([806, 802, 968, 462, 971, 611, 585, 971, 264, 782, 797, 971, 437, 612,
        113, 711, 573, 892, 567, 611, 996, 971, 971, 610, 611, 145, 767, 384,
        971, 508])]
     Correctly misclassified: 0
@    Batch (number 32) has ASR: 0.0
@  Batch 33
     Loss: 6.10575008392334
     True labels: tensor([818, 832,   7, 904,  52, 829, 148, 904,  91, 312, 941, 241, 218, 674,
        829, 818, 451,  63, 163, 206, 218, 958, 218, 488, 669, 959, 515, 676,
        864, 975, 718, 946])
     Predicted labels: [tensor([835, 848, 104, 971, 145, 616, 971, 912, 971,  38, 944, 315, 295, 971,
        719, 835, 504, 971, 245, 284, 971, 910, 295, 538, 999, 962, 971, 971,
        971, 977, 745, 950])]
     Correctly misclassified: 0
@    Batch (number 33) has ASR: 0.0
@  Batch 34
     Loss: 6.220272064208984
     True labels: tensor([392,  79, 436, 222, 795, 540,  81,  70,  36, 995, 299, 140, 996, 590,
        205, 312, 673, 685,   3, 607, 983, 370, 974, 378, 257, 916, 227, 752,
        881,  81, 328, 690])
     Predicted labels: [tensor([451,  17, 491, 971, 814, 737, 971, 161, 130, 995, 368, 224, 738,  63,
        283,  38, 704, 652, 100, 645, 984, 765, 440, 439,  34, 923, 302, 776,
        892, 171, 868,  72])]
     Correctly misclassified: 0
@    Batch (number 34) has ASR: 0.0
@  Batch 35
     Loss: 6.36688232421875
     True labels: tensor([427, 179, 328, 714, 866, 546, 187, 975, 428, 250, 585, 733, 400, 766,
        685, 916, 109, 862,  79, 916, 998, 759, 244, 730, 802, 328, 222, 241,
        820, 685, 227, 812])
     Predicted labels: [tensor([483,  26, 394, 741, 879, 487, 971, 977, 971, 323, 625, 759, 445, 789,
        971, 892, 197, 875,  17, 959, 987, 851, 679, 756, 820, 394, 971, 315,
        837, 715, 302, 971])]
     Correctly misclassified: 0
@    Batch (number 35) has ASR: 0.0
@  Batch 36
     Loss: 6.118929862976074
     True labels: tensor([218, 810, 725, 266,   3, 696, 998, 439, 400, 222, 652, 735, 590, 658,
        818, 291, 663, 521, 832, 725, 685,  81, 885, 946,  36, 595, 652, 392,
        758, 810, 206, 994])
     Predicted labels: [tensor([294, 828, 971, 338, 100, 899, 987, 583, 459, 299, 686, 760,  63, 413,
        835, 360, 738, 971, 971, 971, 715, 611, 896, 950, 130, 971, 783, 451,
        781, 828, 284, 994])]
     Correctly misclassified: 0
@    Batch (number 36) has ASR: 0.0
@  Batch 37
     Loss: 5.8446879386901855
     True labels: tensor([454, 816, 866, 451, 601, 620, 146, 488, 862, 392, 472, 949, 590, 140,
        257, 940, 503, 241,  50, 995, 295, 448, 109, 759,  20, 885, 540, 981,
        816, 372,   3, 980])
     Predicted labels: [tensor([507, 971, 971, 967,  59, 895,  23, 971, 513, 451, 433, 953,  63, 224,
         33, 945, 551, 315, 143, 995, 364, 399, 971, 971, 971, 897, 971, 578,
        833, 433, 100, 981])]
     Correctly misclassified: 0
@    Batch (number 37) has ASR: 0.0
@  Batch 38
     Loss: 5.981834411621094
     True labels: tensor([540, 627, 658, 106, 663, 228, 187,  20,  76, 571, 472, 466, 756, 620,
        696, 735, 301,  18, 479, 230, 285, 975, 995, 881, 718, 227,  30, 233,
        142, 582, 892])
     Predicted labels: [tensor([731, 971, 971, 207, 971, 303, 265, 116, 173, 971, 523, 518,  78, 744,
        725, 760,  37, 114,  53, 305, 355, 672, 995, 892, 971, 611, 125, 308,
        226, 826, 901])]
     Correctly misclassified: 0
@    Batch (number 38) has ASR: 0.0
@  Batch 39
     Loss: 6.012612342834473
     True labels: tensor([474, 892, 163, 939, 607, 766, 730, 864, 455, 164,  76,  16,  81, 990,
        802, 595, 690, 669, 513,  52, 820, 187, 439, 652, 233,  23, 995, 372,
        179, 958, 947, 179])
     Predicted labels: [tensor([971, 971, 195, 944, 971, 789, 412, 971, 971, 246, 176, 112, 171, 990,
        820, 971,  72, 999, 611, 145, 445, 971, 461, 686, 308, 120, 995, 433,
         26, 611, 951,  26])]
     Correctly misclassified: 0
@    Batch (number 39) has ASR: 0.0
@  Batch 40
     Loss: 6.121067523956299
     True labels: tensor([105, 816, 843, 730, 690, 946, 756, 291, 284, 262,  76, 925, 233, 187,
        353, 810, 233, 448, 317, 466, 756, 301, 953,  50, 308, 832, 759, 900,
        452, 389, 986, 974])
     Predicted labels: [tensor([530, 833, 858, 756,  72, 950,  78, 360, 354, 334, 167, 931, 308, 971,
        416, 828, 308, 501, 384, 971,  78,  37, 997, 143, 376, 785, 851, 987,
        849, 718, 987, 701])]
     Correctly misclassified: 0
@    Batch (number 40) has ASR: 0.0
@  Batch 41
     Loss: 6.160027503967285
     True labels: tensor([ 60, 205, 206, 163,  81, 619, 620, 372, 454, 533, 285, 221,   7, 118,
        389, 454, 400, 673, 369, 263, 513, 392, 900, 949, 218, 843, 690, 322,
        674, 527, 437, 312])
     Predicted labels: [tensor([971, 283, 284, 245, 971, 656, 540, 971, 507, 579, 355, 299, 351, 971,
        449, 507, 445, 704, 430, 335, 898, 451, 909, 953, 295, 425,  72, 611,
        705, 573, 493,  31])]
     Correctly misclassified: 0
@    Batch (number 41) has ASR: 0.0
@  Batch 42
     Loss: 6.182245254516602
     True labels: tensor([472,  16, 127, 263,  70, 392, 669, 244, 187, 127, 266,  36, 262, 222,
        673, 142, 445, 546, 998,  18, 353, 369, 812, 488, 341, 940, 436, 454,
        943, 392, 299, 455])
     Predicted labels: [tensor([767, 679, 971, 274, 971, 451, 999, 318, 267, 212, 338, 130, 971, 971,
        704, 160, 306, 487, 998, 114, 416, 971,  83, 440, 405, 945, 971, 507,
        971, 451, 368, 508])]
     Correctly misclassified: 0
@    Batch (number 42) has ASR: 0.0
@  Batch 43
     Loss: 5.846925735473633
     True labels: tensor([759, 735, 335, 341,  18, 759, 758, 734, 118, 436, 829, 163, 118, 977,
         63, 885, 484, 812, 834,   7, 370, 445, 996, 221, 620, 752, 299, 775,
        595, 766, 513])
     Predicted labels: [tensor([782, 549,  40, 405, 971, 611, 971,  76, 616, 491, 415, 245, 204, 979,
        971, 435, 971,  83,  85, 163, 431,   5, 991, 971, 470, 776, 368, 797,
        634, 789, 560])]
     Correctly misclassified: 0
@    Batch (number 43) has ASR: 0.0
@  Batch 44
     Loss: 6.330070972442627
     True labels: tensor([766, 829, 782, 795, 127, 389, 452, 733,  30, 885, 673, 986, 940, 474,
        400, 585, 947, 406, 631, 735, 940, 140, 534, 146, 211, 663, 733, 299,
         91, 355, 378, 735])
     Predicted labels: [tensor([789, 971, 802, 814, 212, 625, 505, 447, 125, 806, 704, 987, 971, 978,
        750, 625, 794, 464, 541, 760, 945, 224,  58,  23, 289, 767, 759, 368,
        173, 418, 439, 651])]
     Correctly misclassified: 0
@    Batch (number 44) has ASR: 0.0
@  Batch 45
     Loss: 6.226683616638184
     True labels: tensor([317, 427, 725, 427, 631, 652, 676, 582,  16, 871, 718, 795, 472, 439,
        658, 681, 105, 146, 370, 406, 163, 730, 818, 527,  18, 436, 953, 533,
        612, 667,  76])
     Predicted labels: [tensor([384, 483, 751, 483, 701, 686, 480, 629, 971, 883, 745, 814, 806, 494,
        794, 418, 971,  23, 431, 464, 245, 756, 835, 530, 114, 580, 679, 579,
         65,   7, 166])]
     Correctly misclassified: 0
@    Batch (number 45) has ASR: 0.0
@  Batch 46
     Loss: 5.765780925750732
     True labels: tensor([142, 222, 681,  60, 295, 862, 972,  52, 355, 370, 359, 977,  30, 448,
        758, 221, 837, 308, 940, 571, 142, 892, 758, 619, 676, 241, 949, 285,
        400, 676, 906,  63])
     Predicted labels: [tensor([226, 299, 711, 152, 364, 875, 974, 145, 733, 431, 421, 611, 118, 971,
        781, 298, 752, 376, 945, 612, 611, 901, 781, 611, 886, 315, 953, 355,
        459, 707, 914, 155])]
     Correctly misclassified: 0
@    Batch (number 46) has ASR: 0.0
@  Batch 47
     Loss: 5.705933570861816
     True labels: tensor([601, 977, 820, 940, 619, 369, 233, 300,  33, 448, 530, 258, 314, 291,
        257,  33, 474, 696, 479, 802, 185, 291, 658, 925, 466, 725, 816, 369,
        843, 994, 601, 595])
     Predicted labels: [tensor([ 64, 970, 836, 611, 468, 430, 308, 369, 128, 971, 576, 330, 381, 971,
        616, 611, 977, 725,  53, 820, 265, 971, 691, 932, 971, 751, 833, 430,
        971, 994,  64, 634])]
     Correctly misclassified: 1
@    Batch (number 47) has ASR: 0.03125
@  Batch 48
     Loss: 6.048497200012207
     True labels: tensor([521,  89, 146, 179, 620, 185, 980, 690, 314, 439, 977, 322, 322,  91,
        230, 658, 357, 676, 652, 892, 266, 866,  23,  89, 994, 285, 791, 370,
        941, 735, 389, 981])
     Predicted labels: [tensor([568, 242,  23,  26, 744, 265, 971,  72, 971, 767, 979, 389, 971, 180,
        305, 691, 971, 707, 440, 971, 338, 879, 120, 180, 994, 355, 810, 971,
        946, 760, 449, 857])]
     Correctly misclassified: 0
@    Batch (number 48) has ASR: 0.0
@  Batch 49
     Loss: 5.752614498138428
     True labels: tensor([663,  16, 266, 734, 534,  33, 696, 205, 285, 540,  23, 106, 735, 752,
        998, 146, 685, 818, 590, 515, 146, 571, 378, 808, 990,  33, 530, 966,
        663, 228, 211,  91])
     Predicted labels: [tensor([438, 112, 338,  76,  58, 128, 968, 203, 355, 737, 118, 611, 760, 776,
        998,  23, 932, 646,  66, 562,  23, 971, 971, 826, 971, 128, 576, 969,
        696, 303, 611, 180])]
     Correctly misclassified: 1
@    Batch (number 49) has ASR: 0.03125
@  Batch 50
     Loss: 5.6481122970581055
     True labels: tensor([585, 534,  76, 733, 448, 871, 946, 170, 980, 146, 949, 257, 222, 571,
        590, 474, 521, 730, 546, 263, 341, 585,  63,  18, 140, 228, 328, 164,
        218, 690,  33,  79])
     Predicted labels: [tensor([472, 971, 611, 872, 501, 883, 793, 246, 981,  23, 953,  33, 299, 612,
         63, 525, 530, 427, 419, 335, 405, 625, 204, 114, 199, 303, 395, 246,
        295,  72, 128,  17])]
     Correctly misclassified: 0
@    Batch (number 50) has ASR: 0.0
@  Batch 51
     Loss: 5.6950297355651855
     True labels: tensor([  3,  52, 612, 862, 218, 676, 163,  16, 892, 866, 994, 472, 582, 372,
        766, 187, 864, 862, 885, 484, 484, 843,  30, 947,  63,   7, 663, 546,
        222, 906, 766, 284])
     Predicted labels: [tensor([100, 971, 611, 476, 295, 707, 971, 112, 504, 971, 994, 523, 759, 433,
        789, 611, 877, 875, 896, 534, 534, 858, 125, 951, 971, 355, 696, 826,
        299, 971, 789, 971])]
     Correctly misclassified: 0
@    Batch (number 51) has ASR: 0.0
@  Batch 52
     Loss: 6.1827287673950195
     True labels: tensor([400, 244, 946, 904,  91, 756, 295,   3, 400, 355, 521,  20, 341, 725,
        299, 612,  36, 533, 452, 437, 314, 530, 295, 540, 953, 571, 244, 766,
        941, 244, 533, 953])
     Predicted labels: [tensor([445, 318, 950, 716, 971,  78, 364, 100, 549, 418, 568, 116, 405, 751,
        368,  65, 130, 579, 968, 971, 379, 576, 364, 971, 957, 971, 318, 789,
        946, 318, 401, 950])]
     Correctly misclassified: 0
@    Batch (number 52) has ASR: 0.0
@  Batch 53
     Loss: 5.908111572265625
     True labels: tensor([515, 837, 230, 466, 714, 211, 557, 994, 619, 758, 725, 488,  36, 341,
        300, 758, 925, 975, 631, 986, 378, 359, 222, 301, 308, 832, 301, 795,
        439, 205, 663, 975])
     Predicted labels: [tensor([562, 971, 305, 837, 741, 289, 611, 994, 971, 781, 751, 668, 130,   6,
        369, 781, 971, 977, 400, 509, 439, 971, 971,  37, 376, 971,  36, 971,
        708, 283, 696, 971])]
     Correctly misclassified: 0
@    Batch (number 53) has ASR: 0.0
@  Batch 54
     Loss: 5.71336555480957
     True labels: tensor([557, 258, 959, 452, 211,  89, 135, 607, 590, 995, 816, 400,  79, 906,
        571, 488, 258,   7, 454, 295, 871,  79, 466, 312,  61, 341, 488, 885,
        369, 372, 127, 454])
     Predicted labels: [tensor([611, 330, 962, 505, 289, 180,  22, 645,  63, 995, 971, 584,  17, 780,
        612, 748, 330, 104, 507, 701, 883, 701, 437,  38, 203, 616, 538, 896,
        430, 433, 971, 507])]
     Correctly misclassified: 0
@    Batch (number 54) has ASR: 0.0
@  Batch 55
     Loss: 6.03273868560791
     True labels: tensor([170, 291, 601, 714, 582, 389, 392, 612, 995, 925, 941,  89,  70, 527,
        690, 392, 527, 466, 674, 871, 437, 981, 972, 557, 663, 250, 981, 109,
        612, 994, 834, 406])
     Predicted labels: [tensor([611, 360,  64, 741, 872, 449, 451, 971, 995, 868, 946, 611, 971, 573,
         72, 679, 573, 518, 705, 883, 492, 442, 974,  60, 868, 323, 971, 197,
         65, 994,  85, 868])]
     Correctly misclassified: 0
@    Batch (number 55) has ASR: 0.0
@  Batch 56
     Loss: 6.255803108215332
     True labels: tensor([ 20,  20, 546, 972, 959, 257, 775, 758, 109, 998, 795, 864, 370, 582,
        451, 685, 312, 250, 990, 843, 974, 233, 262, 808, 752, 829, 513,  23,
        540, 733, 389, 322])
     Predicted labels: [tensor([116, 611, 446, 974, 962,  33, 797, 781, 971, 987, 971, 877, 611, 622,
        969, 715,  38, 323,  63, 858, 972, 308, 334, 826, 776, 845, 971, 119,
        971, 759, 971, 389])]
     Correctly misclassified: 0
@    Batch (number 56) has ASR: 0.0
@  Batch 57
     Loss: 5.496540069580078
     True labels: tensor([452, 904, 164, 148, 916, 631, 916, 106,  63, 308, 953, 148, 262, 105,
        299,  23, 314, 230,  81, 140, 953, 503, 439, 353, 995, 140, 227, 585,
         21,   3,  23, 266])
     Predicted labels: [tensor([971, 912, 246, 232, 967, 400, 923, 194, 971, 376, 989, 176, 334, 186,
        368, 120, 381, 305, 178, 224, 957, 551, 971, 416, 995, 224, 300, 814,
        117, 100, 120, 338])]
     Correctly misclassified: 0
@    Batch (number 57) has ASR: 0.0
@  Batch 58
     Loss: 5.681426525115967
     True labels: tensor([943, 322, 322, 949, 881, 335, 958,  30, 455, 974, 308, 696, 312, 211,
        546, 427,  50, 925, 990, 263, 118, 939, 503, 258, 105, 263, 996, 980,
        904, 619, 725, 445])
     Predicted labels: [tensor([948, 611, 971, 953, 892, 971, 961, 125, 508, 977, 376, 725,  38, 289,
        699, 483, 143, 971, 971, 335, 971, 944, 629, 971, 837, 335, 996, 981,
        912, 656, 751, 868])]
     Correctly misclassified: 0
@    Batch (number 58) has ASR: 0.0
@  Batch 59
     Loss: 5.85178804397583
     True labels: tensor([627, 975, 667, 533, 474, 521,  33, 607, 370, 949, 206, 257, 808, 953,
        285, 227, 904, 925, 355, 972, 733, 627, 221, 782, 406, 227, 612, 714,
        669, 445, 669, 369])
     Predicted labels: [tensor([698, 977,   7, 736, 718, 568, 128, 971, 435, 953, 679,  33, 630, 948,
        355, 971, 489, 932, 418, 974, 971, 687, 298, 802, 464, 971,  65, 741,
        999, 611, 999, 430])]
     Correctly misclassified: 1
@    Batch (number 59) has ASR: 0.03125
@  Batch 60
     Loss: 6.3901519775390625
     True labels: tensor([601,  91, 607, 810, 472, 317, 211, 601, 437, 299, 759, 981, 718, 612,
        406, 513,   3, 185, 667,  70, 317, 940,  89, 941, 946, 301, 718, 437,
        106, 733, 810, 943])
     Predicted labels: [tensor([ 64, 180, 611, 409, 523, 440, 289,  64, 492, 368, 851, 971, 745,  65,
        971, 560, 971, 265,   7, 971, 384, 945, 159, 946, 868, 611, 745, 492,
        190, 732, 828, 948])]
     Correctly misclassified: 0
@    Batch (number 60) has ASR: 0.0
@  Batch 61
     Loss: 6.003533363342285
     True labels: tensor([939, 837, 221, 127, 353, 916, 266, 832, 211,  50, 206, 250, 782, 652,
        681, 802, 301, 802,  76, 812, 222, 206, 540, 752, 355, 357, 451, 974,
        980, 148,  20, 652])
     Predicted labels: [tensor([944, 971, 298, 212, 416, 923, 338, 848, 289, 143, 203, 323, 802, 679,
        616, 820,  37, 820, 161,  83, 299, 284, 720, 594, 418, 611, 504, 972,
        981, 679, 116, 686])]
     Correctly misclassified: 0
@    Batch (number 61) has ASR: 0.0
@  Batch 62
     Loss: 5.829851150512695
     True labels: tensor([474, 466, 472, 959, 685, 357,  23, 834, 734, 843, 667, 314, 734, 995,
        135, 317, 752, 436, 250, 627, 595, 941, 266, 527, 730, 308, 372, 534,
        966, 986, 359, 164])
     Predicted labels: [tensor([977, 611, 842, 962, 715,  42, 119,  85,  76, 698,   7, 374, 971, 995,
        971, 384, 971, 611, 323, 663, 679, 946, 338, 573, 971, 376, 433, 611,
        969, 415, 520, 246])]
     Correctly misclassified: 0
@    Batch (number 62) has ASR: 0.0
@  Batch 63
     Loss: 6.116629123687744
     True labels: tensor([607, 557, 810, 127, 341, 164, 966, 673, 206, 140, 972, 627, 881, 187,
        455])
     Predicted labels: [tensor([645,  60, 828, 212, 405, 246, 969, 704, 284, 224, 974, 406, 894, 267,
        508])]
     Correctly misclassified: 0
@    Batch (number 63) has ASR: 0.0
Epoch [2/2], Loss: 6.116629123687744, Avg ASR: 0.00%
  > Saved generator at epoch 2 to /scratch.ssd/takonoselidze/job_8178938.pbs-m1.metacentrum.cz/checkpoints/generator_epoch_2_target_932.pth


Average ASR over all 2 epochs: 0.01% 

----------------------------------------------------------------------------------------------------


------------------------------ Iteration 2 for target class: "strawberry" (949) ------------------------------
@ Epoch 1 for a target class: 949
@  Batch 1
     Loss: 8.067693710327148
     True labels: tensor([620, 620, 627,  61,  18, 452,  61, 943, 820, 752, 718, 582, 652, 301,
        652, 900, 513, 766, 479, 986, 998,  36, 977, 718, 843, 808, 312, 733,
        106, 837, 947, 900])
     Predicted labels: [tensor([862, 471, 663, 153, 114, 505, 153, 948, 837, 776, 745, 759, 783,  37,
        686, 567, 560, 789,  52, 987, 998, 130, 970, 481, 858, 826,  31, 759,
        194, 852, 631, 909])]
     Correctly misclassified: 0
@    Batch (number 1) has ASR: 0.0
@  Batch 2
     Loss: 7.720896244049072
     True labels: tensor([892, 355, 829,   7, 106, 885, 943, 977, 981, 658, 451, 295, 975, 590,
        284,  33, 900,  91, 127, 681, 233, 866, 314, 479, 472, 322, 185, 266,
        513, 392, 866, 733])
     Predicted labels: [tensor([901, 418, 499, 104, 153, 896, 948, 979, 650, 600, 504, 364, 977,  63,
        354, 128, 909, 549, 212, 711, 308, 879, 381,  53, 523, 389, 266, 338,
        981, 451, 879, 759])]
     Correctly misclassified: 0
@    Batch (number 2) has ASR: 0.0
@  Batch 3
     Loss: 7.463058948516846
     True labels: tensor([980, 972, 285, 179, 427, 673, 370,  16, 142, 676, 843, 295, 759, 862,
        328, 725, 312, 301, 885, 832, 752, 455, 595, 513, 163, 341, 756, 479,
        941, 571, 681, 451])
     Predicted labels: [tensor([981, 974, 355,  26, 483, 704, 861, 112, 265, 886, 858, 364, 851, 875,
        394, 751,  38,  37, 861, 481, 776, 681, 634, 560, 245, 405,  78,  53,
        946, 612, 711, 504])]
     Correctly misclassified: 0
@    Batch (number 3) has ASR: 0.0
@  Batch 4
     Loss: 7.398611068725586
     True labels: tensor([455,  60, 871, 953, 759, 455, 127, 218, 959, 520, 262, 466,  36, 317,
        341, 619, 998, 862, 335, 218, 685, 818, 466, 263, 881, 674, 299, 892,
        284, 233,  79, 357])
     Predicted labels: [tensor([508, 152, 883, 957, 782, 508, 212, 294, 962, 567, 334, 670, 130, 384,
        405, 656, 998, 875,  40, 295, 715, 835, 518, 274, 892, 705, 368, 907,
        339, 308,  17,  42])]
     Correctly misclassified: 0
@    Batch (number 4) has ASR: 0.0
@  Batch 5
     Loss: 7.289799213409424
     True labels: tensor([205,  91, 148, 372, 864, 904, 378, 676, 752, 690, 312, 939, 916, 322,
        233, 170, 454, 466, 515, 221,  18, 582, 818, 759,  63, 607, 756, 627,
        627, 925, 353, 146])
     Predicted labels: [tensor([203, 180, 232, 433, 877, 716, 439, 707, 776,  72,  38, 944, 923, 389,
        308, 251, 507, 783, 562, 298, 114, 633, 835, 851, 215, 645,  78, 884,
        663, 931, 416,  23])]
     Correctly misclassified: 0
@    Batch (number 5) has ASR: 0.0
@  Batch 6
     Loss: 7.457137107849121
     True labels: tensor([515, 488, 808, 620, 658, 513, 257, 454, 163, 187,  30, 925,  60, 673,
        445, 263, 230, 530, 663, 357, 148, 837,  23,  30, 986, 389, 291, 317,
         33, 389, 939, 284])
     Predicted labels: [tensor([562, 538, 826, 895, 691, 560,  33, 507, 245, 267, 904, 415, 250, 704,
          5, 335, 305, 576, 794,  42, 231, 852, 119, 125, 987, 718, 368, 384,
        128, 449, 944, 354])]
     Correctly misclassified: 0
@    Batch (number 6) has ASR: 0.0
@  Batch 7
     Loss: 7.378387928009033
     True labels: tensor([658, 317,  61, 871, 185, 474, 230, 300, 521, 940, 109, 585, 667, 775,
        257,  79, 445, 791, 466, 667, 284, 983, 607, 488, 977, 996, 454, 284,
          3, 135,  70, 187])
     Predicted labels: [tensor([423, 384, 153, 883, 267, 977, 305, 369, 339, 945, 197, 625,   7, 750,
        801,  17,   6, 508, 518,   7, 354, 984, 645, 538, 979, 996, 507, 354,
        100,  22, 161, 267])]
     Correctly misclassified: 0
@    Batch (number 7) has ASR: 0.0
@  Batch 8
     Loss: 7.312359809875488
     True labels: tensor([585, 233, 135, 959, 996, 758, 527, 546,   7, 881, 474, 118, 958, 211,
        314, 947, 335, 885, 795, 820, 262, 983,  60, 681, 808, 503,  61, 808,
         70, 998, 620, 734])
     Predicted labels: [tensor([625, 308,  22, 962, 996, 781, 573, 761, 104, 409, 976, 202, 961, 289,
        381, 951,  40, 861, 814, 837, 334, 984, 152, 589, 826, 551, 258, 630,
        161, 998, 540,  76])]
     Correctly misclassified: 0
@    Batch (number 8) has ASR: 0.0
@  Batch 9
     Loss: 7.318085670471191
     True labels: tensor([810, 355,  81,  61, 308, 222, 941, 663, 540,  23, 163, 582, 940, 718,
        718, 980, 590, 534, 939, 663, 619, 474, 263, 308, 627, 627, 818, 148,
         18, 300, 454])
     Predicted labels: [tensor([828, 769, 171, 153, 376, 299, 946, 910, 720, 118, 195, 759, 945, 745,
        745, 981,  63,  58, 944, 696, 511, 525, 335, 376, 663, 698, 835, 232,
        114, 369, 507])]
     Correctly misclassified: 0
@    Batch (number 9) has ASR: 0.0
@  Batch 10
     Loss: 6.987154006958008
     True labels: tensor([871, 206,  21, 230, 810, 335,  91, 466, 140,  23, 427, 585, 906,  63,
        105, 328, 631, 534, 221, 958, 533, 900, 674,   3, 452, 427, 906, 392,
        871, 571, 206, 981])
     Predicted labels: [tensor([883, 284, 117, 305, 828,  40, 180, 670, 256, 119, 483, 625, 914, 155,
        187, 344, 667,  65, 298, 961, 579, 463, 547, 100, 846, 483, 914, 451,
        883, 612, 284, 982])]
     Correctly misclassified: 0
@    Batch (number 10) has ASR: 0.0
@  Batch 11
     Loss: 7.002378463745117
     True labels: tensor([834, 775, 758, 981, 947, 782, 674, 299,  52, 795, 975,  52, 916,  81,
        533, 218, 437,  21,  20, 369, 527, 472, 335, 994, 892, 312, 612, 484,
        448, 900,  91, 427])
     Predicted labels: [tensor([ 85, 797, 781, 442, 951, 802, 705, 368, 145, 814, 144, 145, 809, 530,
        579, 295, 493, 117, 116, 430, 573, 523,  40, 994, 901,  38,  65, 534,
        501, 909, 769, 483])]
     Correctly misclassified: 0
@    Batch (number 11) has ASR: 0.0
@  Batch 12
     Loss: 6.872237205505371
     True labels: tensor([939,  91, 820, 454, 725, 557, 871, 322, 406, 148, 520, 829, 341, 995,
        353, 843, 676,  63, 503, 966, 557, 140, 733, 179, 972, 164, 357, 140,
        818, 452,  21, 185])
     Predicted labels: [tensor([944, 242, 836, 507, 751,  60, 883, 389, 471, 195, 567, 845, 405, 995,
        416, 858, 707, 155, 551, 969,  60, 224, 759,  26, 974, 246,  42, 224,
        835, 505, 117, 266])]
     Correctly misclassified: 0
@    Batch (number 12) has ASR: 0.0
@  Batch 13
     Loss: 7.038490295410156
     True labels: tensor([118, 871, 163, 527, 590,  76, 291, 127, 295, 669, 187, 714, 372, 941,
         76, 940, 378,  50, 735,  76, 341,  36, 359, 370, 233, 816, 667, 521,
        904, 250,  23, 227])
     Predicted labels: [tensor([204, 883, 254, 573,  63, 162, 360, 212, 364, 700, 267, 741, 740, 946,
        166, 945, 439, 143, 760, 173, 405, 130, 421, 431, 308, 833,   7, 568,
        489, 323, 119, 304])]
     Correctly misclassified: 0
@    Batch (number 13) has ASR: 0.0
@  Batch 14
     Loss: 7.025673866271973
     True labels: tensor([ 30, 881, 546, 916, 474, 673, 241, 448, 669, 843,  79, 472, 904, 222,
        250, 685, 308,  36, 222, 953, 916, 106, 228, 148, 810, 455, 257, 986,
        301,  60, 714, 206])
     Predicted labels: [tensor([125, 892, 826, 923, 460, 704, 315, 735, 999, 858,  17, 523, 912, 299,
        323, 715, 376, 130, 299, 957, 931, 190, 303, 232, 828, 681,  33, 987,
         37, 157, 741, 284])]
     Correctly misclassified: 0
@    Batch (number 14) has ASR: 0.0
@  Batch 15
     Loss: 7.088749885559082
     True labels: tensor([832, 759, 758, 590, 685, 527, 714, 205, 974, 994, 730, 590, 782, 472,
        904, 233, 353,  61, 810, 285,  60, 758, 439,  21, 607, 257, 832, 488,
        357, 533, 455, 946])
     Predicted labels: [tensor([848, 782, 781,  63, 457, 573, 741, 283, 460, 994, 756,  63, 802, 523,
        912, 308, 416, 153, 828, 355, 157, 781, 708, 117, 645,  34, 482, 668,
         42, 579, 508, 793])]
     Correctly misclassified: 0
@    Batch (number 15) has ASR: 0.0
@  Batch 16
     Loss: 6.928588390350342
     True labels: tensor([619, 932, 619, 227, 106, 163, 652,  63, 595, 406, 335, 142, 118,  52,
        812, 990, 582, 652, 998, 428, 607, 981, 690, 437, 353, 810, 263, 448,
        994, 359, 221, 808])
     Predicted labels: [tensor([468, 938, 751, 302, 194, 223, 711, 187, 634, 414,  46, 226, 204, 145,
         83, 990, 759, 686, 998, 871, 645, 982,  72, 492, 416, 828, 335, 578,
        994, 559, 298, 826])]
     Correctly misclassified: 0
@    Batch (number 16) has ASR: 0.0
@  Batch 17
     Loss: 7.104351043701172
     True labels: tensor([995, 148, 996, 947,   3, 652, 140, 533, 663, 864, 977, 227, 546, 534,
        673, 690, 619, 820,  33, 127,  18, 714, 503, 734, 439, 892, 466, 871,
        244, 959, 932, 341])
     Predicted labels: [tensor([995, 232, 996, 951, 100, 686, 224, 579, 438, 877, 970, 300, 590,  58,
        704,  72, 656, 837, 128, 212, 114, 741, 551,  76, 442, 901, 437, 883,
        318, 962, 956, 405])]
     Correctly misclassified: 0
@    Batch (number 17) has ASR: 0.0
@  Batch 18
     Loss: 6.946361064910889
     True labels: tensor([940, 244, 437, 228, 135, 925, 941, 881, 932, 355, 211,  50, 105, 571,
        389, 730,  76, 733, 818, 451, 257, 546, 943, 601, 681,  16, 218, 752,
        972, 308, 690, 981])
     Predicted labels: [tensor([945, 318, 711, 314,  22, 931, 946, 892, 938, 418, 289, 146, 185,  21,
        449, 756, 167, 732, 835, 968,  33, 590, 948,  64, 711, 112, 244, 776,
        974, 376,  72, 857])]
     Correctly misclassified: 0
@    Batch (number 18) has ASR: 0.0
@  Batch 19
     Loss: 6.855195045471191
     True labels: tensor([372, 975, 994, 974, 262, 295, 370, 752, 314, 829,  50, 990, 940, 258,
        314, 448,  79, 372, 795,  89, 943, 530,  36, 676, 170, 832, 557, 953,
        127, 222, 436,  91])
     Predicted labels: [tensor([433, 977, 994, 976, 334, 364, 431, 776, 381, 523, 143, 990, 945, 330,
        381, 400,  17, 433, 814, 179, 470, 576, 130, 844, 251, 754,  60, 677,
        212, 792, 491, 180])]
     Correctly misclassified: 0
@    Batch (number 19) has ASR: 0.0
@  Batch 20
     Loss: 6.919547080993652
     True labels: tensor([658,  52, 834, 791, 314, 222, 378, 448, 900,   7, 521, 996, 291, 484,
        766, 179, 996, 328, 631, 244, 357, 808, 301, 983, 530, 871, 802, 980,
        958, 534, 428,  30])
     Predicted labels: [tensor([830, 145,  85, 419, 381, 299, 439, 570, 567, 163, 339, 996, 360, 534,
        789,  26, 591, 575, 400, 318,  42, 826,  37, 530, 576, 883, 820, 981,
        961, 892, 484, 125])]
     Correctly misclassified: 0
@    Batch (number 20) has ASR: 0.0
@  Batch 21
     Loss: 6.946933269500732
     True labels: tensor([466, 990, 406, 996, 676, 734, 690, 667, 520, 782, 733, 527, 106, 663,
         63, 818, 812, 816, 291, 571,  76, 972,  21, 674, 205, 314, 725, 164,
        355, 520, 515, 916])
     Predicted labels: [tensor([518, 125, 591, 996, 707,  76,  72,   7, 567, 802, 759, 573, 204, 542,
        155, 835,  83, 833, 360, 612, 167, 974, 117, 705, 283, 379, 609, 246,
        767, 567, 562, 960])]
     Correctly misclassified: 0
@    Batch (number 21) has ASR: 0.0
@  Batch 22
     Loss: 7.053366661071777
     True labels: tensor([834, 975, 582, 981,  81, 685, 427, 667, 974, 735, 291, 389, 652, 540,
        832, 733, 521, 127, 445, 714, 230, 299, 714, 904, 832, 341, 932, 109,
        595, 667, 299, 451])
     Predicted labels: [tensor([ 85, 977, 759, 982, 171, 715, 483,   7, 972, 760, 357, 449, 882, 680,
        485, 759, 861, 212,   6, 741, 300, 368, 741, 716, 482, 405, 938, 197,
        634,   8, 368, 504])]
     Correctly misclassified: 0
@    Batch (number 22) has ASR: 0.0
@  Batch 23
     Loss: 6.869091987609863
     True labels: tensor([135, 484, 250, 585, 612, 353, 314, 904, 452, 455, 163, 472, 285, 233,
        163, 353, 520,  20, 676, 980, 906, 669, 146,  60,  33, 211, 451,   3,
        170, 295, 864, 810])
     Predicted labels: [tensor([ 22, 534, 323, 625,  65, 416, 379, 716, 505, 549, 245, 523, 355, 308,
        245, 416, 828,  69, 707, 981, 914, 700,  23, 152, 128, 289, 967, 100,
        251, 364, 877, 828])]
     Correctly misclassified: 0
@    Batch (number 23) has ASR: 0.0
@  Batch 24
     Loss: 6.703886032104492
     True labels: tensor([843, 299, 445, 601, 372, 966, 939, 428, 759, 820, 179, 791, 673, 900,
        601, 718, 832, 996, 540, 696, 241, 959, 590, 221,  70, 673, 205, 335,
        299, 148, 439,  60])
     Predicted labels: [tensor([858, 368,   5,  64, 433, 969, 944, 484, 782, 836,  26, 810, 704, 909,
         64, 745, 754, 996, 585, 901, 315, 960,  63, 298, 161, 704, 549, 315,
        368, 176, 505, 152])]
     Correctly misclassified: 0
@    Batch (number 24) has ASR: 0.0
@  Batch 25
     Loss: 6.775693416595459
     True labels: tensor([995, 995, 808, 974, 142, 370, 782,  79, 690, 266, 314, 241, 146, 163,
        612, 466, 146, 370, 953, 756, 164, 452, 864, 977, 205, 816, 428, 105,
        205, 843, 585, 866])
     Predicted labels: [tensor([995, 995, 826, 972, 226, 516, 802,  17,  72, 338, 381, 315,  23, 245,
         65, 518,  23, 516, 957,  78, 246, 849, 496, 980, 283, 833, 978, 185,
        283, 425, 472, 879])]
     Correctly misclassified: 0
@    Batch (number 25) has ASR: 0.0
@  Batch 26
     Loss: 6.9464216232299805
     True labels: tensor([244, 436, 299, 466, 940, 455, 791, 766, 829, 996, 244, 958, 218, 676,
        837, 812, 940, 734, 802, 533, 258, 301, 718, 300, 221, 439, 601, 775,
        341, 218, 211, 834])
     Predicted labels: [tensor([318, 491, 368, 606, 945, 508, 508, 789, 766, 996, 318, 961, 295, 707,
        522,  83, 945,  77, 820, 401, 330,  37, 745, 369, 299, 577,  64, 559,
        980, 295, 289,  85])]
     Correctly misclassified: 0
@    Batch (number 26) has ASR: 0.0
@  Batch 27
     Loss: 7.016170024871826
     True labels: tensor([263, 980, 515, 228, 812,  16, 233,  16, 733, 437, 428, 582, 627, 228,
        816,  60, 832, 527, 998, 488, 802, 227, 812, 981, 977,  30, 185, 866,
        187, 370, 392, 218])
     Predicted labels: [tensor([335, 981, 562, 311,  83, 112, 308, 112, 759, 492, 484, 600, 884, 303,
        913, 152, 848, 621, 987, 668, 820, 302, 138, 457, 970, 125, 266, 879,
        226, 431, 451, 295])]
     Correctly misclassified: 0
@    Batch (number 27) has ASR: 0.0
@  Batch 28
     Loss: 6.7398481369018555
     True labels: tensor([534,  33, 452, 250, 916, 140, 353, 503, 582, 241, 946, 369, 546, 696,
        142, 612, 534, 521, 540, 484, 206,  52, 484, 228, 947, 285,   3, 939,
        530, 810, 439])
     Predicted labels: [tensor([ 58, 128, 505, 323, 923, 199, 416, 629, 438, 315, 950, 430, 782, 725,
        226,  58,  58, 568, 902, 534, 284, 145, 534, 303, 951, 355, 100, 944,
        576, 828, 494])]
     Correctly misclassified: 0
@    Batch (number 28) has ASR: 0.0
@  Batch 29
     Loss: 6.808648109436035
     True labels: tensor([775, 810, 925, 966, 244, 620, 837, 284, 521, 943, 533, 328, 389, 601,
        454, 866, 812,  33, 990, 533, 451, 455, 472, 227, 958, 257, 685, 906,
        946, 631, 871])
     Predicted labels: [tensor([530, 828, 931, 969, 318, 744, 852, 354, 568, 948, 579, 977, 449,  64,
        507, 879,  83, 128, 990, 579, 968, 508, 842, 302, 961,  33, 715, 914,
        584, 400, 883])]
     Correctly misclassified: 0
@    Batch (number 29) has ASR: 0.0
@  Batch 30
     Loss: 6.927688121795654
     True labels: tensor([663, 756, 667, 571, 140, 244, 109, 946, 756, 479, 179, 820, 389, 474,
        392, 557, 966, 308, 241, 428, 981, 906, 258,  16, 392, 163, 795, 940,
        812, 791,  23])
     Predicted labels: [tensor([696,  78,   7, 612, 224, 318, 197, 588,  78,  53,  26, 782, 449, 525,
        451,  60, 969, 376, 315, 871, 578, 914, 330, 112, 451, 245, 625, 945,
         83, 508, 120])]
     Correctly misclassified: 0
@    Batch (number 30) has ASR: 0.0
@  Batch 31
     Loss: 6.872225284576416
     True labels: tensor([359, 187, 357, 513, 428, 904, 530, 864, 521, 335, 266, 341, 230, 808,
        369, 714, 881, 533, 228, 222, 795, 681, 106, 595, 900, 299, 972, 211,
        932, 285, 250, 612])
     Predicted labels: [tensor([421, 267,  42, 560, 437, 912, 576, 877, 824,  40, 338, 405, 305, 826,
        430, 741, 892, 579, 303, 299, 814, 631, 190, 634, 909, 368, 974, 289,
        938, 355, 323,  65])]
     Correctly misclassified: 0
@    Batch (number 31) has ASR: 0.0
@  Batch 32
     Loss: 7.043393135070801
     True labels: tensor([995, 906, 725, 308, 980, 946, 530, 513,  52, 164, 590, 164, 135, 454,
        406, 445, 448, 357, 479, 105, 730, 205, 146,  81, 322, 427, 308, 818,
         36, 109, 142, 257])
     Predicted labels: [tensor([995, 914, 751, 376, 981, 950, 576, 560, 145, 246,  63, 246,  22, 714,
        464,   6, 501,  42,  53, 193, 412, 283,  21, 171, 389, 433, 376, 807,
        130, 233, 226,  34])]
     Correctly misclassified: 0
@    Batch (number 32) has ASR: 0.0
@  Batch 33
     Loss: 6.702739715576172
     True labels: tensor([146, 766, 612, 227, 627, 406, 881, 862, 179, 696, 832,  33, 503, 118,
        546, 448, 601, 378, 389, 959, 829, 837, 400, 730, 582, 317,  52, 843,
         23, 187, 953, 595])
     Predicted labels: [tensor([ 21, 789,  65, 302, 698, 464, 892, 476,  26, 725, 482, 128, 551, 185,
        605, 578,  64, 439, 693, 962, 845, 852, 459, 756, 447, 384, 145, 858,
        119, 265, 957, 634])]
     Correctly misclassified: 0
@    Batch (number 33) has ASR: 0.0
@  Batch 34
     Loss: 7.018054008483887
     True labels: tensor([ 61, 118, 250, 601, 607, 369, 250, 871, 484, 734, 109, 864, 400, 802,
         20, 758, 816, 735, 370, 372, 730, 994, 118, 734, 571, 980, 759, 752,
        782, 669, 620, 998])
     Predicted labels: [tensor([153, 204, 323,  64, 645, 430, 323, 883, 534,  76, 197, 877, 445, 820,
        116, 530, 833, 760, 431, 433, 756, 994, 263,  76, 612, 981, 782, 776,
        802, 804, 895, 987])]
     Correctly misclassified: 0
@    Batch (number 34) has ASR: 0.0
@  Batch 35
     Loss: 6.594079971313477
     True labels: tensor([185, 546, 658, 227, 974, 966, 369, 904, 998, 959, 479,  89, 972,  52,
        612, 766, 734, 802, 866, 357, 140,  36, 328, 179, 758, 571, 206, 758,
        406, 947, 448])
     Predicted labels: [tensor([265, 487, 712, 300, 970, 969, 430, 912, 998, 935,  53, 179, 974, 145,
         65, 789,  76, 820, 879,  42, 224, 130, 394,  26, 781, 612, 284, 781,
        464, 951, 601])]
     Correctly misclassified: 0
@    Batch (number 35) has ASR: 0.0
@  Batch 36
     Loss: 6.936168670654297
     True labels: tensor([681, 105, 756, 146, 631, 451, 834, 941, 958,  89, 530, 619,  81, 667,
        932, 663, 631, 218, 534,  63, 221, 257, 322, 818, 557,  91, 312, 357,
        185, 734,  89,  50])
     Predicted labels: [tensor([711, 186,  78, 128, 667, 967,  85, 946, 647, 180, 576, 734, 171,   7,
        938, 462, 400, 295,  58, 204, 299,  33, 389, 835,  60, 173,  38,  42,
        265,  76, 179, 143])]
     Correctly misclassified: 0
@    Batch (number 36) has ASR: 0.0
@  Batch 37
     Loss: 6.891360282897949
     True labels: tensor([312, 372, 185, 916, 540, 735,  20, 681, 540,  81, 674,  20, 812, 939,
        527, 515,  50, 142, 972, 685, 620, 802, 513, 994, 775, 892, 837, 389,
        262, 257,  79, 829])
     Predicted labels: [tensor([ 38, 433, 266, 959, 585, 760, 116, 711, 585, 171, 705, 116,  83, 944,
        573, 562, 143, 207, 974, 715, 744, 820, 560, 994, 797, 631, 752,  21,
        334,  36,  17, 845])]
     Correctly misclassified: 0
@    Batch (number 37) has ASR: 0.0
@  Batch 38
     Loss: 6.767348289489746
     True labels: tensor([735,  60, 262,  89, 445, 308, 941,   3, 291, 221, 250, 669, 317, 557,
         21,   7, 285, 170, 266, 527, 980, 445, 986, 612, 218, 585, 357, 892,
        312, 400, 206, 135])
     Predicted labels: [tensor([760, 152, 334, 179, 115, 376, 946, 100, 360, 298, 323, 700, 384,  60,
        117, 104, 355, 251, 338, 573, 981, 178, 998,  65, 295, 625,  42, 504,
         38, 445, 284,  22])]
     Correctly misclassified: 0
@    Batch (number 38) has ASR: 0.0
@  Batch 39
     Loss: 6.902853012084961
     True labels: tensor([ 23, 127, 866, 257, 837, 135,  23, 163, 118,  18, 301, 241, 735, 140,
        436, 977, 479, 170, 690, 448, 359, 540, 947, 222, 427, 585, 802, 925,
        317, 437, 228, 953])
     Predicted labels: [tensor([120, 212, 879,  33, 752,  22, 119, 245, 155, 114,  37, 315, 651, 224,
        683, 970,  52, 212,  72, 869, 564, 585, 951, 383, 483, 625, 820, 931,
        384, 492, 303, 957])]
     Correctly misclassified: 0
@    Batch (number 39) has ASR: 0.0
@  Batch 40
     Loss: 6.806139945983887
     True labels: tensor([291, 428, 437,  52, 148, 295,  52, 314, 947, 378, 312, 582, 179, 953,
        359, 837, 932, 466, 571, 995, 400, 974, 947, 939, 953, 258, 674, 730,
        392, 534,  16])
     Predicted labels: [tensor([360, 484, 492, 145, 232, 794, 145, 381, 951, 439,  38, 622,  26, 957,
        421, 752, 938, 113, 612, 995, 747, 530, 951, 944, 957, 330, 705, 756,
        451, 499, 112])]
     Correctly misclassified: 0
@    Batch (number 40) has ASR: 0.0
@  Batch 41
     Loss: 6.910076141357422
     True labels: tensor([218, 472, 939, 995, 735, 994, 759,  79, 454, 546,  76, 106, 378, 312,
        185, 378,  16, 105, 369, 627, 906, 619, 733,  91, 932, 372, 947, 300,
        142, 300, 557, 658])
     Predicted labels: [tensor([295, 523, 944, 995, 760, 994, 851,  17, 507, 487, 167, 193, 439,  38,
        266, 870, 112, 182, 430, 497, 914, 656, 593, 179, 938, 433, 951, 381,
        226, 369,  60, 691])]
     Correctly misclassified: 0
@    Batch (number 41) has ASR: 0.0
@  Batch 42
     Loss: 6.907125949859619
     True labels: tensor([317, 607, 607, 406, 725, 140, 864, 862, 474,  79, 862, 885, 285,  79,
         23, 135, 996, 227, 285, 378, 211, 843,  30, 983, 571, 775, 690, 975,
        300, 885, 439])
     Predicted labels: [tensor([384, 645, 645, 712, 751, 224, 877, 875, 525,  14, 875, 861, 355,  17,
        118,  22, 996, 302, 355, 439, 289, 858, 118, 984, 612, 797,  72, 354,
        369, 435, 577])]
     Correctly misclassified: 0
@    Batch (number 42) has ASR: 0.0
@  Batch 43
     Loss: 6.692836284637451
     True labels: tensor([437, 959,  30, 990, 959, 925, 986, 322, 369, 972, 652, 725,  76,   7,
        436, 452, 451, 118, 676, 540, 983, 179, 791, 866, 250, 906, 378, 301,
        733,   7, 206])
     Predicted labels: [tensor([492, 962, 125, 990, 962, 930, 987, 591, 430, 974, 534, 751, 167, 104,
        401, 968, 504, 160, 707, 804, 984,  26, 508, 701, 323, 914, 439,  37,
        759, 104, 333])]
     Correctly misclassified: 0
@    Batch (number 43) has ASR: 0.0
@  Batch 44
     Loss: 6.838985443115234
     True labels: tensor([916,  79, 943, 328, 521, 906, 946, 291, 810, 601, 353, 262, 940, 995,
        864, 843, 142, 782, 975, 266, 513,  81,  20, 106,  89, 818,  81, 990,
        135, 866, 106, 685])
     Predicted labels: [tensor([924,  17, 948, 394, 568, 780, 696, 360, 828,  55, 416, 334, 943, 995,
        877, 663, 160, 802, 977, 338, 560, 172, 116, 190, 180, 835, 171, 990,
         22, 467, 194, 715])]
     Correctly misclassified: 0
@    Batch (number 44) has ASR: 0.0
@  Batch 45
     Loss: 7.013741970062256
     True labels: tensor([758, 820, 546, 916, 943, 601, 439, 521, 904, 488, 981,  61, 766, 735,
        451, 959, 285, 975, 808, 590, 142, 448,  50, 669, 829, 866, 775, 262,
        520, 995,  16,  36])
     Predicted labels: [tensor([781, 836, 699, 969, 948,  64, 494, 568, 912, 538, 982, 153, 789, 760,
        967, 962, 355, 530, 826,  63, 200, 887, 143, 588, 641, 701, 797, 334,
        567, 995, 112, 130])]
     Correctly misclassified: 0
@    Batch (number 45) has ASR: 0.0
@  Batch 46
     Loss: 6.751049995422363
     True labels: tensor([892, 127, 829, 452, 515, 540, 230, 816, 782, 966, 118, 127, 445, 812,
        520, 439, 534, 595, 400, 472, 775, 953, 816, 300, 534, 758, 135, 990,
        974, 966, 676, 673])
     Predicted labels: [tensor([901, 212, 499, 966, 562, 450, 305, 833, 802, 969, 155, 212, 329,  83,
        567, 524,  21, 596, 459, 433, 797, 957, 833, 369,  58, 781,  22, 990,
        976, 969, 707, 704])]
     Correctly misclassified: 0
@    Batch (number 46) has ASR: 0.0
@  Batch 47
     Loss: 6.894057273864746
     True labels: tensor([ 50, 258, 958, 436, 946,   3, 300, 730, 631, 164, 802, 782, 663, 520,
        205, 164, 981, 990, 718, 631, 206, 775, 211, 595, 205, 631, 400,  20,
        228, 503, 142, 696])
     Predicted labels: [tensor([143, 330, 930, 491, 868, 100, 369, 603, 667, 246, 820, 802, 462, 567,
        283, 246, 530, 990, 745, 667, 284, 731, 289, 979, 283, 667, 842, 116,
        304, 551, 226, 725])]
     Correctly misclassified: 0
@    Batch (number 47) has ASR: 0.0
@  Batch 48
     Loss: 7.111967086791992
     True labels: tensor([ 63, 975, 892, 718,  61, 427,  20, 829, 885, 241, 959,  70, 816, 652,
        230, 335, 355, 105,  60, 885, 372, 170, 540, 301,  63, 488, 590, 284,
          3,  30, 791, 527])
     Predicted labels: [tensor([204, 672, 901, 745, 203, 483, 116, 719, 470, 315, 962, 161, 833, 686,
        305,  40, 418, 186, 152, 896, 793, 251, 930,  37, 155, 538,  63, 354,
        100, 125, 810, 573])]
     Correctly misclassified: 0
@    Batch (number 48) has ASR: 0.0
@  Batch 49
     Loss: 6.611880302429199
     True labels: tensor([503, 881, 445, 170, 766, 106, 673, 266, 515, 681, 998, 428, 301, 585,
        685, 714, 109, 230, 299,   3, 595,  50,  76, 353, 977, 730, 925, 725,
        140, 975, 263, 109])
     Predicted labels: [tensor([631, 892, 306, 251, 789, 194, 704, 333, 469, 418, 998, 536,  36, 625,
        715, 741, 183, 305, 368, 100, 634, 143, 167, 416, 972, 756, 931, 751,
        224, 977, 335, 530])]
     Correctly misclassified: 0
@    Batch (number 49) has ASR: 0.0
@  Batch 50
     Loss: 6.854151725769043
     True labels: tensor([222, 105, 472,   7, 370, 530, 881, 756, 759, 266, 295, 428, 663, 601,
         21, 164, 291, 966, 392, 881, 250,  91, 557, 372, 696, 369, 179, 986,
        730, 233, 685, 885])
     Predicted labels: [tensor([299, 182, 523, 352, 431, 576, 892,  78, 782, 338, 364, 554, 696,  64,
        117, 246, 360, 969, 451, 892, 323, 179,  60, 433, 725, 430,  26, 998,
        756, 308, 715, 897])]
     Correctly misclassified: 0
@    Batch (number 50) has ASR: 0.0
@  Batch 51
     Loss: 6.865335941314697
     True labels: tensor([862, 607, 127, 308, 527, 146, 355, 187, 946, 994, 187, 317, 222, 266,
        941, 669, 674,  16, 513, 118, 258, 515, 406, 696, 885, 455, 263, 227,
        244, 258, 148, 148])
     Predicted labels: [tensor([875, 645, 212, 373, 573,  23, 477, 267, 588, 994, 267, 384, 299, 338,
        946, 999, 705, 112, 560, 155, 330, 562, 464, 530, 896, 508, 335, 302,
        318, 330, 158, 281])]
     Correctly misclassified: 0
@    Batch (number 51) has ASR: 0.0
@  Batch 52
     Loss: 6.657855987548828
     True labels: tensor([ 81, 820, 359, 439, 109, 619, 925, 941, 791, 474, 503, 328,  20,  70,
        977,  70, 484, 170, 681, 211, 994, 291, 230, 983, 862, 479, 301, 752,
        735, 802,  89, 436])
     Predicted labels: [tensor([178, 669, 421, 861, 197, 436, 931, 946, 508, 554, 551, 394, 116, 161,
        863, 161, 534, 251, 711, 289, 994, 530, 305, 984, 875,  53,  37, 776,
        651, 820, 179, 491])]
     Correctly misclassified: 0
@    Batch (number 52) has ASR: 0.0
@  Batch 53
     Loss: 6.713580131530762
     True labels: tensor([187, 205, 521, 244, 164,  70, 631, 994, 862, 658, 295,  76, 953, 515,
        980, 328, 802,  30, 977, 658, 734, 810, 445, 105, 233, 946, 503, 752,
        627, 295, 752, 940])
     Predicted labels: [tensor([266, 283, 568, 318, 246, 161, 667, 994, 875, 719, 364, 167, 957, 562,
        981,  26, 820, 125, 970, 691,  76, 828,   5, 193, 308, 951, 551, 776,
        663, 364, 582, 945])]
     Correctly misclassified: 0
@    Batch (number 53) has ASR: 0.0
@  Batch 54
     Loss: 7.131219387054443
     True labels: tensor([986, 972, 995, 474, 488, 756,  89, 479, 658, 714, 230, 619, 820, 782,
        974, 484, 834, 996, 571, 766,  23, 667,  89, 392, 436,  18,  50, 228,
        795, 676, 892, 455])
     Predicted labels: [tensor([987, 974, 995, 530, 557,  78, 159,  53, 691, 741, 305, 656, 837, 795,
        976, 534,  86, 996, 450, 789, 119,   7, 179, 894, 491, 114, 143, 303,
        814, 707, 849, 681])]
     Correctly misclassified: 0
@    Batch (number 54) has ASR: 0.0
@  Batch 55
     Loss: 6.868222713470459
     True labels: tensor([ 21, 317, 696, 520, 663, 109, 906, 990, 557, 837,  91,  70, 607, 673,
        791, 892, 900, 620, 370,  36, 300, 406, 674, 696, 834, 631, 341, 474,
        690, 816, 437, 983])
     Predicted labels: [tensor([117, 384, 725, 469, 696, 197, 780, 990,  60, 852, 180, 156, 914, 704,
        620, 901, 544, 657, 431, 130, 369, 818, 705, 725,  85, 400, 405, 525,
         72, 833, 492, 984])]
     Correctly misclassified: 0
@    Batch (number 55) has ASR: 0.0
@  Batch 56
     Loss: 6.684330940246582
     True labels: tensor([986, 674, 241, 943, 904, 725, 359, 619, 378, 759,  18, 958, 673,  16,
        590, 958, 221,  63, 221, 881,  61, 322, 782, 258, 730, 436, 474, 392,
        187, 795,  70, 359])
     Predicted labels: [tensor([415, 705, 315, 948, 912, 751, 520, 656, 439, 851, 114, 961, 704, 112,
         63, 868, 298, 155, 298, 892, 153, 389, 802, 330, 756, 488, 525, 451,
        265, 814, 161, 421])]
     Correctly misclassified: 0
@    Batch (number 56) has ASR: 0.0
@  Batch 57
     Loss: 6.838028430938721
     True labels: tensor([ 30, 759, 990, 427, 829, 488,  18, 335, 439,  18, 488, 322, 557, 328,
        932,  18, 582, 834, 612, 733, 546, 925,  33, 164, 513, 262, 620,  76,
        437, 735])
     Predicted labels: [tensor([125, 782, 990, 562, 845, 668, 114,  46, 577, 114, 577, 389,  60, 394,
        938, 114, 622,  85,  65, 759, 838, 931, 128, 794, 560, 334, 744, 176,
        492, 760])]
     Correctly misclassified: 0
@    Batch (number 57) has ASR: 0.0
@  Batch 58
     Loss: 6.8033294677734375
     True labels: tensor([ 33, 980, 170, 530, 834, 885, 974, 285, 816, 211, 752, 690,   7, 389,
        355, 263, 451, 916, 244, 900, 436, 353, 818, 170, 820, 669, 436, 312,
        696, 258, 620, 795])
     Predicted labels: [tensor([128, 981, 251, 576,  82, 896, 976, 355, 833, 289, 776,  72, 291, 449,
        777, 335, 967, 923, 318, 909, 491, 416, 835, 251, 836, 999, 491,  38,
        725, 330, 744, 814])]
     Correctly misclassified: 0
@    Batch (number 58) has ASR: 0.0
@  Batch 59
     Loss: 6.875131607055664
     True labels: tensor([766, 725, 400, 998, 595, 355,  81, 943, 669, 515, 308, 685, 206, 472,
        812, 484, 795, 488, 454, 105, 454, 652, 714, 975,  21, 986, 355, 241,
        775,  89, 939, 983])
     Predicted labels: [tensor([789, 751, 459, 998, 634, 418, 172, 948, 999, 974, 376, 715, 284, 400,
         83, 534, 460, 668, 507, 187, 507, 686, 741, 977, 117, 987, 418, 315,
        414, 180, 944, 984])]
     Correctly misclassified: 0
@    Batch (number 59) has ASR: 0.0
@  Batch 60
     Loss: 6.691705703735352
     True labels: tensor([837, 795, 314, 674,  21,  36, 317, 946, 983, 520, 585, 109, 284, 341,
        369, 222, 756, 533, 427, 284, 808,   3, 185, 986, 843, 479, 369, 185,
        585, 834, 758,   7])
     Predicted labels: [tensor([752, 814, 381, 705, 117, 130, 384, 950, 984, 567, 625, 197, 354, 405,
        430, 299,  78, 579, 483, 354, 826, 100, 266, 987, 425,  52, 430, 265,
        625,  85, 781, 104])]
     Correctly misclassified: 0
@    Batch (number 60) has ASR: 0.0
@  Batch 61
     Loss: 6.902119159698486
     True labels: tensor([266, 400, 228, 998, 392, 925, 864, 452,  63, 263, 766, 322, 484, 718,
        146, 862, 941, 932, 266, 300, 627, 734, 667, 530, 437, 328, 725, 241,
        974, 966, 295, 146])
     Predicted labels: [tensor([338, 434, 303, 998, 451, 931, 877, 505, 155, 335, 789, 389, 534, 745,
         23, 875, 946, 938, 333, 369, 406,  76,   8, 576, 492, 394, 751, 315,
        976, 969, 364,  23])]
     Correctly misclassified: 0
@    Batch (number 61) has ASR: 0.0
@  Batch 62
     Loss: 6.788692474365234
     True labels: tensor([206, 227,  33, 681, 406, 696, 262, 211, 832, 263, 612, 400, 791, 983,
        335, 322, 359, 221, 756, 718, 862, 389,  70, 400, 943, 359, 941, 958,
         20, 669, 262, 652])
     Predicted labels: [tensor([284, 302, 128, 966, 711, 725, 334, 289, 482, 335,  65, 921, 810, 984,
         47,  30, 783, 298,  78, 786, 875, 449, 163, 459, 948, 421, 946, 961,
        116, 577, 334, 783])]
     Correctly misclassified: 0
@    Batch (number 62) has ASR: 0.0
@  Batch 63
     Loss: 6.795281410217285
     True labels: tensor([595, 299, 503, 258, 972, 284, 864, 370, 452, 966, 355, 533,   7, 658,
         50, 607])
     Predicted labels: [tensor([730, 368, 551, 330, 974, 354, 877, 530, 898, 969, 418, 579, 104, 691,
        143, 645])]
     Correctly misclassified: 0
@    Batch (number 63) has ASR: 0.0
Epoch [1/2], Loss: 6.795281410217285, Avg ASR: 0.00%
  > Saved generator at epoch 1 to /scratch.ssd/takonoselidze/job_8178938.pbs-m1.metacentrum.cz/checkpoints/generator_epoch_1_target_949.pth
@ Epoch 2 for a target class: 949
@  Batch 1
     Loss: 6.780496597290039
     True labels: tensor([733,  23, 546,  76,  16, 341, 105, 881,  21, 353, 205, 378, 834,  70,
        355, 980, 585, 353, 258, 959, 521, 941, 520, 221, 756, 370, 981, 834,
         16, 241, 515])
     Predicted labels: [tensor([759, 120, 782, 167, 549,  51, 193, 892, 117, 416, 283, 439,  85, 161,
        418, 429, 625, 416, 330, 962, 568, 946, 752, 298,  78, 745, 982,  85,
        112, 315, 562])]
     Correctly misclassified: 0
@    Batch (number 1) has ASR: 0.0
@  Batch 2
     Loss: 6.793532371520996
     True labels: tensor([ 36, 631, 466, 428, 832, 452,  76, 187, 816, 540, 300, 843, 257, 222,
        980, 455, 359, 681, 974, 900, 257, 795, 995, 257, 484, 439, 448,   7,
        881, 916, 585, 300])
     Predicted labels: [tensor([130, 400, 518, 871, 482, 737, 161, 265, 833, 680, 369, 530,  33, 299,
        981, 508, 520, 438, 976, 567,  33, 814, 995,  34, 534, 577, 887, 104,
        892, 923, 625, 369])]
     Correctly misclassified: 0
@    Batch (number 2) has ASR: 0.0
@  Batch 3
     Loss: 6.90623664855957
     True labels: tensor([187, 300, 791, 582, 466, 862, 843, 759, 241, 521, 892, 291,  63, 667,
         91, 631, 916, 127,  30, 829,  60,  63, 135, 864, 808, 427, 262, 164,
         61, 571, 557, 406])
     Predicted labels: [tensor([256, 369, 810, 622, 113, 875, 698, 851, 315, 339, 901, 360, 155,   7,
        180, 400, 818, 212, 125, 845, 152, 204,  22, 877, 826, 460, 334, 246,
        153, 612,  60, 591])]
     Correctly misclassified: 0
@    Batch (number 3) has ASR: 0.0
@  Batch 4
     Loss: 6.649686813354492
     True labels: tensor([389, 775, 906, 244, 452, 266, 135, 932,  21, 619, 862, 995, 540, 140,
        527, 466, 359, 370, 218, 299, 300, 257, 341, 904, 714, 832, 488,  79,
        752, 808, 881, 454])
     Predicted labels: [tensor([449, 797, 914, 318, 968, 333,  22, 938, 117, 468, 875, 995, 585, 205,
        573, 437, 421, 431, 295, 368, 369,  33,   6, 549, 741, 482, 668,  17,
        776, 630, 892, 714])]
     Correctly misclassified: 0
@    Batch (number 4) has ASR: 0.0
@  Batch 5
     Loss: 6.816843509674072
     True labels: tensor([862, 966, 658, 601, 370, 756, 941, 829, 685, 140, 185, 975, 996, 943,
        359,  50, 696, 357, 690, 258,  89, 230, 372, 906,  23, 437, 439, 406,
        725,  23,  70,  18])
     Predicted labels: [tensor([875, 969, 413,  64, 783,  78, 946, 845, 715, 224, 265, 354, 996, 948,
        421, 530, 530,  14,  72, 330, 180, 305, 643, 914, 116, 492, 577, 710,
        751, 119, 161, 114])]
     Correctly misclassified: 0
@    Batch (number 5) has ASR: 0.0
@  Batch 6
     Loss: 6.700970649719238
     True labels: tensor([795, 820, 317, 837, 810, 109, 775, 127, 427, 735,  61, 940, 837, 595,
         50, 802, 862, 328, 445, 685, 730, 317, 164,   7, 479, 925, 676, 258,
        782, 916, 557, 148])
     Predicted labels: [tensor([814, 837, 384, 852, 828, 197, 797, 212, 663, 760, 530, 945, 852, 913,
        143, 820, 875, 394,   6, 715, 756, 384, 246, 104,  52, 931, 707, 330,
        802, 923,  60, 281])]
     Correctly misclassified: 0
@    Batch (number 6) has ASR: 0.0
@  Batch 7
     Loss: 6.889521598815918
     True labels: tensor([900, 295, 148, 904, 355, 981, 170, 454, 943, 454, 314, 995, 503, 211,
        452, 832, 601, 866, 241, 759, 472, 222,  61, 206, 439, 527, 983, 791,
        221, 227, 782, 263])
     Predicted labels: [tensor([463, 364, 158, 912, 418, 683, 251, 507, 948, 507, 379, 995, 551, 289,
        441, 732,  64, 879, 315, 782, 523, 299, 153, 284, 577, 573, 984, 620,
        274, 302, 802, 335])]
     Correctly misclassified: 0
@    Batch (number 7) has ASR: 0.0
@  Batch 8
     Loss: 6.835511684417725
     True labels: tensor([ 50, 118, 520, 669,  60, 820, 146, 262, 370, 996,  81, 233, 451, 652,
        106, 667, 766, 663, 832, 958,  21, 758, 520, 164, 986, 148, 607, 981,
        263, 975, 488])
     Predicted labels: [tensor([143, 155, 582, 700, 152, 861,  23, 334, 861, 996, 171, 308, 504, 686,
        194,   7, 789, 696, 481, 961, 117, 781, 567, 246, 998, 232, 914, 530,
        335, 977, 668])]
     Correctly misclassified: 0
@    Batch (number 8) has ASR: 0.0
@  Batch 9
     Loss: 6.882963180541992
     True labels: tensor([881, 663, 795,  36,  76,  61, 766, 142, 355, 652, 488,  60, 829, 590,
        378, 179, 947, 904, 832, 810, 864, 871, 353,  63, 862, 986,  20, 690,
        400, 904, 314, 734])
     Predicted labels: [tensor([892, 910, 814, 130, 173, 153, 789, 266, 696, 882, 538, 152, 845,  63,
        439,  26, 951, 489, 848, 828, 877, 883, 416, 187, 476, 509, 116,  72,
        587,  78, 381,  76])]
     Correctly misclassified: 0
@    Batch (number 9) has ASR: 0.0
@  Batch 10
     Loss: 6.668666362762451
     True labels: tensor([533,  33, 328, 513, 932, 820, 959, 791, 106,  91, 530,  23, 359, 250,
        369, 322, 530, 759, 866, 284, 994, 959, 530, 871, 533, 981,  61, 428,
        627,  33, 370])
     Predicted labels: [tensor([579, 128, 394, 560, 938, 617, 962, 508, 194, 180, 576,  78, 421, 323,
        430, 389, 576, 782, 879, 354, 994, 962, 576, 883, 579, 680, 153, 437,
        497, 128, 516])]
     Correctly misclassified: 0
@    Batch (number 10) has ASR: 0.0
@  Batch 11
     Loss: 6.946965217590332
     True labels: tensor([871, 513, 837, 530,  61, 690, 669, 658, 885, 455, 983, 322, 163, 620,
        802, 146, 582, 756, 818, 206, 284, 372,  70, 127, 241, 118, 284, 590,
        983, 148, 966, 782])
     Predicted labels: [tensor([883, 560, 752, 576, 153,  72, 804, 830, 897, 681, 984, 389, 245, 862,
        820,  23, 872,  78, 835, 332, 354, 433, 161, 212, 315, 155, 354,  63,
        984, 232, 969, 802])]
     Correctly misclassified: 0
@    Batch (number 11) has ASR: 0.0
@  Batch 12
     Loss: 6.7719573974609375
     True labels: tensor([513, 437, 164,  81, 221, 816, 312, 766, 775, 341, 756, 802,  21, 766,
        353, 140, 218, 674, 730, 534, 503, 808, 940, 974, 142, 301, 206, 520,
        685, 996, 436,  89])
     Predicted labels: [tensor([560, 492, 246, 171, 298, 833,  31, 789, 797, 549,  78, 820, 117, 789,
        416, 256, 295, 530, 756,  58, 551, 826, 945, 976, 226,  37, 284, 567,
        715, 996, 491, 179])]
     Correctly misclassified: 0
@    Batch (number 12) has ASR: 0.0
@  Batch 13
     Loss: 6.804759502410889
     True labels: tensor([676, 146, 735, 932, 301, 696, 448, 782,  60, 818, 725, 534, 455, 582,
        503, 179, 986, 291, 766, 218,   3, 230, 674, 714, 521, 714, 241, 284,
        300, 527, 958])
     Predicted labels: [tensor([707, 128, 651, 938,  37, 899, 869, 802, 152, 835, 751,  58, 681, 759,
        551,  26, 998, 360, 789, 295, 100, 305, 547, 741, 568, 741, 315, 354,
        369, 573, 961])]
     Correctly misclassified: 0
@    Batch (number 13) has ASR: 0.0
@  Batch 14
     Loss: 6.711972236633301
     True labels: tensor([981, 925, 756, 146, 187, 291, 990, 285, 533, 359, 484, 105, 474, 233,
        479,  20, 285, 730, 540, 142, 607, 466, 766,  61, 667, 515, 472, 714,
        392, 484, 353, 981])
     Predicted labels: [tensor([982, 931,  78,  23, 267, 360, 990, 355, 579, 421, 534, 182, 525, 308,
         53, 116, 355, 875, 902, 226, 645, 518, 789, 203,   7, 562, 523, 588,
        451, 534, 416, 982])]
     Correctly misclassified: 0
@    Batch (number 14) has ASR: 0.0
@  Batch 15
     Loss: 6.547763824462891
     True labels: tensor([696, 163, 140,   7, 308, 627, 685, 685, 520, 135, 474, 766, 266, 612,
         33, 802, 250, 488, 980,  89, 466, 187,  33, 998, 300, 284, 734, 953,
        631, 206, 521, 439])
     Predicted labels: [tensor([725, 245, 224, 104, 376, 406, 715, 652, 567,  22, 976, 789, 338,  65,
        128, 820, 323, 538, 981, 179, 518, 355, 128, 998, 369, 354,  76, 957,
        667, 284, 339, 494])]
     Correctly misclassified: 0
@    Batch (number 15) has ASR: 0.0
@  Batch 16
     Loss: 7.005362033843994
     True labels: tensor([808, 448, 308, 734, 795, 977, 986, 557, 906, 735, 582, 179, 179, 312,
        607, 317,   3, 437, 299, 972, 263, 357, 981, 977, 756, 205, 170, 233,
        725, 233, 530])
     Predicted labels: [tensor([826, 689, 376,  76, 530, 649, 987,  60, 914, 760, 622,  26,  26,  38,
        645, 384, 100, 711, 368, 974, 274,  42, 982, 483,  78, 283, 172, 308,
        609, 308, 576])]
     Correctly misclassified: 0
@    Batch (number 16) has ASR: 0.0
@  Batch 17
     Loss: 6.960137367248535
     True labels: tensor([250,   3, 620, 714, 590, 974, 301,  16, 808, 595, 885, 227, 998, 810,
        445, 974, 959, 947, 995, 228,  36, 658,  18, 466,  81, 428,  60, 756,
        164, 983, 546,  60])
     Predicted labels: [tensor([323, 100, 744, 741,  63, 976,  37, 112, 826, 730, 896, 307, 987, 925,
        530, 825, 962, 951, 995, 304, 130, 691, 114, 670, 172, 871, 152,  78,
        198, 984, 487, 530])]
     Correctly misclassified: 0
@    Batch (number 17) has ASR: 0.0
@  Batch 18
     Loss: 6.6789870262146
     True labels: tensor([428, 445, 892, 262, 595, 620, 299,  30, 451, 983, 953, 718, 546, 571,
        981, 436, 818, 389, 601, 291, 975, 795, 540, 946, 947, 812, 947, 317,
        301, 612,  60,   7])
     Predicted labels: [tensor([484,   5, 907, 334, 634, 744, 368, 125, 967, 984, 957,  21, 590, 612,
        578, 491, 835, 449,  55, 111, 977, 814, 585, 696, 951,  83, 955, 384,
         37,  65, 157, 104])]
     Correctly misclassified: 0
@    Batch (number 18) has ASR: 0.0
@  Batch 19
     Loss: 6.612956523895264
     True labels: tensor([730,  70, 696, 370, 228, 690, 733,  33, 733, 291, 233, 369, 674, 939,
        673, 681, 810, 652,  79, 818, 187,  91,  63, 105, 341, 211, 590, 866,
        218, 557, 428])
     Predicted labels: [tensor([756, 161, 725, 431, 311,  72, 759, 128, 759, 337, 308, 430, 705, 944,
        704, 711, 828, 686,  17, 835, 267, 180, 204, 193, 405, 289,  63, 879,
        295,  60, 536])]
     Correctly misclassified: 0
@    Batch (number 19) has ASR: 0.0
@  Batch 20
     Loss: 6.872241020202637
     True labels: tensor([ 23, 355, 900, 946, 696, 258, 972, 312, 428, 585, 998, 892, 663, 187,
        994, 906, 515, 631, 620, 990, 674,  76,  76, 810, 105, 454, 733, 185,
        939, 983, 885, 953])
     Predicted labels: [tensor([119, 418, 567, 950, 725, 330, 974,  38, 484, 625, 998, 504, 794, 267,
        994, 914, 562, 400, 895, 990, 705, 176, 167, 828, 187, 507, 759, 267,
        944, 984, 861, 957])]
     Correctly misclassified: 0
@    Batch (number 20) has ASR: 0.0
@  Batch 21
     Loss: 7.016874313354492
     True labels: tensor([681, 685, 995, 427, 939, 328, 218, 244, 941,  50, 451, 527, 445, 759,
        900, 484, 540, 571, 900, 244, 571, 974, 540, 521, 314, 142, 557, 221,
        892, 881, 257, 527])
     Predicted labels: [tensor([711, 715, 995, 483, 944, 344, 295, 318, 946, 143, 504, 573,   6, 851,
        567, 534, 585, 612, 774, 318, 612, 972, 804, 850, 381, 202,  60, 298,
        901, 409,  33, 573])]
     Correctly misclassified: 0
@    Batch (number 21) has ASR: 0.0
@  Batch 22
     Loss: 6.619992256164551
     True labels: tensor([725, 148, 718, 513, 263, 663, 406, 533, 244, 222, 983, 958, 627, 995,
        328, 975, 953, 990,  36, 389, 530, 983, 439, 733, 939, 972, 977, 118,
         79, 241, 445, 335])
     Predicted labels: [tensor([751, 176, 745, 560, 335, 462, 712, 579, 318, 276, 984, 930, 698, 995,
        575, 977, 957, 990, 130, 472, 576, 984, 505, 759, 944, 974, 970, 202,
         17, 315, 115,  40])]
     Correctly misclassified: 0
@    Batch (number 22) has ASR: 0.0
@  Batch 23
     Loss: 6.90449333190918
     True labels: tensor([357, 994, 674, 322, 228, 284, 685, 163, 690, 312, 977, 758, 733, 669,
        521, 328, 520, 448, 892, 756, 946, 445,  33, 314, 466,  79, 673, 370,
        314, 285, 627, 834])
     Predicted labels: [tensor([ 42, 994, 705, 389, 303, 354, 715, 245,  72,  38, 970, 530, 759, 700,
        568, 103, 567, 501, 901,  78, 950,   6, 128, 381, 783,  17, 704, 431,
        381, 355, 663,  85])]
     Correctly misclassified: 0
@    Batch (number 23) has ASR: 0.0
@  Batch 24
     Loss: 6.901397705078125
     True labels: tensor([996, 832,  61, 718, 534, 322, 455,  70,   7, 359, 308, 488,  76,  36,
        170, 218, 892, 782, 998, 932, 314,  81, 503, 795,  20,  91, 829, 663,
        148, 946, 669, 448])
     Predicted labels: [tensor([996, 848, 153, 745,  58, 389, 549, 161, 104, 783, 376, 577, 167, 130,
        251, 295, 901, 802, 998, 938, 379, 171, 631, 814, 116, 892, 680, 696,
        239, 951, 623, 578])]
     Correctly misclassified: 0
@    Batch (number 24) has ASR: 0.0
@  Batch 25
     Loss: 6.735546112060547
     True labels: tensor([503, 595, 966, 448, 669,  52, 752, 427, 585, 601, 864, 766, 966, 230,
        392, 308, 437, 389, 437, 916, 681, 228, 534, 669, 667, 676, 357, 266,
        355, 118, 250, 986])
     Predicted labels: [tensor([551, 634, 969, 501, 700, 145, 776, 483, 625,  64, 877, 789, 969, 305,
        451, 376, 492, 449, 492, 959, 549, 303, 111, 999,   7, 707,  10, 338,
        777, 263, 323, 987])]
     Correctly misclassified: 0
@    Batch (number 25) has ASR: 0.0
@  Batch 26
     Loss: 6.778669834136963
     True labels: tensor([484, 557, 369, 372, 187, 266, 455, 142, 479, 557, 454, 986, 228, 900,
        439, 222, 735, 244,  63, 533, 515,  36, 353, 400, 301, 135, 227, 941,
         91, 170, 818, 312])
     Predicted labels: [tensor([534,  60, 430, 433, 267, 338, 508, 226,  53,  67, 507, 987, 314, 909,
        708, 299, 760, 318, 155, 462, 562, 130, 416, 459,  37,  22, 302, 946,
        180, 251, 835,  38])]
     Correctly misclassified: 0
@    Batch (number 26) has ASR: 0.0
@  Batch 27
     Loss: 6.630467414855957
     True labels: tensor([ 60, 300, 484, 533, 257, 515, 714,  21, 378, 291, 906, 810, 389, 472,
        607, 758, 808, 674, 355, 530, 832, 263, 900, 981, 185, 314, 972, 520,
          3,  79, 734])
     Predicted labels: [tensor([152, 369, 534, 579,  33, 562, 741, 117, 439, 360, 780, 828, 718, 433,
        530, 781, 826, 705, 893, 576, 485, 335, 567, 650, 266, 381, 974, 567,
        100,  17,  76])]
     Correctly misclassified: 0
@    Batch (number 27) has ASR: 0.0
@  Batch 28
     Loss: 6.819436550140381
     True labels: tensor([227, 885, 533, 612, 837,  70, 620, 864, 369, 571, 619,  20, 612, 359,
         76, 335, 322, 998, 925, 620, 782, 658, 585, 990, 185, 837, 595,  52,
        667, 163, 986, 607])
     Predicted labels: [tensor([302, 876, 401, 111, 752, 161, 657, 877, 430, 450, 751, 116,  65, 421,
        173, 794, 389, 998, 931, 744, 802, 423, 625, 990, 266, 852, 634, 145,
          7, 195, 415, 549])]
     Correctly misclassified: 0
@    Batch (number 28) has ASR: 0.0
@  Batch 29
     Loss: 6.736850738525391
     True labels: tensor([437, 906, 258, 834, 328, 185, 378, 766, 406, 206, 127, 455, 312, 837,
        946, 312, 146, 109, 258, 990,  79, 142, 571, 222, 974, 427, 466, 295,
        439, 295, 582, 105])
     Predicted labels: [tensor([493, 914, 330,  86, 394, 265, 439, 789, 464, 284, 212, 508,  38, 522,
        868,  38,  23, 197, 330, 990,  14, 226, 603, 299, 970, 483, 670, 364,
        708, 364, 622, 186])]
     Correctly misclassified: 0
@    Batch (number 29) has ASR: 0.0
@  Batch 30
     Loss: 6.758910179138184
     True labels: tensor([775, 658, 627, 291, 620, 669, 106, 932, 355, 816, 455, 484, 451, 185,
        994, 612,  81, 341, 652, 230, 221, 620, 451, 515, 436, 718, 673, 946,
        676, 378, 335, 820])
     Predicted labels: [tensor([797, 691, 406, 360, 437, 999, 530, 938, 418, 914, 681, 534, 504, 266,
        994,  65, 171, 405, 686, 305, 299, 744, 967, 405, 491, 745, 704, 551,
        480, 439,  40, 836])]
     Correctly misclassified: 0
@    Batch (number 30) has ASR: 0.0
@  Batch 31
     Loss: 6.588929176330566
     True labels: tensor([300,  23, 990, 994, 663, 866, 164, 472,  63, 834, 179, 975, 328,  16,
        866, 534, 718, 676, 916, 590, 299, 980, 445, 479, 211, 227, 998, 527,
         30, 521,  52, 756])
     Predicted labels: [tensor([369, 119, 990, 994, 530, 879, 246, 523, 155,  85,  26, 144, 394, 112,
        879,  58, 745, 707, 949,  63, 368, 981, 306,  53, 289, 302, 987, 573,
        125, 568, 145,  78])]
     Correctly misclassified: 1
@    Batch (number 31) has ASR: 0.03125
@  Batch 32
     Loss: 6.77501106262207
     True labels: tensor([795, 257, 977, 406, 118, 590, 406, 925, 146, 810,  30,   7, 222, 981,
        958, 454, 353, 663, 472, 436,  18, 802, 996, 972,  33, 233, 958, 227,
        975, 317, 966,  52])
     Predicted labels: [tensor([814,  33, 979, 464, 263,  63, 719, 415, 794, 828, 125, 353, 299, 857,
        961, 507, 416, 696, 523, 683, 114, 820, 996, 974, 128, 308, 961, 300,
        977, 384, 969, 145])]
     Correctly misclassified: 0
@    Batch (number 32) has ASR: 0.0
@  Batch 33
     Loss: 6.6847405433654785
     True labels: tensor([285, 829, 163, 808, 148,  52, 674, 341, 752, 946, 752, 994, 266, 515,
        607,  36, 452, 866, 834, 534,  21, 925, 925, 966, 932, 864, 540, 782,
        233, 685, 299])
     Predicted labels: [tensor([355, 845, 245, 826, 232, 145, 705, 405, 776, 950, 776, 994, 338, 469,
        645, 130, 505, 701,  85, 128, 117, 931, 415, 969, 938, 877, 585, 802,
        308, 715, 368])]
     Correctly misclassified: 0
@    Batch (number 33) has ASR: 0.0
@  Batch 34
     Loss: 6.77081298828125
     True labels: tensor([484, 730, 341, 308, 941, 263, 601, 864, 451, 233, 998, 513, 904, 612,
        359, 372, 925, 445, 866, 428, 595, 820, 206, 205, 730,  79, 690, 262,
        445, 530, 142,  61])
     Predicted labels: [tensor([534, 756, 405, 376, 946, 335,  64, 877, 967, 308, 794, 560, 912,  65,
        564, 578, 931, 150, 701, 978, 634, 782, 284, 283, 756,  17,  72, 334,
          5, 576, 226, 153])]
     Correctly misclassified: 0
@    Batch (number 34) has ASR: 0.0
@  Batch 35
     Loss: 6.830986976623535
     True labels: tensor([631, 406, 571, 829, 775, 534, 335,  91, 619, 974, 812, 590, 452, 244,
        372, 810, 257, 998, 791, 998, 958, 211,  33, 812, 455, 170, 452, 620,
        820, 436, 353, 389])
     Predicted labels: [tensor([400, 622, 612, 499, 797,  58,  47, 180, 656, 976,  83,  63, 849, 318,
        433, 828, 337, 987, 810, 998, 961, 289, 128,  83, 508, 251, 505, 895,
        837, 491, 416, 449])]
     Correctly misclassified: 0
@    Batch (number 35) has ASR: 0.0
@  Batch 36
     Loss: 6.866098403930664
     True labels: tensor([ 76, 230, 980, 479, 795,  23,  76,  30, 227,  81, 733, 299, 595, 142,
        266, 718,  81, 109, 940,  16, 513, 663, 881, 730,  63, 369, 990, 940,
        164, 106, 244, 372])
     Predicted labels: [tensor([166, 305, 981,  53, 625, 119, 167, 119, 302, 253, 759, 368, 634, 226,
        338, 745, 178, 197, 945, 112, 560, 696, 892, 756, 185, 430, 990, 945,
        246, 204, 318, 433])]
     Correctly misclassified: 0
@    Batch (number 36) has ASR: 0.0
@  Batch 37
     Loss: 6.805617809295654
     True labels: tensor([843, 451, 674, 451,  20, 474, 527, 725, 904, 758, 977, 170, 285, 372,
        179, 406, 127, 940, 941, 452, 829, 983, 843, 864, 205,  16, 474, 690,
        392,  63, 925, 427])
     Predicted labels: [tensor([858, 504, 705, 931, 116, 977, 573, 751, 912, 111, 970, 212, 350, 433,
         26, 464, 212, 945, 946, 505, 845, 984, 858, 877, 283, 112, 525,  72,
        451, 155, 931, 839])]
     Correctly misclassified: 0
@    Batch (number 37) has ASR: 0.0
@  Batch 38
     Loss: 6.831361770629883
     True labels: tensor([ 89, 652, 674, 455, 164, 652, 359, 503,  91, 775, 222, 832, 733, 454,
        995, 148, 406, 881, 266, 295, 474, 540, 690, 466,  89, 392, 437, 437,
        752, 696,  33, 406])
     Predicted labels: [tensor([179, 783, 705, 508, 794, 818, 421, 551, 769, 797, 299, 482, 447, 507,
        995, 231, 518, 892, 338, 364, 975, 930,  72, 518, 179, 451, 492, 492,
        776, 725, 128, 958])]
     Correctly misclassified: 0
@    Batch (number 38) has ASR: 0.0
@  Batch 39
     Loss: 6.834469795227051
     True labels: tensor([317,  79, 759, 733,  30, 370,  89, 284, 775, 667, 916, 953, 291, 474,
        759, 218, 975, 170, 428, 585, 353, 285, 392, 185, 837, 595, 900, 106,
        484, 436, 392,  61])
     Predicted labels: [tensor([384,  17, 782, 759, 125, 431, 180, 354, 797,   7, 960, 957, 360, 977,
        782, 295, 977, 251, 554, 625, 416, 355, 398, 265, 574, 634, 909, 194,
        534, 491, 451, 153])]
     Correctly misclassified: 0
@    Batch (number 39) has ASR: 0.0
@  Batch 40
     Loss: 6.527094841003418
     True labels: tensor([262, 681, 221,  52, 295, 527, 977, 590, 996, 474, 820, 299,  33,  50,
         81, 109, 533,  70, 975, 205, 871, 127,  23, 105, 266, 681, 106, 974,
        977, 810, 322,  89])
     Predicted labels: [tensor([334, 711, 298, 145, 364, 573, 972,  63, 996, 525, 837, 368, 128, 143,
        172, 197, 579, 263, 672, 283, 883, 212, 118, 193, 338, 711, 194, 976,
        644, 828,  30, 179])]
     Correctly misclassified: 0
@    Batch (number 40) has ASR: 0.0
@  Batch 41
     Loss: 6.640132427215576
     True labels: tensor([389, 244, 533, 437, 904, 871, 714,  70,  23, 612,  18, 227, 735, 900,
        791, 546, 946, 667, 146, 980, 829, 595, 818,  20, 170, 658, 940,  63,
        983, 590, 436, 943])
     Predicted labels: [tensor([718, 318, 579, 492, 912, 883, 741, 161, 119,  65, 114, 304, 760, 909,
        810, 590, 588,   8,  23, 981, 641, 634, 835, 116, 251, 600, 945, 155,
        984,  63, 459, 948])]
     Correctly misclassified: 0
@    Batch (number 41) has ASR: 0.0
@  Batch 42
     Loss: 6.844042778015137
     True labels: tensor([448, 916, 996, 328, 389, 448, 734, 357, 105, 843, 667, 820, 943, 607,
        284, 674,  89, 530, 530, 994, 314, 571, 673, 696, 834, 451, 355, 218,
        322, 230, 681, 939])
     Predicted labels: [tensor([400, 923, 996, 394, 449, 128,  76,  42, 182, 725,   7, 530, 948, 645,
        354, 705, 179, 576, 576, 994, 381, 612, 704, 725,  85, 967, 623, 295,
        389, 305, 441, 944])]
     Correctly misclassified: 0
@    Batch (number 42) has ASR: 0.0
@  Batch 43
     Loss: 6.632998466491699
     True labels: tensor([676, 262, 266, 527, 612,  52, 400, 392,  52, 953, 958, 990, 972, 241,
        284,  79, 262, 959, 109, 752, 118, 335, 105, 864, 791, 284, 299, 370,
        250, 612, 941, 862])
     Predicted labels: [tensor([707, 334, 338, 573,  65, 145, 459, 451, 145, 957, 961, 990, 974, 315,
        354,  17, 334, 962, 197, 776, 204,  46, 186, 877, 810, 354, 368, 606,
        323,  65, 946, 875])]
     Correctly misclassified: 0
@    Batch (number 43) has ASR: 0.0
@  Batch 44
     Loss: 6.870837688446045
     True labels: tensor([775, 990, 673, 451, 812, 658, 222, 795, 127, 400, 725, 676, 257,  36,
        285, 228, 140, 906, 782, 986, 534, 812, 179,  18, 802, 627, 258, 228,
        775, 521,  89])
     Predicted labels: [tensor([797, 990, 704, 968,  83, 111, 299, 814, 212, 842, 751, 480,  34, 130,
        353, 303, 224, 914, 802, 813,  58,  83,  26, 114, 820, 663, 330, 312,
        530, 568, 179])]
     Correctly misclassified: 0
@    Batch (number 44) has ASR: 0.0
@  Batch 45
     Loss: 6.639247894287109
     True labels: tensor([400, 206, 758, 585, 994, 619,  18, 479, 163, 250, 142,  36, 335,  81,
        795, 864, 816, 109, 263, 980, 782, 994, 619, 959, 105, 619, 262, 832,
        953, 227, 142, 263])
     Predicted labels: [tensor([445, 284, 781, 472, 994, 656, 114,  53, 242, 323, 200, 130,  46, 171,
        814, 877, 833, 197, 335, 981, 802, 994, 656, 960, 185, 511, 334, 713,
        950, 302, 207, 335])]
     Correctly misclassified: 0
@    Batch (number 45) has ASR: 0.0
@  Batch 46
     Loss: 7.125701904296875
     True labels: tensor([392,  30, 378, 582, 263, 211, 211, 871, 222, 163, 681, 378, 546, 601,
        939, 906, 808, 718, 546, 966, 369, 946, 958, 759, 652, 206, 170, 871,
        540, 109, 837, 211])
     Predicted labels: [tensor([451, 125, 439, 686, 335, 289, 289, 883, 299, 245, 629, 439, 699,  64,
        944, 484, 826, 745, 620, 969, 430, 950, 631, 782, 686, 284, 251, 883,
        720, 233, 752, 289])]
     Correctly misclassified: 0
@    Batch (number 46) has ASR: 0.0
@  Batch 47
     Loss: 6.782054901123047
     True labels: tensor([690, 818, 359, 479, 758, 140,   7, 135, 734, 503, 295, 986,   7, 308,
        585, 690, 187, 454, 353, 663,  76, 472,  21, 862, 140, 221, 752, 221,
        696, 941, 312, 314])
     Predicted labels: [tensor([ 72, 835, 846,  53, 781, 224, 104,  22,  76, 551, 364, 987, 348, 376,
        724,  72, 266, 507, 416, 542, 167, 842, 117, 875, 199, 298, 776, 299,
        725, 946,  38, 381])]
     Correctly misclassified: 0
@    Batch (number 47) has ASR: 0.0
@  Batch 48
     Loss: 6.577855110168457
     True labels: tensor([230, 734, 479, 862, 947, 285, 696, 400, 816, 619, 843, 250, 752, 378,
        164, 972, 372, 357, 966, 140, 244, 285, 488, 885, 667, 355, 975, 631,
        862, 735, 328])
     Predicted labels: [tensor([305,  76,  58, 875, 951, 355, 725, 459, 833, 734, 858, 323, 776, 439,
        246, 974, 433,  42, 969, 224, 318, 355, 538, 861,   7, 845, 976, 667,
        875, 651, 394])]
     Correctly misclassified: 0
@    Batch (number 48) has ASR: 0.0
@  Batch 49
     Loss: 6.781896591186523
     True labels: tensor([428, 834, 427, 448, 205, 218, 285, 439, 262, 479, 127, 885, 228, 185,
        436, 148, 734, 436, 291, 233, 818, 295, 250, 843, 834, 735, 244, 295,
        263, 369, 974, 980])
     Predicted labels: [tensor([484,  85, 483, 570, 283, 295, 355, 494, 334,  52, 212, 435, 303, 265,
        769, 232,  77, 416, 360, 308, 657, 364, 323, 425,  86, 582, 318, 364,
        335, 430, 972, 981])]
     Correctly misclassified: 0
@    Batch (number 49) has ASR: 0.0
@  Batch 50
     Loss: 6.722250938415527
     True labels: tensor([452, 974,  52, 812, 958, 439, 885, 627, 607, 582, 164,   3,  21,  20,
        669, 308, 392, 301, 546, 885, 146, 582, 832, 230,  81, 843,   7, 714,
        185, 513, 258, 758])
     Predicted labels: [tensor([505, 977, 145,  83, 961, 577, 896, 663, 645, 759, 246, 100, 117,  69,
        999, 376, 451,  37, 826, 896,  23, 507, 754, 305, 171, 858, 104, 741,
        266, 929, 330, 781])]
     Correctly misclassified: 0
@    Batch (number 50) has ASR: 0.0
@  Batch 51
     Loss: 6.655527114868164
     True labels: tensor([756, 221, 735, 812, 916, 472, 998, 295, 900, 601, 941,  21, 925, 335,
        947, 667, 106, 669, 187,  50, 818, 619,  18, 758, 601, 906, 816, 676,
        681,  20, 925,  30])
     Predicted labels: [tensor([ 78, 298, 760,  83, 931, 400, 998, 364, 909,  64, 946, 117, 931,  40,
        951,   8, 190, 999, 267, 143, 835, 656, 114, 781,  64, 914, 833, 707,
        589, 116, 499, 125])]
     Correctly misclassified: 0
@    Batch (number 51) has ASR: 0.0
@  Batch 52
     Loss: 6.681103229522705
     True labels: tensor([943, 601, 939, 582, 179,   3, 211, 881, 995, 940, 515, 369, 546, 185,
         89, 959, 582, 947,  91, 488, 479, 146, 881, 730, 734, 995, 791, 652,
         52,  60, 428, 818])
     Predicted labels: [tensor([948,  64, 944, 759,  26, 100, 289, 892, 995, 945, 562, 430, 487, 265,
        969, 962, 759, 951, 242, 538,  53, 135, 892, 412,  76, 995, 508, 534,
        145, 152, 628, 835])]
     Correctly misclassified: 0
@    Batch (number 52) has ASR: 0.0
@  Batch 53
     Loss: 6.942237854003906
     True labels: tensor([812, 730, 230, 427,   3, 946, 585, 534,  16, 652, 488, 607, 571, 802,
        503, 400, 118, 619, 714, 291, 314,  30, 148, 916, 966, 820, 904, 932,
        735, 488, 452, 503])
     Predicted labels: [tensor([ 83, 756, 305, 483, 100, 588, 625, 818, 112, 686, 557, 645, 612, 820,
        629, 445, 844, 436, 741, 360, 381, 125, 264, 923, 969, 836, 716, 938,
        760, 538, 849, 551])]
     Correctly misclassified: 0
@    Batch (number 53) has ASR: 0.0
@  Batch 54
     Loss: 6.689535617828369
     True labels: tensor([972,  36,  50,  79, 520, 676, 472, 474, 400, 233, 885, 357, 163, 295,
        301, 812, 631, 546, 816,  18, 791, 943, 631, 725, 228, 759, 445, 335,
        472, 940, 904, 317])
     Predicted labels: [tensor([974, 130, 143,  17, 567, 707, 432, 718, 549, 308, 896,  42, 245, 364,
         36,  83, 667, 605, 833, 114, 508, 948, 541, 751, 303, 782,   6,  40,
        523, 945, 912, 384])]
     Correctly misclassified: 0
@    Batch (number 54) has ASR: 0.0
@  Batch 55
     Loss: 6.798898696899414
     True labels: tensor([812, 808, 658, 947, 791, 866, 328, 335, 118, 241,   3, 958,  91, 892,
        258,  20, 300, 205, 714, 627, 222, 916,  20, 676, 372, 341, 211, 752,
        904, 953, 106, 669])
     Predicted labels: [tensor([ 83, 826, 691, 951, 508, 879, 394,  40, 160, 315, 100, 961, 179, 901,
        330, 116, 369, 283, 741, 884, 299, 923, 116, 707, 433, 405, 289, 776,
        912, 957, 153, 700])]
     Correctly misclassified: 0
@    Batch (number 55) has ASR: 0.0
@  Batch 56
     Loss: 6.688231468200684
     True labels: tensor([372, 436, 631, 681,   7, 317, 607, 557, 972,  50,  18, 135, 109, 301,
        335, 939, 135, 829, 452,  16, 932, 301, 266, 378, 601, 557, 730, 940,
         21, 135, 258, 943])
     Predicted labels: [tensor([433, 491, 400, 711, 352, 384, 645,  60, 974, 146, 306,  22, 199,  37,
         40, 944,  22, 845, 505, 112, 938,  37, 338, 439,  64,  60, 971, 945,
        117,  22, 330, 948])]
     Correctly misclassified: 0
@    Batch (number 56) has ASR: 0.0
@  Batch 57
     Loss: 6.957001686096191
     True labels: tensor([837, 439, 871, 355, 206, 802, 540, 262, 834, 205, 595, 427, 546, 484,
        127, 317, 474, 892, 816, 943,  70, 758, 990, 455, 590, 370, 389, 170,
        658, 843, 322, 257])
     Predicted labels: [tensor([852, 583, 883, 418, 284, 820, 898, 334,  85, 283, 634, 483, 487, 534,
        212, 384, 525, 901, 833, 948, 530, 781, 990, 508,  63, 739, 449, 251,
        691, 858, 389, 801])]
     Correctly misclassified: 0
@    Batch (number 57) has ASR: 0.0
@  Batch 58
     Loss: 6.597114562988281
     True labels: tensor([758,   3, 673, 959, 718, 673, 400, 205, 947, 521, 109, 105,  30, 810,
        941, 515, 725, 631, 943, 513, 663, 106, 733, 312, 454, 658, 140, 357,
        488, 533, 521, 673])
     Predicted labels: [tensor([781, 100, 704, 962, 786, 704, 459, 283, 951, 568, 208, 185, 125, 828,
        946, 562, 751, 667, 948, 560, 647, 190, 759,  38, 507, 971, 224,  42,
        538, 579, 568, 704])]
     Correctly misclassified: 0
@    Batch (number 58) has ASR: 0.0
@  Batch 59
     Loss: 6.868405818939209
     True labels: tensor([146, 725,  16, 218, 995, 996, 163, 308, 791, 816, 448, 221, 299, 135,
        308, 585, 972, 829, 322, 205, 400,  63, 816, 513, 986, 109, 975, 994,
        357, 673,  70, 864])
     Predicted labels: [tensor([ 23, 751, 112, 295, 995, 996, 245, 376, 508, 833, 735, 298, 368,  22,
        376, 625, 974, 766,   0, 283, 445, 155, 833, 560, 987, 197, 977, 994,
         42, 704, 161, 877])]
     Correctly misclassified: 0
@    Batch (number 59) has ASR: 0.0
@  Batch 60
     Loss: 6.747550010681152
     True labels: tensor([627, 953, 211, 881, 808, 673, 250, 775,  50, 179, 996, 782, 966, 341,
        906, 534, 932, 943, 892, 227, 300, 959,  91, 725,  16, 317, 437, 571,
        163, 820, 322, 389])
     Predicted labels: [tensor([663, 957, 289, 892, 826, 704, 323, 797, 143,  26, 996, 802, 969, 755,
        914, 749, 938, 948, 530, 302, 369, 962, 173, 751, 112, 384, 492, 612,
        245, 445, 389, 449])]
     Correctly misclassified: 0
@    Batch (number 60) has ASR: 0.0
@  Batch 61
     Loss: 6.56420373916626
     True labels: tensor([718, 312, 685, 503, 862, 308, 980, 135, 759, 947, 299, 106,  50, 766,
        977, 939, 357, 127, 140, 892, 378, 118, 515, 759, 959, 802, 685, 369,
        392, 871, 206, 250])
     Predicted labels: [tensor([745,  38, 715, 551, 875, 373, 981,  22, 851, 951, 368, 229, 143, 789,
        970, 944,  42, 212, 224, 901, 439, 155, 562, 782, 962, 820, 715, 430,
        451, 883, 284, 323])]
     Correctly misclassified: 0
@    Batch (number 61) has ASR: 0.0
@  Batch 62
     Loss: 6.728803634643555
     True labels: tensor([427, 230, 627, 866, 228, 466, 520,  18, 187, 474, 977, 734, 802, 454,
        953, 752, 620, 179, 241, 696,  23, 735, 619, 885, 527, 369, 341, 472,
        241,  60, 980,   3])
     Predicted labels: [tensor([483, 305, 698, 879, 303, 836, 567, 114, 267, 554, 979,  76, 820, 507,
        957, 881, 744, 794, 315, 901, 118, 760, 656, 530, 573, 430, 405, 523,
        315, 152, 981, 100])]
     Correctly misclassified: 0
@    Batch (number 62) has ASR: 0.0
@  Batch 63
     Loss: 6.785442352294922
     True labels: tensor([939, 301, 932, 513, 118, 837, 871, 866, 652, 718, 612, 557, 940, 996,
        843, 520])
     Predicted labels: [tensor([944,  37, 956, 560, 204, 752, 883, 879, 783, 745,  58,  60, 943, 996,
        858, 567])]
     Correctly misclassified: 0
@    Batch (number 63) has ASR: 0.0
Epoch [2/2], Loss: 6.785442352294922, Avg ASR: 0.00%
  > Saved generator at epoch 2 to /scratch.ssd/takonoselidze/job_8178938.pbs-m1.metacentrum.cz/checkpoints/generator_epoch_2_target_949.pth


Average ASR over all 2 epochs: 0.00% 

----------------------------------------------------------------------------------------------------



====================================== Evaluating generators ======================================
checkpoint files: ['generator_epoch_1_target_932.pth', 'generator_epoch_1_target_949.pth', 'generator_epoch_2_target_932.pth', 'generator_epoch_2_target_949.pth']
by target class: {932: [(1, 'generator_epoch_1_target_932.pth'), (2, 'generator_epoch_2_target_932.pth')], 949: [(1, 'generator_epoch_1_target_949.pth'), (2, 'generator_epoch_2_target_949.pth')]}
Results for target class "pretzel" (932)
----------------------------------------------------------------------------------------------------
  > Loaded generator from checkpoints/generator_epoch_1_target_932.pth 
Epoch 1 -<>- Patch ASR: 0.00%
  > Loaded generator from checkpoints/generator_epoch_2_target_932.pth 
Epoch 2 -<>- Patch ASR: 0.01%
----------------------------------------------------------------------------------------------------
Best generator found at epoch 2 with ASR: 0.01%
----------------------------------------------------------------------------------------------------
Results for target class "strawberry" (949)
----------------------------------------------------------------------------------------------------
  > Loaded generator from checkpoints/generator_epoch_1_target_949.pth 
Epoch 1 -<>- Patch ASR: 0.00%
  > Loaded generator from checkpoints/generator_epoch_2_target_949.pth 
Epoch 2 -<>- Patch ASR: 0.00%
----------------------------------------------------------------------------------------------------
Best generator found at epoch 2 with ASR: 0.01%
----------------------------------------------------------------------------------------------------
====================================================================================================
RESULTS:{932: {'best_asr': 6.28140703517588e-05, 'best_epoch': 2, 'best_patch': tensor([[[2.7007e-02, 9.2527e-01, 9.9101e-01, 9.8900e-01, 9.2892e-01,
          1.1232e-02, 1.6305e-03, 2.4754e-03, 6.5699e-02, 1.2100e-01,
          5.3305e-01, 1.0585e-02, 1.3368e-03, 9.7124e-01, 9.9557e-01,
          9.7741e-01],
         [4.0283e-01, 9.9752e-01, 9.9903e-01, 9.9712e-01, 3.6566e-02,
          2.0584e-03, 6.6072e-05, 2.6300e-02, 4.0533e-02, 9.6512e-01,
          6.1660e-03, 2.6535e-03, 1.2255e-02, 9.9974e-01, 9.9964e-01,
          9.9536e-01],
         [8.0452e-01, 9.9944e-01, 9.9980e-01, 9.9433e-01, 1.7177e-02,
          1.6272e-03, 7.9992e-04, 1.0929e-02, 5.9841e-02, 1.9912e-03,
          1.9729e-04, 2.5359e-03, 2.8666e-02, 9.9976e-01, 9.9929e-01,
          9.9703e-01],
         [3.7602e-02, 9.9698e-01, 9.9078e-01, 1.3849e-02, 3.6007e-04,
          1.3001e-03, 1.1539e-03, 1.2769e-03, 1.0759e-03, 7.2223e-04,
          6.7487e-04, 2.2527e-03, 1.6367e-02, 9.9311e-01, 9.7869e-01,
          1.1359e-01],
         [5.9209e-02, 1.0893e-02, 7.6793e-03, 5.4383e-04, 2.7645e-04,
          1.9047e-03, 7.5072e-05, 1.6356e-04, 3.1173e-05, 2.6584e-05,
          4.6492e-06, 3.0130e-04, 4.6327e-03, 3.5526e-01, 3.9688e-02,
          7.0840e-03],
         [4.7475e-04, 7.2208e-04, 1.7038e-03, 1.1732e-03, 2.9391e-04,
          2.8397e-03, 9.8193e-04, 4.2810e-03, 6.1220e-04, 2.5769e-03,
          2.6959e-04, 1.7959e-03, 1.2957e-02, 1.9760e-02, 8.8450e-04,
          3.0228e-04],
         [1.3489e-04, 9.5308e-05, 6.8247e-05, 3.1897e-04, 1.9798e-04,
          6.7198e-04, 1.0265e-03, 2.9309e-03, 1.2197e-03, 1.9696e-04,
          2.6181e-04, 2.2684e-02, 5.1692e-02, 5.8687e-02, 7.5310e-05,
          4.0603e-04],
         [5.1633e-04, 5.6556e-04, 2.1897e-03, 2.0781e-03, 4.1032e-04,
          2.0909e-03, 8.3780e-04, 1.7401e-02, 2.9340e-03, 2.3156e-03,
          8.2877e-04, 5.0971e-01, 9.8070e-01, 7.7087e-02, 8.1477e-04,
          7.4965e-04],
         [3.4512e-03, 5.5790e-01, 9.6498e-01, 5.9383e-01, 5.8450e-03,
          4.0106e-01, 1.0405e-02, 1.3435e-01, 1.1163e-02, 3.3592e-02,
          2.7501e-02, 9.8745e-01, 9.9915e-01, 9.9550e-01, 4.3179e-03,
          6.1064e-03],
         [3.2022e-02, 9.9984e-01, 9.9729e-01, 9.8673e-01, 1.3313e-02,
          6.9110e-01, 1.9238e-01, 8.1039e-01, 1.1442e-01, 7.1918e-01,
          1.5755e-01, 9.8984e-01, 9.8800e-01, 9.9301e-01, 5.6706e-01,
          1.7443e-02],
         [4.4250e-02, 9.7273e-01, 6.9799e-01, 3.6130e-02, 3.1298e-04,
          1.5511e-03, 4.9976e-04, 7.2706e-03, 1.8784e-03, 1.9317e-03,
          1.0647e-03, 1.8497e-02, 3.1554e-01, 9.3652e-01, 6.3778e-03,
          9.4019e-03],
         [2.2591e-02, 2.6541e-02, 9.6617e-01, 1.1303e-02, 3.4646e-03,
          4.3230e-03, 1.3763e-02, 3.1812e-01, 1.9971e-01, 1.1287e-02,
          1.6169e-02, 2.2158e-01, 9.4797e-01, 1.1390e-01, 2.3386e-02,
          5.2782e-03],
         [3.5247e-03, 3.3405e-02, 7.2962e-01, 2.1862e-01, 6.7165e-01,
          6.9247e-01, 9.8340e-01, 9.6739e-01, 9.8820e-01, 8.9898e-01,
          9.8133e-01, 4.9541e-01, 9.9779e-01, 9.7572e-01, 3.5634e-01,
          7.9601e-03],
         [4.4210e-02, 9.9791e-01, 9.9868e-01, 9.9751e-01, 9.9280e-01,
          9.9836e-01, 9.9827e-01, 9.9825e-01, 9.9664e-01, 9.9820e-01,
          9.9675e-01, 9.9626e-01, 9.9619e-01, 9.9896e-01, 9.9818e-01,
          5.8437e-01],
         [8.0006e-01, 9.9994e-01, 9.9781e-01, 9.9940e-01, 9.9754e-01,
          9.9744e-01, 9.9747e-01, 9.9820e-01, 9.9742e-01, 9.9903e-01,
          9.9601e-01, 9.8884e-01, 9.9892e-01, 9.9498e-01, 9.9330e-01,
          8.8720e-01],
         [9.7530e-01, 9.9528e-01, 9.9277e-01, 9.3597e-01, 6.7122e-01,
          9.2597e-01, 8.3539e-01, 9.3500e-01, 7.3942e-01, 9.4350e-01,
          8.1952e-01, 8.8822e-01, 3.7578e-01, 9.7471e-01, 9.4942e-01,
          9.2563e-01]],

        [[7.7793e-03, 1.7561e-03, 8.8998e-01, 1.4153e-02, 1.0254e-01,
          7.5527e-03, 4.0555e-03, 5.8224e-02, 9.8634e-01, 9.8545e-01,
          9.7137e-01, 1.1622e-02, 2.7179e-03, 6.1287e-03, 9.7970e-01,
          1.3546e-02],
         [1.9055e-02, 9.9923e-01, 9.9988e-01, 9.9997e-01, 5.2241e-01,
          9.8072e-01, 9.8668e-01, 9.9891e-01, 9.9929e-01, 9.9999e-01,
          9.9622e-01, 9.7363e-01, 9.6992e-01, 9.9986e-01, 9.9993e-01,
          9.9473e-01],
         [9.9574e-01, 9.9989e-01, 9.9999e-01, 9.9991e-01, 9.9778e-01,
          9.8506e-01, 9.9950e-01, 9.9996e-01, 1.0000e+00, 9.9951e-01,
          9.9479e-01, 9.5429e-01, 9.9989e-01, 9.9996e-01, 9.9998e-01,
          9.9395e-01],
         [9.8937e-01, 9.9995e-01, 9.9958e-01, 9.9828e-01, 8.4373e-01,
          7.3124e-01, 9.5212e-01, 9.9412e-01, 9.7829e-01, 9.5666e-01,
          4.4114e-02, 3.0028e-02, 9.8487e-01, 9.9966e-01, 9.9880e-01,
          9.4289e-01],
         [9.9486e-01, 9.9923e-01, 9.9848e-01, 9.5865e-01, 2.9351e-01,
          4.2937e-01, 8.5831e-01, 9.4491e-01, 9.6824e-01, 2.2625e-02,
          7.1464e-03, 1.2775e-02, 9.8595e-01, 9.9967e-01, 9.9951e-01,
          7.3752e-01],
         [9.8013e-01, 9.8920e-01, 9.8353e-01, 1.1831e-02, 6.2856e-02,
          1.6559e-01, 7.9895e-01, 1.0121e-01, 3.6173e-01, 9.7880e-03,
          2.4477e-03, 1.0552e-02, 9.7300e-01, 9.8898e-01, 9.9634e-01,
          2.3051e-01],
         [4.1584e-02, 4.9345e-01, 9.1808e-01, 9.6790e-03, 3.5578e-01,
          4.4251e-01, 9.3189e-01, 9.2758e-01, 9.1732e-01, 9.4773e-02,
          1.2430e-02, 3.4896e-01, 9.9601e-01, 9.8975e-01, 9.7171e-01,
          2.6519e-03],
         [1.4690e-02, 9.9904e-01, 9.9890e-01, 9.8950e-01, 9.9845e-01,
          9.9767e-01, 9.9886e-01, 9.9855e-01, 9.9505e-01, 9.8989e-01,
          9.9069e-01, 9.9814e-01, 9.9924e-01, 9.9968e-01, 9.9221e-01,
          4.0193e-03],
         [5.2660e-01, 9.9955e-01, 9.9998e-01, 9.9860e-01, 9.9742e-01,
          9.9773e-01, 9.9771e-01, 9.9583e-01, 9.9824e-01, 9.5245e-01,
          9.7215e-01, 9.9108e-01, 9.9959e-01, 9.9981e-01, 9.9804e-01,
          2.0885e-02],
         [9.9424e-01, 9.9998e-01, 9.9995e-01, 9.8141e-01, 5.3427e-01,
          2.6818e-02, 4.0994e-02, 3.4823e-02, 2.3302e-02, 5.7232e-03,
          2.3026e-03, 9.1959e-01, 9.9165e-01, 9.9982e-01, 9.9772e-01,
          9.7975e-01],
         [9.9510e-01, 9.9762e-01, 9.9909e-01, 4.8216e-03, 1.9023e-03,
          1.4395e-03, 2.8879e-03, 1.4229e-03, 2.3017e-03, 2.1338e-04,
          9.4357e-04, 1.6756e-02, 5.6596e-01, 9.9876e-01, 9.9686e-01,
          1.8323e-01],
         [9.6937e-02, 9.9802e-01, 9.2332e-02, 1.6626e-03, 6.4719e-04,
          1.0025e-03, 1.4385e-03, 2.8310e-03, 3.6630e-04, 1.0218e-03,
          1.2708e-03, 6.8777e-03, 3.3018e-03, 9.5643e-01, 9.7473e-01,
          5.6044e-03],
         [1.7505e-02, 9.2712e-01, 8.6109e-03, 8.6863e-03, 2.8804e-03,
          3.5459e-03, 4.3978e-03, 4.6480e-03, 6.0485e-03, 4.5656e-03,
          1.3516e-03, 7.4914e-04, 6.2831e-03, 9.8658e-01, 9.8608e-01,
          5.0148e-03],
         [3.4440e-02, 9.9569e-01, 9.7961e-01, 1.1886e-02, 6.7390e-03,
          2.0262e-02, 3.3031e-02, 6.0371e-03, 7.2263e-03, 4.3151e-02,
          1.0736e-02, 5.8637e-03, 1.3100e-01, 9.9779e-01, 9.9735e-01,
          9.9262e-01],
         [9.9574e-01, 9.9269e-01, 9.9278e-01, 2.7126e-01, 1.0934e-01,
          3.6462e-02, 2.6018e-02, 3.1478e-02, 4.8590e-02, 1.7703e-02,
          9.4722e-03, 3.1553e-02, 3.3532e-01, 9.9859e-01, 9.9880e-01,
          9.8549e-01],
         [9.8382e-01, 9.8312e-01, 1.0025e-02, 2.2819e-03, 1.1329e-03,
          1.6590e-03, 1.6848e-03, 1.9512e-03, 1.6252e-03, 2.6351e-03,
          2.3704e-03, 1.3310e-03, 7.2236e-03, 2.3722e-02, 9.6243e-01,
          9.7625e-01]],

        [[3.5290e-02, 9.6662e-01, 9.9313e-01, 9.1806e-01, 9.7588e-01,
          1.5879e-02, 5.7696e-03, 2.2865e-01, 9.4318e-01, 9.9423e-01,
          9.8171e-01, 7.8121e-01, 7.6090e-02, 9.9212e-01, 9.9859e-01,
          7.1297e-01],
         [9.9452e-01, 9.9863e-01, 9.9999e-01, 9.9960e-01, 9.3859e-01,
          2.6860e-03, 5.0231e-01, 9.8522e-01, 9.9686e-01, 9.9819e-01,
          9.9560e-01, 9.7345e-01, 9.9894e-01, 9.9973e-01, 9.9999e-01,
          9.9965e-01],
         [9.9694e-01, 9.9990e-01, 9.9998e-01, 9.9589e-01, 5.1609e-02,
          2.1443e-03, 8.9581e-03, 9.1725e-01, 9.8614e-01, 9.5306e-01,
          5.1078e-03, 1.2842e-02, 9.9354e-01, 9.9970e-01, 9.9997e-01,
          9.9750e-01],
         [7.9180e-01, 9.9908e-01, 9.9810e-01, 6.2727e-03, 2.7090e-04,
          1.1829e-04, 2.8074e-04, 1.0780e-03, 1.2451e-03, 1.1519e-03,
          2.1631e-04, 3.4818e-04, 2.0837e-02, 9.9750e-01, 9.9361e-01,
          2.3273e-01],
         [4.3778e-01, 9.6297e-01, 7.5883e-01, 2.1856e-03, 6.9290e-05,
          4.8399e-05, 2.0644e-04, 1.1307e-03, 1.2422e-04, 2.3776e-04,
          3.2753e-05, 2.2420e-04, 5.7785e-03, 9.8898e-01, 9.0487e-01,
          2.1358e-02],
         [9.4732e-03, 2.7638e-03, 6.6611e-04, 4.8301e-04, 1.4767e-04,
          1.4395e-04, 9.2438e-04, 2.1625e-03, 1.0055e-03, 8.9645e-05,
          7.8470e-05, 2.5749e-05, 3.0001e-03, 1.6765e-02, 8.4317e-04,
          5.6174e-04],
         [4.7231e-04, 5.4723e-04, 1.1925e-03, 2.1592e-04, 5.8183e-04,
          1.3845e-03, 3.6158e-03, 6.9131e-03, 2.4435e-03, 2.5782e-03,
          1.0514e-04, 5.1419e-03, 3.7706e-02, 4.4126e-03, 7.1386e-04,
          4.9591e-05],
         [7.9131e-03, 1.5098e-03, 3.6808e-03, 2.5317e-04, 9.5636e-05,
          6.4999e-05, 9.6917e-05, 8.9240e-04, 2.0254e-04, 1.2998e-03,
          2.9755e-03, 1.7821e-02, 2.0855e-01, 6.5131e-02, 3.3575e-03,
          5.8171e-04],
         [1.8930e-02, 9.9359e-01, 9.9566e-01, 1.9476e-02, 1.4903e-02,
          1.0400e-03, 1.0342e-03, 2.5038e-03, 3.7253e-03, 3.9652e-03,
          2.1050e-02, 6.4353e-01, 9.4247e-01, 9.9603e-01, 1.0778e-01,
          1.3114e-03],
         [9.9682e-01, 9.9994e-01, 9.9839e-01, 9.6857e-01, 5.7712e-03,
          1.0545e-03, 1.3518e-04, 6.9022e-03, 5.0795e-04, 1.2213e-02,
          3.9306e-04, 4.1898e-02, 8.7051e-02, 9.9440e-01, 4.8014e-02,
          2.3115e-02],
         [9.9629e-01, 9.9860e-01, 9.9396e-01, 2.6561e-03, 3.8403e-04,
          9.9897e-05, 1.3942e-04, 5.1585e-04, 3.4645e-04, 8.3661e-04,
          1.5205e-04, 8.4439e-03, 2.4234e-01, 1.6073e-01, 3.3668e-02,
          3.5608e-03],
         [9.8289e-01, 9.8977e-01, 3.7094e-01, 2.3583e-04, 1.9938e-04,
          3.8531e-04, 1.2452e-03, 1.4531e-03, 4.6917e-03, 7.8446e-04,
          3.6460e-03, 2.5685e-03, 1.2114e-01, 3.8303e-02, 7.5492e-02,
          5.0359e-03],
         [2.5978e-01, 9.9828e-01, 9.1211e-01, 1.6853e-02, 1.2082e-02,
          6.3123e-03, 3.7153e-02, 5.2198e-01, 2.7721e-01, 1.1385e-01,
          8.6536e-02, 8.0117e-01, 5.9535e-01, 9.9946e-01, 9.9265e-01,
          2.1358e-02],
         [9.9423e-01, 9.9954e-01, 9.9947e-01, 9.9115e-01, 9.4190e-01,
          9.4412e-01, 9.8278e-01, 9.8789e-01, 9.8552e-01, 9.7898e-01,
          9.8368e-01, 9.8675e-01, 9.9732e-01, 9.9982e-01, 9.9971e-01,
          9.9576e-01],
         [9.9831e-01, 9.9621e-01, 9.8039e-01, 1.1401e-01, 6.9495e-02,
          8.6724e-02, 7.1552e-02, 1.9478e-01, 1.6923e-01, 4.5313e-01,
          6.8062e-02, 3.3282e-01, 9.7994e-01, 9.8355e-01, 9.9757e-01,
          9.8598e-01],
         [9.8378e-01, 9.5789e-01, 2.2231e-02, 4.5475e-04, 2.8020e-04,
          1.1752e-03, 9.0054e-04, 7.8806e-04, 1.4855e-03, 2.8524e-03,
          1.6847e-03, 1.4092e-03, 4.8434e-03, 1.1425e-01, 8.6474e-01,
          9.6357e-01]]], device='cuda:0')}, 949: {'best_asr': 6.28140703517588e-05, 'best_epoch': 2, 'best_patch': tensor([[[2.7007e-02, 9.2527e-01, 9.9101e-01, 9.8900e-01, 9.2892e-01,
          1.1232e-02, 1.6305e-03, 2.4754e-03, 6.5699e-02, 1.2100e-01,
          5.3305e-01, 1.0585e-02, 1.3368e-03, 9.7124e-01, 9.9557e-01,
          9.7741e-01],
         [4.0283e-01, 9.9752e-01, 9.9903e-01, 9.9712e-01, 3.6566e-02,
          2.0584e-03, 6.6072e-05, 2.6300e-02, 4.0533e-02, 9.6512e-01,
          6.1660e-03, 2.6535e-03, 1.2255e-02, 9.9974e-01, 9.9964e-01,
          9.9536e-01],
         [8.0452e-01, 9.9944e-01, 9.9980e-01, 9.9433e-01, 1.7177e-02,
          1.6272e-03, 7.9992e-04, 1.0929e-02, 5.9841e-02, 1.9912e-03,
          1.9729e-04, 2.5359e-03, 2.8666e-02, 9.9976e-01, 9.9929e-01,
          9.9703e-01],
         [3.7602e-02, 9.9698e-01, 9.9078e-01, 1.3849e-02, 3.6007e-04,
          1.3001e-03, 1.1539e-03, 1.2769e-03, 1.0759e-03, 7.2223e-04,
          6.7487e-04, 2.2527e-03, 1.6367e-02, 9.9311e-01, 9.7869e-01,
          1.1359e-01],
         [5.9209e-02, 1.0893e-02, 7.6793e-03, 5.4383e-04, 2.7645e-04,
          1.9047e-03, 7.5072e-05, 1.6356e-04, 3.1173e-05, 2.6584e-05,
          4.6492e-06, 3.0130e-04, 4.6327e-03, 3.5526e-01, 3.9688e-02,
          7.0840e-03],
         [4.7475e-04, 7.2208e-04, 1.7038e-03, 1.1732e-03, 2.9391e-04,
          2.8397e-03, 9.8193e-04, 4.2810e-03, 6.1220e-04, 2.5769e-03,
          2.6959e-04, 1.7959e-03, 1.2957e-02, 1.9760e-02, 8.8450e-04,
          3.0228e-04],
         [1.3489e-04, 9.5308e-05, 6.8247e-05, 3.1897e-04, 1.9798e-04,
          6.7198e-04, 1.0265e-03, 2.9309e-03, 1.2197e-03, 1.9696e-04,
          2.6181e-04, 2.2684e-02, 5.1692e-02, 5.8687e-02, 7.5310e-05,
          4.0603e-04],
         [5.1633e-04, 5.6556e-04, 2.1897e-03, 2.0781e-03, 4.1032e-04,
          2.0909e-03, 8.3780e-04, 1.7401e-02, 2.9340e-03, 2.3156e-03,
          8.2877e-04, 5.0971e-01, 9.8070e-01, 7.7087e-02, 8.1477e-04,
          7.4965e-04],
         [3.4512e-03, 5.5790e-01, 9.6498e-01, 5.9383e-01, 5.8450e-03,
          4.0106e-01, 1.0405e-02, 1.3435e-01, 1.1163e-02, 3.3592e-02,
          2.7501e-02, 9.8745e-01, 9.9915e-01, 9.9550e-01, 4.3179e-03,
          6.1064e-03],
         [3.2022e-02, 9.9984e-01, 9.9729e-01, 9.8673e-01, 1.3313e-02,
          6.9110e-01, 1.9238e-01, 8.1039e-01, 1.1442e-01, 7.1918e-01,
          1.5755e-01, 9.8984e-01, 9.8800e-01, 9.9301e-01, 5.6706e-01,
          1.7443e-02],
         [4.4250e-02, 9.7273e-01, 6.9799e-01, 3.6130e-02, 3.1298e-04,
          1.5511e-03, 4.9976e-04, 7.2706e-03, 1.8784e-03, 1.9317e-03,
          1.0647e-03, 1.8497e-02, 3.1554e-01, 9.3652e-01, 6.3778e-03,
          9.4019e-03],
         [2.2591e-02, 2.6541e-02, 9.6617e-01, 1.1303e-02, 3.4646e-03,
          4.3230e-03, 1.3763e-02, 3.1812e-01, 1.9971e-01, 1.1287e-02,
          1.6169e-02, 2.2158e-01, 9.4797e-01, 1.1390e-01, 2.3386e-02,
          5.2782e-03],
         [3.5247e-03, 3.3405e-02, 7.2962e-01, 2.1862e-01, 6.7165e-01,
          6.9247e-01, 9.8340e-01, 9.6739e-01, 9.8820e-01, 8.9898e-01,
          9.8133e-01, 4.9541e-01, 9.9779e-01, 9.7572e-01, 3.5634e-01,
          7.9601e-03],
         [4.4210e-02, 9.9791e-01, 9.9868e-01, 9.9751e-01, 9.9280e-01,
          9.9836e-01, 9.9827e-01, 9.9825e-01, 9.9664e-01, 9.9820e-01,
          9.9675e-01, 9.9626e-01, 9.9619e-01, 9.9896e-01, 9.9818e-01,
          5.8437e-01],
         [8.0006e-01, 9.9994e-01, 9.9781e-01, 9.9940e-01, 9.9754e-01,
          9.9744e-01, 9.9747e-01, 9.9820e-01, 9.9742e-01, 9.9903e-01,
          9.9601e-01, 9.8884e-01, 9.9892e-01, 9.9498e-01, 9.9330e-01,
          8.8720e-01],
         [9.7530e-01, 9.9528e-01, 9.9277e-01, 9.3597e-01, 6.7122e-01,
          9.2597e-01, 8.3539e-01, 9.3500e-01, 7.3942e-01, 9.4350e-01,
          8.1952e-01, 8.8822e-01, 3.7578e-01, 9.7471e-01, 9.4942e-01,
          9.2563e-01]],

        [[7.7793e-03, 1.7561e-03, 8.8998e-01, 1.4153e-02, 1.0254e-01,
          7.5527e-03, 4.0555e-03, 5.8224e-02, 9.8634e-01, 9.8545e-01,
          9.7137e-01, 1.1622e-02, 2.7179e-03, 6.1287e-03, 9.7970e-01,
          1.3546e-02],
         [1.9055e-02, 9.9923e-01, 9.9988e-01, 9.9997e-01, 5.2241e-01,
          9.8072e-01, 9.8668e-01, 9.9891e-01, 9.9929e-01, 9.9999e-01,
          9.9622e-01, 9.7363e-01, 9.6992e-01, 9.9986e-01, 9.9993e-01,
          9.9473e-01],
         [9.9574e-01, 9.9989e-01, 9.9999e-01, 9.9991e-01, 9.9778e-01,
          9.8506e-01, 9.9950e-01, 9.9996e-01, 1.0000e+00, 9.9951e-01,
          9.9479e-01, 9.5429e-01, 9.9989e-01, 9.9996e-01, 9.9998e-01,
          9.9395e-01],
         [9.8937e-01, 9.9995e-01, 9.9958e-01, 9.9828e-01, 8.4373e-01,
          7.3124e-01, 9.5212e-01, 9.9412e-01, 9.7829e-01, 9.5666e-01,
          4.4114e-02, 3.0028e-02, 9.8487e-01, 9.9966e-01, 9.9880e-01,
          9.4289e-01],
         [9.9486e-01, 9.9923e-01, 9.9848e-01, 9.5865e-01, 2.9351e-01,
          4.2937e-01, 8.5831e-01, 9.4491e-01, 9.6824e-01, 2.2625e-02,
          7.1464e-03, 1.2775e-02, 9.8595e-01, 9.9967e-01, 9.9951e-01,
          7.3752e-01],
         [9.8013e-01, 9.8920e-01, 9.8353e-01, 1.1831e-02, 6.2856e-02,
          1.6559e-01, 7.9895e-01, 1.0121e-01, 3.6173e-01, 9.7880e-03,
          2.4477e-03, 1.0552e-02, 9.7300e-01, 9.8898e-01, 9.9634e-01,
          2.3051e-01],
         [4.1584e-02, 4.9345e-01, 9.1808e-01, 9.6790e-03, 3.5578e-01,
          4.4251e-01, 9.3189e-01, 9.2758e-01, 9.1732e-01, 9.4773e-02,
          1.2430e-02, 3.4896e-01, 9.9601e-01, 9.8975e-01, 9.7171e-01,
          2.6519e-03],
         [1.4690e-02, 9.9904e-01, 9.9890e-01, 9.8950e-01, 9.9845e-01,
          9.9767e-01, 9.9886e-01, 9.9855e-01, 9.9505e-01, 9.8989e-01,
          9.9069e-01, 9.9814e-01, 9.9924e-01, 9.9968e-01, 9.9221e-01,
          4.0193e-03],
         [5.2660e-01, 9.9955e-01, 9.9998e-01, 9.9860e-01, 9.9742e-01,
          9.9773e-01, 9.9771e-01, 9.9583e-01, 9.9824e-01, 9.5245e-01,
          9.7215e-01, 9.9108e-01, 9.9959e-01, 9.9981e-01, 9.9804e-01,
          2.0885e-02],
         [9.9424e-01, 9.9998e-01, 9.9995e-01, 9.8141e-01, 5.3427e-01,
          2.6818e-02, 4.0994e-02, 3.4823e-02, 2.3302e-02, 5.7232e-03,
          2.3026e-03, 9.1959e-01, 9.9165e-01, 9.9982e-01, 9.9772e-01,
          9.7975e-01],
         [9.9510e-01, 9.9762e-01, 9.9909e-01, 4.8216e-03, 1.9023e-03,
          1.4395e-03, 2.8879e-03, 1.4229e-03, 2.3017e-03, 2.1338e-04,
          9.4357e-04, 1.6756e-02, 5.6596e-01, 9.9876e-01, 9.9686e-01,
          1.8323e-01],
         [9.6937e-02, 9.9802e-01, 9.2332e-02, 1.6626e-03, 6.4719e-04,
          1.0025e-03, 1.4385e-03, 2.8310e-03, 3.6630e-04, 1.0218e-03,
          1.2708e-03, 6.8777e-03, 3.3018e-03, 9.5643e-01, 9.7473e-01,
          5.6044e-03],
         [1.7505e-02, 9.2712e-01, 8.6109e-03, 8.6863e-03, 2.8804e-03,
          3.5459e-03, 4.3978e-03, 4.6480e-03, 6.0485e-03, 4.5656e-03,
          1.3516e-03, 7.4914e-04, 6.2831e-03, 9.8658e-01, 9.8608e-01,
          5.0148e-03],
         [3.4440e-02, 9.9569e-01, 9.7961e-01, 1.1886e-02, 6.7390e-03,
          2.0262e-02, 3.3031e-02, 6.0371e-03, 7.2263e-03, 4.3151e-02,
          1.0736e-02, 5.8637e-03, 1.3100e-01, 9.9779e-01, 9.9735e-01,
          9.9262e-01],
         [9.9574e-01, 9.9269e-01, 9.9278e-01, 2.7126e-01, 1.0934e-01,
          3.6462e-02, 2.6018e-02, 3.1478e-02, 4.8590e-02, 1.7703e-02,
          9.4722e-03, 3.1553e-02, 3.3532e-01, 9.9859e-01, 9.9880e-01,
          9.8549e-01],
         [9.8382e-01, 9.8312e-01, 1.0025e-02, 2.2819e-03, 1.1329e-03,
          1.6590e-03, 1.6848e-03, 1.9512e-03, 1.6252e-03, 2.6351e-03,
          2.3704e-03, 1.3310e-03, 7.2236e-03, 2.3722e-02, 9.6243e-01,
          9.7625e-01]],

        [[3.5290e-02, 9.6662e-01, 9.9313e-01, 9.1806e-01, 9.7588e-01,
          1.5879e-02, 5.7696e-03, 2.2865e-01, 9.4318e-01, 9.9423e-01,
          9.8171e-01, 7.8121e-01, 7.6090e-02, 9.9212e-01, 9.9859e-01,
          7.1297e-01],
         [9.9452e-01, 9.9863e-01, 9.9999e-01, 9.9960e-01, 9.3859e-01,
          2.6860e-03, 5.0231e-01, 9.8522e-01, 9.9686e-01, 9.9819e-01,
          9.9560e-01, 9.7345e-01, 9.9894e-01, 9.9973e-01, 9.9999e-01,
          9.9965e-01],
         [9.9694e-01, 9.9990e-01, 9.9998e-01, 9.9589e-01, 5.1609e-02,
          2.1443e-03, 8.9581e-03, 9.1725e-01, 9.8614e-01, 9.5306e-01,
          5.1078e-03, 1.2842e-02, 9.9354e-01, 9.9970e-01, 9.9997e-01,
          9.9750e-01],
         [7.9180e-01, 9.9908e-01, 9.9810e-01, 6.2727e-03, 2.7090e-04,
          1.1829e-04, 2.8074e-04, 1.0780e-03, 1.2451e-03, 1.1519e-03,
          2.1631e-04, 3.4818e-04, 2.0837e-02, 9.9750e-01, 9.9361e-01,
          2.3273e-01],
         [4.3778e-01, 9.6297e-01, 7.5883e-01, 2.1856e-03, 6.9290e-05,
          4.8399e-05, 2.0644e-04, 1.1307e-03, 1.2422e-04, 2.3776e-04,
          3.2753e-05, 2.2420e-04, 5.7785e-03, 9.8898e-01, 9.0487e-01,
          2.1358e-02],
         [9.4732e-03, 2.7638e-03, 6.6611e-04, 4.8301e-04, 1.4767e-04,
          1.4395e-04, 9.2438e-04, 2.1625e-03, 1.0055e-03, 8.9645e-05,
          7.8470e-05, 2.5749e-05, 3.0001e-03, 1.6765e-02, 8.4317e-04,
          5.6174e-04],
         [4.7231e-04, 5.4723e-04, 1.1925e-03, 2.1592e-04, 5.8183e-04,
          1.3845e-03, 3.6158e-03, 6.9131e-03, 2.4435e-03, 2.5782e-03,
          1.0514e-04, 5.1419e-03, 3.7706e-02, 4.4126e-03, 7.1386e-04,
          4.9591e-05],
         [7.9131e-03, 1.5098e-03, 3.6808e-03, 2.5317e-04, 9.5636e-05,
          6.4999e-05, 9.6917e-05, 8.9240e-04, 2.0254e-04, 1.2998e-03,
          2.9755e-03, 1.7821e-02, 2.0855e-01, 6.5131e-02, 3.3575e-03,
          5.8171e-04],
         [1.8930e-02, 9.9359e-01, 9.9566e-01, 1.9476e-02, 1.4903e-02,
          1.0400e-03, 1.0342e-03, 2.5038e-03, 3.7253e-03, 3.9652e-03,
          2.1050e-02, 6.4353e-01, 9.4247e-01, 9.9603e-01, 1.0778e-01,
          1.3114e-03],
         [9.9682e-01, 9.9994e-01, 9.9839e-01, 9.6857e-01, 5.7712e-03,
          1.0545e-03, 1.3518e-04, 6.9022e-03, 5.0795e-04, 1.2213e-02,
          3.9306e-04, 4.1898e-02, 8.7051e-02, 9.9440e-01, 4.8014e-02,
          2.3115e-02],
         [9.9629e-01, 9.9860e-01, 9.9396e-01, 2.6561e-03, 3.8403e-04,
          9.9897e-05, 1.3942e-04, 5.1585e-04, 3.4645e-04, 8.3661e-04,
          1.5205e-04, 8.4439e-03, 2.4234e-01, 1.6073e-01, 3.3668e-02,
          3.5608e-03],
         [9.8289e-01, 9.8977e-01, 3.7094e-01, 2.3583e-04, 1.9938e-04,
          3.8531e-04, 1.2452e-03, 1.4531e-03, 4.6917e-03, 7.8446e-04,
          3.6460e-03, 2.5685e-03, 1.2114e-01, 3.8303e-02, 7.5492e-02,
          5.0359e-03],
         [2.5978e-01, 9.9828e-01, 9.1211e-01, 1.6853e-02, 1.2082e-02,
          6.3123e-03, 3.7153e-02, 5.2198e-01, 2.7721e-01, 1.1385e-01,
          8.6536e-02, 8.0117e-01, 5.9535e-01, 9.9946e-01, 9.9265e-01,
          2.1358e-02],
         [9.9423e-01, 9.9954e-01, 9.9947e-01, 9.9115e-01, 9.4190e-01,
          9.4412e-01, 9.8278e-01, 9.8789e-01, 9.8552e-01, 9.7898e-01,
          9.8368e-01, 9.8675e-01, 9.9732e-01, 9.9982e-01, 9.9971e-01,
          9.9576e-01],
         [9.9831e-01, 9.9621e-01, 9.8039e-01, 1.1401e-01, 6.9495e-02,
          8.6724e-02, 7.1552e-02, 1.9478e-01, 1.6923e-01, 4.5313e-01,
          6.8062e-02, 3.3282e-01, 9.7994e-01, 9.8355e-01, 9.9757e-01,
          9.8598e-01],
         [9.8378e-01, 9.5789e-01, 2.2231e-02, 4.5475e-04, 2.8020e-04,
          1.1752e-03, 9.0054e-04, 7.8806e-04, 1.4855e-03, 2.8524e-03,
          1.6847e-03, 1.4092e-03, 4.8434e-03, 1.1425e-01, 8.6474e-01,
          9.6357e-01]]], device='cuda:0')}}
BEST PATCh: tensor([[[2.7007e-02, 9.2527e-01, 9.9101e-01, 9.8900e-01, 9.2892e-01,
          1.1232e-02, 1.6305e-03, 2.4754e-03, 6.5699e-02, 1.2100e-01,
          5.3305e-01, 1.0585e-02, 1.3368e-03, 9.7124e-01, 9.9557e-01,
          9.7741e-01],
         [4.0283e-01, 9.9752e-01, 9.9903e-01, 9.9712e-01, 3.6566e-02,
          2.0584e-03, 6.6072e-05, 2.6300e-02, 4.0533e-02, 9.6512e-01,
          6.1660e-03, 2.6535e-03, 1.2255e-02, 9.9974e-01, 9.9964e-01,
          9.9536e-01],
         [8.0452e-01, 9.9944e-01, 9.9980e-01, 9.9433e-01, 1.7177e-02,
          1.6272e-03, 7.9992e-04, 1.0929e-02, 5.9841e-02, 1.9912e-03,
          1.9729e-04, 2.5359e-03, 2.8666e-02, 9.9976e-01, 9.9929e-01,
          9.9703e-01],
         [3.7602e-02, 9.9698e-01, 9.9078e-01, 1.3849e-02, 3.6007e-04,
          1.3001e-03, 1.1539e-03, 1.2769e-03, 1.0759e-03, 7.2223e-04,
          6.7487e-04, 2.2527e-03, 1.6367e-02, 9.9311e-01, 9.7869e-01,
          1.1359e-01],
         [5.9209e-02, 1.0893e-02, 7.6793e-03, 5.4383e-04, 2.7645e-04,
          1.9047e-03, 7.5072e-05, 1.6356e-04, 3.1173e-05, 2.6584e-05,
          4.6492e-06, 3.0130e-04, 4.6327e-03, 3.5526e-01, 3.9688e-02,
          7.0840e-03],
         [4.7475e-04, 7.2208e-04, 1.7038e-03, 1.1732e-03, 2.9391e-04,
          2.8397e-03, 9.8193e-04, 4.2810e-03, 6.1220e-04, 2.5769e-03,
          2.6959e-04, 1.7959e-03, 1.2957e-02, 1.9760e-02, 8.8450e-04,
          3.0228e-04],
         [1.3489e-04, 9.5308e-05, 6.8247e-05, 3.1897e-04, 1.9798e-04,
          6.7198e-04, 1.0265e-03, 2.9309e-03, 1.2197e-03, 1.9696e-04,
          2.6181e-04, 2.2684e-02, 5.1692e-02, 5.8687e-02, 7.5310e-05,
          4.0603e-04],
         [5.1633e-04, 5.6556e-04, 2.1897e-03, 2.0781e-03, 4.1032e-04,
          2.0909e-03, 8.3780e-04, 1.7401e-02, 2.9340e-03, 2.3156e-03,
          8.2877e-04, 5.0971e-01, 9.8070e-01, 7.7087e-02, 8.1477e-04,
          7.4965e-04],
         [3.4512e-03, 5.5790e-01, 9.6498e-01, 5.9383e-01, 5.8450e-03,
          4.0106e-01, 1.0405e-02, 1.3435e-01, 1.1163e-02, 3.3592e-02,
          2.7501e-02, 9.8745e-01, 9.9915e-01, 9.9550e-01, 4.3179e-03,
          6.1064e-03],
         [3.2022e-02, 9.9984e-01, 9.9729e-01, 9.8673e-01, 1.3313e-02,
          6.9110e-01, 1.9238e-01, 8.1039e-01, 1.1442e-01, 7.1918e-01,
          1.5755e-01, 9.8984e-01, 9.8800e-01, 9.9301e-01, 5.6706e-01,
          1.7443e-02],
         [4.4250e-02, 9.7273e-01, 6.9799e-01, 3.6130e-02, 3.1298e-04,
          1.5511e-03, 4.9976e-04, 7.2706e-03, 1.8784e-03, 1.9317e-03,
          1.0647e-03, 1.8497e-02, 3.1554e-01, 9.3652e-01, 6.3778e-03,
          9.4019e-03],
         [2.2591e-02, 2.6541e-02, 9.6617e-01, 1.1303e-02, 3.4646e-03,
          4.3230e-03, 1.3763e-02, 3.1812e-01, 1.9971e-01, 1.1287e-02,
          1.6169e-02, 2.2158e-01, 9.4797e-01, 1.1390e-01, 2.3386e-02,
          5.2782e-03],
         [3.5247e-03, 3.3405e-02, 7.2962e-01, 2.1862e-01, 6.7165e-01,
          6.9247e-01, 9.8340e-01, 9.6739e-01, 9.8820e-01, 8.9898e-01,
          9.8133e-01, 4.9541e-01, 9.9779e-01, 9.7572e-01, 3.5634e-01,
          7.9601e-03],
         [4.4210e-02, 9.9791e-01, 9.9868e-01, 9.9751e-01, 9.9280e-01,
          9.9836e-01, 9.9827e-01, 9.9825e-01, 9.9664e-01, 9.9820e-01,
          9.9675e-01, 9.9626e-01, 9.9619e-01, 9.9896e-01, 9.9818e-01,
          5.8437e-01],
         [8.0006e-01, 9.9994e-01, 9.9781e-01, 9.9940e-01, 9.9754e-01,
          9.9744e-01, 9.9747e-01, 9.9820e-01, 9.9742e-01, 9.9903e-01,
          9.9601e-01, 9.8884e-01, 9.9892e-01, 9.9498e-01, 9.9330e-01,
          8.8720e-01],
         [9.7530e-01, 9.9528e-01, 9.9277e-01, 9.3597e-01, 6.7122e-01,
          9.2597e-01, 8.3539e-01, 9.3500e-01, 7.3942e-01, 9.4350e-01,
          8.1952e-01, 8.8822e-01, 3.7578e-01, 9.7471e-01, 9.4942e-01,
          9.2563e-01]],

        [[7.7793e-03, 1.7561e-03, 8.8998e-01, 1.4153e-02, 1.0254e-01,
          7.5527e-03, 4.0555e-03, 5.8224e-02, 9.8634e-01, 9.8545e-01,
          9.7137e-01, 1.1622e-02, 2.7179e-03, 6.1287e-03, 9.7970e-01,
          1.3546e-02],
         [1.9055e-02, 9.9923e-01, 9.9988e-01, 9.9997e-01, 5.2241e-01,
          9.8072e-01, 9.8668e-01, 9.9891e-01, 9.9929e-01, 9.9999e-01,
          9.9622e-01, 9.7363e-01, 9.6992e-01, 9.9986e-01, 9.9993e-01,
          9.9473e-01],
         [9.9574e-01, 9.9989e-01, 9.9999e-01, 9.9991e-01, 9.9778e-01,
          9.8506e-01, 9.9950e-01, 9.9996e-01, 1.0000e+00, 9.9951e-01,
          9.9479e-01, 9.5429e-01, 9.9989e-01, 9.9996e-01, 9.9998e-01,
          9.9395e-01],
         [9.8937e-01, 9.9995e-01, 9.9958e-01, 9.9828e-01, 8.4373e-01,
          7.3124e-01, 9.5212e-01, 9.9412e-01, 9.7829e-01, 9.5666e-01,
          4.4114e-02, 3.0028e-02, 9.8487e-01, 9.9966e-01, 9.9880e-01,
          9.4289e-01],
         [9.9486e-01, 9.9923e-01, 9.9848e-01, 9.5865e-01, 2.9351e-01,
          4.2937e-01, 8.5831e-01, 9.4491e-01, 9.6824e-01, 2.2625e-02,
          7.1464e-03, 1.2775e-02, 9.8595e-01, 9.9967e-01, 9.9951e-01,
          7.3752e-01],
         [9.8013e-01, 9.8920e-01, 9.8353e-01, 1.1831e-02, 6.2856e-02,
          1.6559e-01, 7.9895e-01, 1.0121e-01, 3.6173e-01, 9.7880e-03,
          2.4477e-03, 1.0552e-02, 9.7300e-01, 9.8898e-01, 9.9634e-01,
          2.3051e-01],
         [4.1584e-02, 4.9345e-01, 9.1808e-01, 9.6790e-03, 3.5578e-01,
          4.4251e-01, 9.3189e-01, 9.2758e-01, 9.1732e-01, 9.4773e-02,
          1.2430e-02, 3.4896e-01, 9.9601e-01, 9.8975e-01, 9.7171e-01,
          2.6519e-03],
         [1.4690e-02, 9.9904e-01, 9.9890e-01, 9.8950e-01, 9.9845e-01,
          9.9767e-01, 9.9886e-01, 9.9855e-01, 9.9505e-01, 9.8989e-01,
          9.9069e-01, 9.9814e-01, 9.9924e-01, 9.9968e-01, 9.9221e-01,
          4.0193e-03],
         [5.2660e-01, 9.9955e-01, 9.9998e-01, 9.9860e-01, 9.9742e-01,
          9.9773e-01, 9.9771e-01, 9.9583e-01, 9.9824e-01, 9.5245e-01,
          9.7215e-01, 9.9108e-01, 9.9959e-01, 9.9981e-01, 9.9804e-01,
          2.0885e-02],
         [9.9424e-01, 9.9998e-01, 9.9995e-01, 9.8141e-01, 5.3427e-01,
          2.6818e-02, 4.0994e-02, 3.4823e-02, 2.3302e-02, 5.7232e-03,
          2.3026e-03, 9.1959e-01, 9.9165e-01, 9.9982e-01, 9.9772e-01,
          9.7975e-01],
         [9.9510e-01, 9.9762e-01, 9.9909e-01, 4.8216e-03, 1.9023e-03,
          1.4395e-03, 2.8879e-03, 1.4229e-03, 2.3017e-03, 2.1338e-04,
          9.4357e-04, 1.6756e-02, 5.6596e-01, 9.9876e-01, 9.9686e-01,
          1.8323e-01],
         [9.6937e-02, 9.9802e-01, 9.2332e-02, 1.6626e-03, 6.4719e-04,
          1.0025e-03, 1.4385e-03, 2.8310e-03, 3.6630e-04, 1.0218e-03,
          1.2708e-03, 6.8777e-03, 3.3018e-03, 9.5643e-01, 9.7473e-01,
          5.6044e-03],
         [1.7505e-02, 9.2712e-01, 8.6109e-03, 8.6863e-03, 2.8804e-03,
          3.5459e-03, 4.3978e-03, 4.6480e-03, 6.0485e-03, 4.5656e-03,
          1.3516e-03, 7.4914e-04, 6.2831e-03, 9.8658e-01, 9.8608e-01,
          5.0148e-03],
         [3.4440e-02, 9.9569e-01, 9.7961e-01, 1.1886e-02, 6.7390e-03,
          2.0262e-02, 3.3031e-02, 6.0371e-03, 7.2263e-03, 4.3151e-02,
          1.0736e-02, 5.8637e-03, 1.3100e-01, 9.9779e-01, 9.9735e-01,
          9.9262e-01],
         [9.9574e-01, 9.9269e-01, 9.9278e-01, 2.7126e-01, 1.0934e-01,
          3.6462e-02, 2.6018e-02, 3.1478e-02, 4.8590e-02, 1.7703e-02,
          9.4722e-03, 3.1553e-02, 3.3532e-01, 9.9859e-01, 9.9880e-01,
          9.8549e-01],
         [9.8382e-01, 9.8312e-01, 1.0025e-02, 2.2819e-03, 1.1329e-03,
          1.6590e-03, 1.6848e-03, 1.9512e-03, 1.6252e-03, 2.6351e-03,
          2.3704e-03, 1.3310e-03, 7.2236e-03, 2.3722e-02, 9.6243e-01,
          9.7625e-01]],

        [[3.5290e-02, 9.6662e-01, 9.9313e-01, 9.1806e-01, 9.7588e-01,
          1.5879e-02, 5.7696e-03, 2.2865e-01, 9.4318e-01, 9.9423e-01,
          9.8171e-01, 7.8121e-01, 7.6090e-02, 9.9212e-01, 9.9859e-01,
          7.1297e-01],
         [9.9452e-01, 9.9863e-01, 9.9999e-01, 9.9960e-01, 9.3859e-01,
          2.6860e-03, 5.0231e-01, 9.8522e-01, 9.9686e-01, 9.9819e-01,
          9.9560e-01, 9.7345e-01, 9.9894e-01, 9.9973e-01, 9.9999e-01,
          9.9965e-01],
         [9.9694e-01, 9.9990e-01, 9.9998e-01, 9.9589e-01, 5.1609e-02,
          2.1443e-03, 8.9581e-03, 9.1725e-01, 9.8614e-01, 9.5306e-01,
          5.1078e-03, 1.2842e-02, 9.9354e-01, 9.9970e-01, 9.9997e-01,
          9.9750e-01],
         [7.9180e-01, 9.9908e-01, 9.9810e-01, 6.2727e-03, 2.7090e-04,
          1.1829e-04, 2.8074e-04, 1.0780e-03, 1.2451e-03, 1.1519e-03,
          2.1631e-04, 3.4818e-04, 2.0837e-02, 9.9750e-01, 9.9361e-01,
          2.3273e-01],
         [4.3778e-01, 9.6297e-01, 7.5883e-01, 2.1856e-03, 6.9290e-05,
          4.8399e-05, 2.0644e-04, 1.1307e-03, 1.2422e-04, 2.3776e-04,
          3.2753e-05, 2.2420e-04, 5.7785e-03, 9.8898e-01, 9.0487e-01,
          2.1358e-02],
         [9.4732e-03, 2.7638e-03, 6.6611e-04, 4.8301e-04, 1.4767e-04,
          1.4395e-04, 9.2438e-04, 2.1625e-03, 1.0055e-03, 8.9645e-05,
          7.8470e-05, 2.5749e-05, 3.0001e-03, 1.6765e-02, 8.4317e-04,
          5.6174e-04],
         [4.7231e-04, 5.4723e-04, 1.1925e-03, 2.1592e-04, 5.8183e-04,
          1.3845e-03, 3.6158e-03, 6.9131e-03, 2.4435e-03, 2.5782e-03,
          1.0514e-04, 5.1419e-03, 3.7706e-02, 4.4126e-03, 7.1386e-04,
          4.9591e-05],
         [7.9131e-03, 1.5098e-03, 3.6808e-03, 2.5317e-04, 9.5636e-05,
          6.4999e-05, 9.6917e-05, 8.9240e-04, 2.0254e-04, 1.2998e-03,
          2.9755e-03, 1.7821e-02, 2.0855e-01, 6.5131e-02, 3.3575e-03,
          5.8171e-04],
         [1.8930e-02, 9.9359e-01, 9.9566e-01, 1.9476e-02, 1.4903e-02,
          1.0400e-03, 1.0342e-03, 2.5038e-03, 3.7253e-03, 3.9652e-03,
          2.1050e-02, 6.4353e-01, 9.4247e-01, 9.9603e-01, 1.0778e-01,
          1.3114e-03],
         [9.9682e-01, 9.9994e-01, 9.9839e-01, 9.6857e-01, 5.7712e-03,
          1.0545e-03, 1.3518e-04, 6.9022e-03, 5.0795e-04, 1.2213e-02,
          3.9306e-04, 4.1898e-02, 8.7051e-02, 9.9440e-01, 4.8014e-02,
          2.3115e-02],
         [9.9629e-01, 9.9860e-01, 9.9396e-01, 2.6561e-03, 3.8403e-04,
          9.9897e-05, 1.3942e-04, 5.1585e-04, 3.4645e-04, 8.3661e-04,
          1.5205e-04, 8.4439e-03, 2.4234e-01, 1.6073e-01, 3.3668e-02,
          3.5608e-03],
         [9.8289e-01, 9.8977e-01, 3.7094e-01, 2.3583e-04, 1.9938e-04,
          3.8531e-04, 1.2452e-03, 1.4531e-03, 4.6917e-03, 7.8446e-04,
          3.6460e-03, 2.5685e-03, 1.2114e-01, 3.8303e-02, 7.5492e-02,
          5.0359e-03],
         [2.5978e-01, 9.9828e-01, 9.1211e-01, 1.6853e-02, 1.2082e-02,
          6.3123e-03, 3.7153e-02, 5.2198e-01, 2.7721e-01, 1.1385e-01,
          8.6536e-02, 8.0117e-01, 5.9535e-01, 9.9946e-01, 9.9265e-01,
          2.1358e-02],
         [9.9423e-01, 9.9954e-01, 9.9947e-01, 9.9115e-01, 9.4190e-01,
          9.4412e-01, 9.8278e-01, 9.8789e-01, 9.8552e-01, 9.7898e-01,
          9.8368e-01, 9.8675e-01, 9.9732e-01, 9.9982e-01, 9.9971e-01,
          9.9576e-01],
         [9.9831e-01, 9.9621e-01, 9.8039e-01, 1.1401e-01, 6.9495e-02,
          8.6724e-02, 7.1552e-02, 1.9478e-01, 1.6923e-01, 4.5313e-01,
          6.8062e-02, 3.3282e-01, 9.7994e-01, 9.8355e-01, 9.9757e-01,
          9.8598e-01],
         [9.8378e-01, 9.5789e-01, 2.2231e-02, 4.5475e-04, 2.8020e-04,
          1.1752e-03, 9.0054e-04, 7.8806e-04, 1.4855e-03, 2.8524e-03,
          1.6847e-03, 1.4092e-03, 4.8434e-03, 1.1425e-01, 8.6474e-01,
          9.6357e-01]]], device='cuda:0')
The generator was trained on: vit_b_16.
Target class: "pretzel" (932)
The generated adversarial patch on model vit_b_16 had 1 misclassifications
ASR for target model vit_b_16: 0.05%
BEST PATCh: tensor([[[2.7007e-02, 9.2527e-01, 9.9101e-01, 9.8900e-01, 9.2892e-01,
          1.1232e-02, 1.6305e-03, 2.4754e-03, 6.5699e-02, 1.2100e-01,
          5.3305e-01, 1.0585e-02, 1.3368e-03, 9.7124e-01, 9.9557e-01,
          9.7741e-01],
         [4.0283e-01, 9.9752e-01, 9.9903e-01, 9.9712e-01, 3.6566e-02,
          2.0584e-03, 6.6072e-05, 2.6300e-02, 4.0533e-02, 9.6512e-01,
          6.1660e-03, 2.6535e-03, 1.2255e-02, 9.9974e-01, 9.9964e-01,
          9.9536e-01],
         [8.0452e-01, 9.9944e-01, 9.9980e-01, 9.9433e-01, 1.7177e-02,
          1.6272e-03, 7.9992e-04, 1.0929e-02, 5.9841e-02, 1.9912e-03,
          1.9729e-04, 2.5359e-03, 2.8666e-02, 9.9976e-01, 9.9929e-01,
          9.9703e-01],
         [3.7602e-02, 9.9698e-01, 9.9078e-01, 1.3849e-02, 3.6007e-04,
          1.3001e-03, 1.1539e-03, 1.2769e-03, 1.0759e-03, 7.2223e-04,
          6.7487e-04, 2.2527e-03, 1.6367e-02, 9.9311e-01, 9.7869e-01,
          1.1359e-01],
         [5.9209e-02, 1.0893e-02, 7.6793e-03, 5.4383e-04, 2.7645e-04,
          1.9047e-03, 7.5072e-05, 1.6356e-04, 3.1173e-05, 2.6584e-05,
          4.6492e-06, 3.0130e-04, 4.6327e-03, 3.5526e-01, 3.9688e-02,
          7.0840e-03],
         [4.7475e-04, 7.2208e-04, 1.7038e-03, 1.1732e-03, 2.9391e-04,
          2.8397e-03, 9.8193e-04, 4.2810e-03, 6.1220e-04, 2.5769e-03,
          2.6959e-04, 1.7959e-03, 1.2957e-02, 1.9760e-02, 8.8450e-04,
          3.0228e-04],
         [1.3489e-04, 9.5308e-05, 6.8247e-05, 3.1897e-04, 1.9798e-04,
          6.7198e-04, 1.0265e-03, 2.9309e-03, 1.2197e-03, 1.9696e-04,
          2.6181e-04, 2.2684e-02, 5.1692e-02, 5.8687e-02, 7.5310e-05,
          4.0603e-04],
         [5.1633e-04, 5.6556e-04, 2.1897e-03, 2.0781e-03, 4.1032e-04,
          2.0909e-03, 8.3780e-04, 1.7401e-02, 2.9340e-03, 2.3156e-03,
          8.2877e-04, 5.0971e-01, 9.8070e-01, 7.7087e-02, 8.1477e-04,
          7.4965e-04],
         [3.4512e-03, 5.5790e-01, 9.6498e-01, 5.9383e-01, 5.8450e-03,
          4.0106e-01, 1.0405e-02, 1.3435e-01, 1.1163e-02, 3.3592e-02,
          2.7501e-02, 9.8745e-01, 9.9915e-01, 9.9550e-01, 4.3179e-03,
          6.1064e-03],
         [3.2022e-02, 9.9984e-01, 9.9729e-01, 9.8673e-01, 1.3313e-02,
          6.9110e-01, 1.9238e-01, 8.1039e-01, 1.1442e-01, 7.1918e-01,
          1.5755e-01, 9.8984e-01, 9.8800e-01, 9.9301e-01, 5.6706e-01,
          1.7443e-02],
         [4.4250e-02, 9.7273e-01, 6.9799e-01, 3.6130e-02, 3.1298e-04,
          1.5511e-03, 4.9976e-04, 7.2706e-03, 1.8784e-03, 1.9317e-03,
          1.0647e-03, 1.8497e-02, 3.1554e-01, 9.3652e-01, 6.3778e-03,
          9.4019e-03],
         [2.2591e-02, 2.6541e-02, 9.6617e-01, 1.1303e-02, 3.4646e-03,
          4.3230e-03, 1.3763e-02, 3.1812e-01, 1.9971e-01, 1.1287e-02,
          1.6169e-02, 2.2158e-01, 9.4797e-01, 1.1390e-01, 2.3386e-02,
          5.2782e-03],
         [3.5247e-03, 3.3405e-02, 7.2962e-01, 2.1862e-01, 6.7165e-01,
          6.9247e-01, 9.8340e-01, 9.6739e-01, 9.8820e-01, 8.9898e-01,
          9.8133e-01, 4.9541e-01, 9.9779e-01, 9.7572e-01, 3.5634e-01,
          7.9601e-03],
         [4.4210e-02, 9.9791e-01, 9.9868e-01, 9.9751e-01, 9.9280e-01,
          9.9836e-01, 9.9827e-01, 9.9825e-01, 9.9664e-01, 9.9820e-01,
          9.9675e-01, 9.9626e-01, 9.9619e-01, 9.9896e-01, 9.9818e-01,
          5.8437e-01],
         [8.0006e-01, 9.9994e-01, 9.9781e-01, 9.9940e-01, 9.9754e-01,
          9.9744e-01, 9.9747e-01, 9.9820e-01, 9.9742e-01, 9.9903e-01,
          9.9601e-01, 9.8884e-01, 9.9892e-01, 9.9498e-01, 9.9330e-01,
          8.8720e-01],
         [9.7530e-01, 9.9528e-01, 9.9277e-01, 9.3597e-01, 6.7122e-01,
          9.2597e-01, 8.3539e-01, 9.3500e-01, 7.3942e-01, 9.4350e-01,
          8.1952e-01, 8.8822e-01, 3.7578e-01, 9.7471e-01, 9.4942e-01,
          9.2563e-01]],

        [[7.7793e-03, 1.7561e-03, 8.8998e-01, 1.4153e-02, 1.0254e-01,
          7.5527e-03, 4.0555e-03, 5.8224e-02, 9.8634e-01, 9.8545e-01,
          9.7137e-01, 1.1622e-02, 2.7179e-03, 6.1287e-03, 9.7970e-01,
          1.3546e-02],
         [1.9055e-02, 9.9923e-01, 9.9988e-01, 9.9997e-01, 5.2241e-01,
          9.8072e-01, 9.8668e-01, 9.9891e-01, 9.9929e-01, 9.9999e-01,
          9.9622e-01, 9.7363e-01, 9.6992e-01, 9.9986e-01, 9.9993e-01,
          9.9473e-01],
         [9.9574e-01, 9.9989e-01, 9.9999e-01, 9.9991e-01, 9.9778e-01,
          9.8506e-01, 9.9950e-01, 9.9996e-01, 1.0000e+00, 9.9951e-01,
          9.9479e-01, 9.5429e-01, 9.9989e-01, 9.9996e-01, 9.9998e-01,
          9.9395e-01],
         [9.8937e-01, 9.9995e-01, 9.9958e-01, 9.9828e-01, 8.4373e-01,
          7.3124e-01, 9.5212e-01, 9.9412e-01, 9.7829e-01, 9.5666e-01,
          4.4114e-02, 3.0028e-02, 9.8487e-01, 9.9966e-01, 9.9880e-01,
          9.4289e-01],
         [9.9486e-01, 9.9923e-01, 9.9848e-01, 9.5865e-01, 2.9351e-01,
          4.2937e-01, 8.5831e-01, 9.4491e-01, 9.6824e-01, 2.2625e-02,
          7.1464e-03, 1.2775e-02, 9.8595e-01, 9.9967e-01, 9.9951e-01,
          7.3752e-01],
         [9.8013e-01, 9.8920e-01, 9.8353e-01, 1.1831e-02, 6.2856e-02,
          1.6559e-01, 7.9895e-01, 1.0121e-01, 3.6173e-01, 9.7880e-03,
          2.4477e-03, 1.0552e-02, 9.7300e-01, 9.8898e-01, 9.9634e-01,
          2.3051e-01],
         [4.1584e-02, 4.9345e-01, 9.1808e-01, 9.6790e-03, 3.5578e-01,
          4.4251e-01, 9.3189e-01, 9.2758e-01, 9.1732e-01, 9.4773e-02,
          1.2430e-02, 3.4896e-01, 9.9601e-01, 9.8975e-01, 9.7171e-01,
          2.6519e-03],
         [1.4690e-02, 9.9904e-01, 9.9890e-01, 9.8950e-01, 9.9845e-01,
          9.9767e-01, 9.9886e-01, 9.9855e-01, 9.9505e-01, 9.8989e-01,
          9.9069e-01, 9.9814e-01, 9.9924e-01, 9.9968e-01, 9.9221e-01,
          4.0193e-03],
         [5.2660e-01, 9.9955e-01, 9.9998e-01, 9.9860e-01, 9.9742e-01,
          9.9773e-01, 9.9771e-01, 9.9583e-01, 9.9824e-01, 9.5245e-01,
          9.7215e-01, 9.9108e-01, 9.9959e-01, 9.9981e-01, 9.9804e-01,
          2.0885e-02],
         [9.9424e-01, 9.9998e-01, 9.9995e-01, 9.8141e-01, 5.3427e-01,
          2.6818e-02, 4.0994e-02, 3.4823e-02, 2.3302e-02, 5.7232e-03,
          2.3026e-03, 9.1959e-01, 9.9165e-01, 9.9982e-01, 9.9772e-01,
          9.7975e-01],
         [9.9510e-01, 9.9762e-01, 9.9909e-01, 4.8216e-03, 1.9023e-03,
          1.4395e-03, 2.8879e-03, 1.4229e-03, 2.3017e-03, 2.1338e-04,
          9.4357e-04, 1.6756e-02, 5.6596e-01, 9.9876e-01, 9.9686e-01,
          1.8323e-01],
         [9.6937e-02, 9.9802e-01, 9.2332e-02, 1.6626e-03, 6.4719e-04,
          1.0025e-03, 1.4385e-03, 2.8310e-03, 3.6630e-04, 1.0218e-03,
          1.2708e-03, 6.8777e-03, 3.3018e-03, 9.5643e-01, 9.7473e-01,
          5.6044e-03],
         [1.7505e-02, 9.2712e-01, 8.6109e-03, 8.6863e-03, 2.8804e-03,
          3.5459e-03, 4.3978e-03, 4.6480e-03, 6.0485e-03, 4.5656e-03,
          1.3516e-03, 7.4914e-04, 6.2831e-03, 9.8658e-01, 9.8608e-01,
          5.0148e-03],
         [3.4440e-02, 9.9569e-01, 9.7961e-01, 1.1886e-02, 6.7390e-03,
          2.0262e-02, 3.3031e-02, 6.0371e-03, 7.2263e-03, 4.3151e-02,
          1.0736e-02, 5.8637e-03, 1.3100e-01, 9.9779e-01, 9.9735e-01,
          9.9262e-01],
         [9.9574e-01, 9.9269e-01, 9.9278e-01, 2.7126e-01, 1.0934e-01,
          3.6462e-02, 2.6018e-02, 3.1478e-02, 4.8590e-02, 1.7703e-02,
          9.4722e-03, 3.1553e-02, 3.3532e-01, 9.9859e-01, 9.9880e-01,
          9.8549e-01],
         [9.8382e-01, 9.8312e-01, 1.0025e-02, 2.2819e-03, 1.1329e-03,
          1.6590e-03, 1.6848e-03, 1.9512e-03, 1.6252e-03, 2.6351e-03,
          2.3704e-03, 1.3310e-03, 7.2236e-03, 2.3722e-02, 9.6243e-01,
          9.7625e-01]],

        [[3.5290e-02, 9.6662e-01, 9.9313e-01, 9.1806e-01, 9.7588e-01,
          1.5879e-02, 5.7696e-03, 2.2865e-01, 9.4318e-01, 9.9423e-01,
          9.8171e-01, 7.8121e-01, 7.6090e-02, 9.9212e-01, 9.9859e-01,
          7.1297e-01],
         [9.9452e-01, 9.9863e-01, 9.9999e-01, 9.9960e-01, 9.3859e-01,
          2.6860e-03, 5.0231e-01, 9.8522e-01, 9.9686e-01, 9.9819e-01,
          9.9560e-01, 9.7345e-01, 9.9894e-01, 9.9973e-01, 9.9999e-01,
          9.9965e-01],
         [9.9694e-01, 9.9990e-01, 9.9998e-01, 9.9589e-01, 5.1609e-02,
          2.1443e-03, 8.9581e-03, 9.1725e-01, 9.8614e-01, 9.5306e-01,
          5.1078e-03, 1.2842e-02, 9.9354e-01, 9.9970e-01, 9.9997e-01,
          9.9750e-01],
         [7.9180e-01, 9.9908e-01, 9.9810e-01, 6.2727e-03, 2.7090e-04,
          1.1829e-04, 2.8074e-04, 1.0780e-03, 1.2451e-03, 1.1519e-03,
          2.1631e-04, 3.4818e-04, 2.0837e-02, 9.9750e-01, 9.9361e-01,
          2.3273e-01],
         [4.3778e-01, 9.6297e-01, 7.5883e-01, 2.1856e-03, 6.9290e-05,
          4.8399e-05, 2.0644e-04, 1.1307e-03, 1.2422e-04, 2.3776e-04,
          3.2753e-05, 2.2420e-04, 5.7785e-03, 9.8898e-01, 9.0487e-01,
          2.1358e-02],
         [9.4732e-03, 2.7638e-03, 6.6611e-04, 4.8301e-04, 1.4767e-04,
          1.4395e-04, 9.2438e-04, 2.1625e-03, 1.0055e-03, 8.9645e-05,
          7.8470e-05, 2.5749e-05, 3.0001e-03, 1.6765e-02, 8.4317e-04,
          5.6174e-04],
         [4.7231e-04, 5.4723e-04, 1.1925e-03, 2.1592e-04, 5.8183e-04,
          1.3845e-03, 3.6158e-03, 6.9131e-03, 2.4435e-03, 2.5782e-03,
          1.0514e-04, 5.1419e-03, 3.7706e-02, 4.4126e-03, 7.1386e-04,
          4.9591e-05],
         [7.9131e-03, 1.5098e-03, 3.6808e-03, 2.5317e-04, 9.5636e-05,
          6.4999e-05, 9.6917e-05, 8.9240e-04, 2.0254e-04, 1.2998e-03,
          2.9755e-03, 1.7821e-02, 2.0855e-01, 6.5131e-02, 3.3575e-03,
          5.8171e-04],
         [1.8930e-02, 9.9359e-01, 9.9566e-01, 1.9476e-02, 1.4903e-02,
          1.0400e-03, 1.0342e-03, 2.5038e-03, 3.7253e-03, 3.9652e-03,
          2.1050e-02, 6.4353e-01, 9.4247e-01, 9.9603e-01, 1.0778e-01,
          1.3114e-03],
         [9.9682e-01, 9.9994e-01, 9.9839e-01, 9.6857e-01, 5.7712e-03,
          1.0545e-03, 1.3518e-04, 6.9022e-03, 5.0795e-04, 1.2213e-02,
          3.9306e-04, 4.1898e-02, 8.7051e-02, 9.9440e-01, 4.8014e-02,
          2.3115e-02],
         [9.9629e-01, 9.9860e-01, 9.9396e-01, 2.6561e-03, 3.8403e-04,
          9.9897e-05, 1.3942e-04, 5.1585e-04, 3.4645e-04, 8.3661e-04,
          1.5205e-04, 8.4439e-03, 2.4234e-01, 1.6073e-01, 3.3668e-02,
          3.5608e-03],
         [9.8289e-01, 9.8977e-01, 3.7094e-01, 2.3583e-04, 1.9938e-04,
          3.8531e-04, 1.2452e-03, 1.4531e-03, 4.6917e-03, 7.8446e-04,
          3.6460e-03, 2.5685e-03, 1.2114e-01, 3.8303e-02, 7.5492e-02,
          5.0359e-03],
         [2.5978e-01, 9.9828e-01, 9.1211e-01, 1.6853e-02, 1.2082e-02,
          6.3123e-03, 3.7153e-02, 5.2198e-01, 2.7721e-01, 1.1385e-01,
          8.6536e-02, 8.0117e-01, 5.9535e-01, 9.9946e-01, 9.9265e-01,
          2.1358e-02],
         [9.9423e-01, 9.9954e-01, 9.9947e-01, 9.9115e-01, 9.4190e-01,
          9.4412e-01, 9.8278e-01, 9.8789e-01, 9.8552e-01, 9.7898e-01,
          9.8368e-01, 9.8675e-01, 9.9732e-01, 9.9982e-01, 9.9971e-01,
          9.9576e-01],
         [9.9831e-01, 9.9621e-01, 9.8039e-01, 1.1401e-01, 6.9495e-02,
          8.6724e-02, 7.1552e-02, 1.9478e-01, 1.6923e-01, 4.5313e-01,
          6.8062e-02, 3.3282e-01, 9.7994e-01, 9.8355e-01, 9.9757e-01,
          9.8598e-01],
         [9.8378e-01, 9.5789e-01, 2.2231e-02, 4.5475e-04, 2.8020e-04,
          1.1752e-03, 9.0054e-04, 7.8806e-04, 1.4855e-03, 2.8524e-03,
          1.6847e-03, 1.4092e-03, 4.8434e-03, 1.1425e-01, 8.6474e-01,
          9.6357e-01]]], device='cuda:0')
The generator was trained on: vit_b_16.
Target class: "strawberry" (949)
The generated adversarial patch on model vit_b_16 had 0 misclassifications
ASR for target model vit_b_16: 0.00%
Archiving results...
Copying results to home directory...
Job completed successfully!

**********************************************************************************************************

The SCRATCHes have been SUCCESSFULLY cleaned...
